<h1>Machine learning (and more) for scenario generation and data</h1>
<h1>augmentation in quantitative wealth and investment management</h1>
<h1>QWIM</h1>
<h2>Cristian Homescu</h2>
<h2>December 2022</h2>
<p><code>Abstract
This document provides details for this QWIM project, and it incorporates the following sections</code>
- Motivation
- Relevant references
- Suggested project tasks and timelines
- Practical info
    Recommended software tools
    Recommended datasets
- Design and implementation for the project codes
- Potentially useful Python and R packages, codes and frameworks
- Appendices
    Appendices include
- Overviews of investment processes and models in QWIM
- Comparison of investment portfolios using portfolios metrics and benchmark portfolios</p>
<h2>Contents</h2>
<p><strong>1 Motivation for the project 4</strong>
1.1 Need for additional data forQWIM.................................... 4
1.2 Using ML to generate synthetic data forQWIM............................. 4</p>
<p><strong>2 Relevant references 6</strong>
2.1 Main references................................................ 6
2.2 Comprehensive list of references....................................... 8
2.2.1 Scenarios incorporating interactions and dependencies across and within market periods... 8
2.2.2 Scenarios based on subsets of factors................................ 8
2.2.3 Incorporating expert views within scenarios............................ 8
2.2.4 Data augmentation and scenarios generated using machine learning within context of QWIM 8
2.2.5 Scenarios based on flexible probabilities.............................. 9
2.2.6 Scenarios based on Monte Carlo simulation............................ 9
2.2.7 Scenarios constructed using bootstrapping approach....................... 10
2.2.8 Scenarios constructed using resampling approach......................... 10
2.2.9 Scenarios based on similarities and discords within time series.................. 10</p>
<pre><code>  - 2.2.10 Data augmentation and scenario generation using machine learning models
  - 2.2.11 Scenarios for extreme events and stress testing
  - 2.2.12 Scenarios for extreme events and stress testing within context of QWIM.
  - 2.2.13 Economic scenario generators.
  - 2.2.14 Scenarios incorporating dependencies (correlations, covariances, copulas).
  - 2.2.15 Extreme events and scenarios.
  - 2.2.16 Extreme events and scenarios within context of QWIM
  - 2.2.17 Scenarios based on agent-based modeliing
  - 2.2.18 Validating scenarios and augmented datasets
  - 2.2.19 Software implementations and frameworks.
</code></pre>
<ul>
<li>3 Practical details for the project</li>
<li>3.1 Interaction with students</li>
<li>3.2 Data.</li>
<li>3.3 Private GitHub repository for the QWIM project.</li>
<li>3.4 Deliverables.</li>
<li>3.5 (Optional) Article submission to leading journals</li>
<li>4 Project tasks and timelines</li>
<li>4.1 Suggested timelines for project tasks</li>
<li>4.2 Literature review.</li>
<li>4.3 Write-up summary of literature review.</li>
<li>4.4 Identification of appropriate Python and/or R packages</li>
<li>4.5 Code design.</li>
<li>4.6 Implementation of coding framework and components</li>
<li>4.7 Interactive visualizer.</li>
<li>4.8 Project report and presentation.</li>
<li>5 Design and implementation for the project codes</li>
<li>5.1 Visualize project workflow and coding framework.</li>
<li>5.2 Representative examples of Python libraries with well designed folder structure</li>
<li>6 Practical Info</li>
<li>6.1 Recommended software tools<ul>
<li>6.1.1 Python</li>
<li>6.1.2 R.</li>
<li>6.1.3 R IDE.</li>
<li>6.1.4 Python IDE.</li>
<li>6.1.5 Bibliography Manager</li>
<li>6.1.6 Document processor</li>
<li>6.1.7 Source control manager</li>
<li>6.1.8 File editor.</li>
<li>6.1.9 Runtime libraries.</li>
</ul>
</li>
<li>6.2 Recommended datasets</li>
<li>7 Potentially useful Python and R software implementations: packages, codes and frameworks</li>
<li>7.1 Collections and repositories of resources</li>
<li>7.2 Connection between Python and R codes</li>
<li>7.3 Anomaly detection and data outliers</li>
<li>7.4 Bayesian analysis and modeling.</li>
<li>7.5 Causality, inference and dependencies</li>
<li>7.6 Classification, Motifs, Neighbors, Wavelets, Transforms.</li>
<li>7.7 Clustering.</li>
<li>7.8 Coding utilities and frameworks.</li>
<li>7.9 Computational performance.</li>
<li>7.10 Containers, projects, pipelines and deployment</li>
<li>7.11 Covariances, correlations and volatilities.</li>
<li>7.12 Data analysis and exploration.</li>
<li>7.13 Data augmentation, scenario generation and synthetic time series.</li>
<li>7.14 Data cleaning, preparation and validation</li>
<li>7.15 Data Imputation</li>
<li>7.16 Data regimes, states and changepoints: analysis and modeling.</li>
<li>7.17 Data structures, storage and serialization</li>
<li>7.18 Dates and times</li>
<li>7.19 Dimensionality reduction</li>
<li>7.20 Distances and Similarity.</li>
<li>7.21 ESG and Impact Investing.</li>
<li>7.22 Explainability, Interpretability, Fairness, Data Privacy</li>
<li>7.23 Features for time series.</li>
<li>7.24 Filtering and spectral analysis for time series</li>
<li>7.25 Forecasting time series.</li>
<li>7.26 Graphs and graphical modeling.</li>
<li>7.27 Linear algebra.</li>
<li>7.28 Machine Learning.</li>
<li>7.29 Machine Learning frameworks (includes Automated ML and hyperparameters tuning)</li>
<li>7.30 Network and graph analysis.</li>
<li>7.31 Numerical methods (includes numerical optimization)</li>
<li>7.32 Probabilistic modeling (includes mixture models and Gaussian Processes)</li>
<li>7.33 Reinforcement learning.</li>
<li>7.34 Robust numerical methods.</li>
<li>7.35 Selection of features, variables, models, data splits</li>
<li>7.36 Sensitivity analysis and numerical derivatives</li>
<li>7.37 Statistics and Probability</li>
<li>7.38 Stress testing, rare events, extreme values and scenarios, survival analysis</li>
<li>7.39 Symbolic regression &amp; data-driven model discovery and machine learning</li>
<li>7.40 Testing (numerical, statistical, etc.), comparison and ranking</li>
<li>7.41 Testing software codes</li>
<li>7.42 Time series analysis and modeling</li>
<li>7.43 Text, sentiment and topic analytics (including NLP)</li>
<li>7.44 Uncertainty: analysis and modeling.</li>
<li>7.45 Visualization and reporting</li>
<li>8 Codes for QWIM (Quantitative Wealth and Investment Management)</li>
<li>8.1 Collections of resources</li>
<li>8.2 Research studies with code</li>
<li>8.3 Python software implementations.</li>
<li>8.4 R software implementations</li>
<li>References</li>
<li>Appendix A: Overviews of investment processes and models in QWIM</li>
<li>Appendix C: Comparison of investment using portfolios metrics and benchmark portfolios</li>
</ul>
<h2>1 Motivation for the project</h2>
<p>Statistical risk management approaches like Value at Risk (VaR) proved largely ineffective in addressing the kinds
of market movements that occurred with past crisis periods. Scenario analysis addresses many of the shortcomings
of the statistical approache, since it is both forward looking and also able to draw on historical experience that
might not be represented in the development samples for statistical approaches.
There is a need to conduct rigorous and systematic scenario analysis. A key challenge in applying scenario
analysis is constructing “tail event” scenarios that are severe but plausible. We can assess scenario’s plausibility
by reference to the behavior of observable variables used to define the scenario (e.g., asset prices, bond yields,
credit spreads, etc.). To generate realistic scenarios in all relevant market regimes we can use use machine learning
approaches to identify regimes.
Additional scenarios can also be generated through “data augmentation” algorithms used in machine learning
(e.g., through transfer learning or generative adversarial networks GANs).</p>
<h3>1.1 Need for additional data for QWIM</h3>
<p>Not having sufficient data (due to medium to low sampling frequency and/or limited historical data) will have an
impact on</p>
<ul>
<li>adequately trainingMLmodels</li>
<li>tackling unbalanced datasets</li>
<li>data anonymization and preserving of data privacy</li>
<li>comprehensive testing of investment strategies and portfolios</li>
<li>robust portfolio construction</li>
<li>portfolio risk management
Synthetic data can be obtained through</li>
<li>ML-based data augmentation <strong>DAug</strong></li>
<li>data similarity with data in other time periods</li>
<li>combine observations with expert views</li>
<li>agent based modeling</li>
<li>scenario generation</li>
<li>construction of stress scenarios</li>
</ul>
<h3>1.2 Using ML to generate synthetic data for QWIM</h3>
<p>There is significant need for additional data inQWIM</p>
<ul>
<li>for adequately trainingMLmodels</li>
<li>to tackle unbalanced datasets</li>
<li>for constructing a very comprehensive set of scenarios incorporating most scenarios which were not observed,
    yet are plausible and consistent with market and investor behavior and with economic intuition</li>
<li>for data anonymization and preserving of data privacy</li>
<li>for comprehensive testing of investment strategies and portfolios</li>
<li>
<p>for constructing much more robust portfolios using scenario-based optimization</p>
</li>
<li>
<p>for better risk management of investment portfolios
Assefa et al. (“Generating Synthetic Data in Finance: Opportunities, Challenges and Pitfalls,” 2019):
synthetic data defined as data obtained from a generative process that learns properties of real data
Synthetic financialTSdata is expected to have universal features, commonly referred to as stylized facts, together
with specialized features of a specific asset class or investment vehicle. When classical approaches are considered,
these stylized facts are often formulated in terms of distribution of returns.
Most promisingMLmethods to generate synthetic financialTS:</p>
</li>
<li>generative adversarial networks GANS</li>
<li>Variational Autoencoders VAEs</li>
<li>Restricted Boltzmann Machine RBM</li>
</ul>
<h2>2 Relevant references</h2>
<h3>2.1 Main references</h3>
<p>List of references:
Alaa et al. (“How Faithful is your Synthetic Data? Sample-level Metrics for Evaluating and Auditing Generative
Models,” 2022)
Asch et al. (“Model-assisted deep learning of rare extreme events from partial observations,” 2022)
Bahrpeyma et al. (“A Methodology for Validating Diversity in Synthetic Time Series Generation,” 2021)
Bhatia et al. (“ExGAN: Adversarial Generation of Extreme Samples,” 2021)
Bond-Taylor et al. (“Deep Generative Modelling: A Comparative Review of VAEs, GANs, Normalizing Flows,
Energy-Based and Autoregressive Models,” 2022)
Bandara et al. (“Improving the accuracy of global forecasting models using time series data augmentation,”
2021)
Buehler et al. (“A Data-driven Market Simulator for Small Data Environments,” 2020)
Buehler et al. (“Generating financial markets with signatures,” 2021)
Cerqueira et al. (“Evaluating time series forecasting models: an empirical study on performance estimation
methods,” 2020)
Cubuk et al. (“RandAugment: Practical data augmentation with no separate search,” 2019)
Czasonis et al. (“Enhanced Scenario Analysis,” 2020)
Czasonis et al. (“Relevance,” 2021)
Dahl and Sorensen (“Time Series (re)sampling using Generative Adversarial Networks,” 2021)
Da Silva and Shi (“Towards Improved Generalization in Financial Markets with Synthetic Data Generation,”
2019)
Debnath et al. (“Exploring Generative Data Augmentation in Multivariate Time Series Forecasting : Opportu-
nities and Challenges,” 2021)
De Gennaro Aquino et al. (“Portfolio Selection With Exploration of New Investment Opportunities,” 2021)
De Meer et al. (“Tackling the exponential scaling of signature-based GANs for high-dimensional financial time
series generation,” 2021)
De Meer Pardo (“Enriching Financial Datasets with Generative Adversarial Networks,” 2019)
Diffenbaugh (“Verification of extreme event attribution: Using out-of-sample observations to assess changes in
probabilities of unprecedented events.,” 2020)
Ding et al. (“Modeling Extreme Events in Time Series Prediction,” 2019)
Dogariu et al. (“Towards Realistic Financial Time Series Generation via Generative Adversarial Learning,” 2021)
Dogariu et al. (“Generation of Realistic Synthetic Financial Time-Series,” 2021)
Faggini et al. (“Crises in economic complex networks: Black Swans or Dragon Kings?” 2019)
Flaig and Junike (“Scenario generation for market risk models using generative neural networks,” 2022)
Franco-Pedroso et al. (“The ETS challenges: a machine learning approach to the evaluation of simulated financial
time series for improving generation processes,” 2019)
Franco-Pedroso et al. (“Generating Virtual Scenarios of Multivariate Financial Data for Quantitative Trading
Applications,” 2019)
Fons et al. (“Adaptive Weighting Scheme for Automatic Time-Series Data Augmentation,” 2021)
Fons et al. (“Augmenting Transferred Representations for Stock Classification,” 2021)
Fritzsch et al. (“Marginals Versus Copulas: Which Account For More Model Risk In Multivariate Risk Fore-
casting?” 2021)
Fu et al. (“Data augmentation for time series,” 2020)
Golub et al. (“Market-Driven Scenarios: An Approach for Plausible Scenario Construction,” 2018)
He et al. (“Data Augmentation Revisited: Rethinking the Distribution Gap between Clean and Augmented
Data,” 2019)
Heaton and Witte (“Synthetic Financial Data: An Application to Regulatory Compliance for Broker-Dealers,”
2021)
Kang et al. (“GRATIS: GeneRAting TIme Series with diverse and controllable characteristics,” 2020)
Kang et al. (“Déjà vu: A data-centric forecasting approach through time series cross-similarity,” 2021)
Kondratyev and Schwarz (“The Market Generator,” 2020)</p>
<p>Koshiyama et al. (“Generative Adversarial Networks for Financial Trading Strategies Fine-Tuning and Combi-
nation,” 2021)
Kritzman et al. (“Portfolio Choice with Path-Dependent Scenarios,” 2021)
Kritzman and Turkington (“History, Shocks, and Drifts: A New Approach to Portfolio Formation,” 2022)
Lerch et al. (“Forecaster’s Dilemma: Extreme Events and Forecast Evaluation,” 2017)
Lezmi et al. (“Improving the Robustness of Trading Strategy Backtesting with Boltzmann Machines and Gen-
erative Adversarial Networks,” 2020)
Lezmi et al. (“Portfolio Allocation with Skewness Risk: A Practical Guide,” 2019)
Li et al. (“SynC: A Copula based Framework for Generating Synthetic Data from Aggregated Sources,” 2020)
Liu et al. (“Efficient Time Series Augmentation Methods,” 2020)
Mannix and Cesa (“’Signatures’ promise quants a tool for all jobs,” 2021)
Mariani et al. (“PAGAN: Portfolio Analysis with Generative Adversarial Networks,” 2019)
Marti et al. (“Exploring and measuring non-linear correlations: Copulas, Lightspeed Transportation and Clus-
tering,” 2017)
Marti (“CORRGAN: sampling realistic financial correlation matrices using generative adversarial networks,”
2020)
Marti et al. (“cCorrGAN: Conditional Correlation GAN for Learning Empirical Conditional Distributions in the
Elliptope,” 2021)
Kuchnik and Smith (“Efficient Augmentation via Data Subsampling,” 2018)
Packham and Woebbeking (“Correlation scenarios and correlation stress testing,” 2021)
Papenbrock et al. (“Matrix Evolutions: Synthetic Correlations and Explainable Machine Learning for Con-
structing Robust Investment Portfolios,” 2021)
Paul et al. (“PSA-GAN: Progressive Self Attention GANs for Synthetic Time Series,” 2022)
Pei et al. (“Towards Generating Real-World Time Series Data,” 2021)
Raab et al. (“Assessing, visualizing and improving the utility of synthetic data,” 2021)
Raghunathan (“Synthetic Data,” 2021)
Rosen and Saunders (“Regress under stress: A simple least-squares method for integrating economic scenarios
with risk simulations,” 2016)
Rosen (“Integrating Economic Scenarios with Advanced Scenario Analytics to Manage Investment Portfolios,”
2015)
Rosen (“Re-Thinking Scenarios: Stress Testing of Multi-Asset Portfolios by Integrating Economic Scenarios
with Advanced Simulation Analytics,” 2015)
Rosolia and Osterrieder (“Analyzing Deep Generated Financial Time Series for Various Asset Classes,” 2021)
Sahamkhadam and Stephan (“Portfolio Optimization Based on Forecasting Models Using Vine Copulas: An
Empirical Assessment for the Financial Crisis,” 2021)
Sapp (“Efficient Estimation of Distributional Tail Shape and the Extremal Index with Applications to Risk
Management,” 2017)
Sharma et al. (“V- U-, L- or W- shaped economic recovery after Covid-19: Insights from an Agent Based Model,”
2021)
Silva and Ferreira (“Surrogate Monte Carlo,” 2021)
Snow (“DataGene: A Framework for Dataset Similarity,” 2020)
Takahashi et al. (“Modeling financial time-series with generative adversarial networks,” 2019)
Wang et al. (“Scalable Data Augmentation for Deep Learning,” 2019)
Wen et al. (“Time Series Data Augmentation for Deep Learning: A Survey,” 2021)
Wiese et al. (“Quant GANs: deep generation of financial time series,” 2020)
Yuan and Yuan (“A Monte Carlo synthetic sample based performance evaluation method for covariance matrix
estimators,” 2021)
Zhang et al. (“DADA: Deep Adversarial Data Augmentation for Extremely Low Data Regime Classification,”
2018)
Ziyin et al. (“What Data Augmentation Do We Need for Deep-Learning-Based Finance?” 2021)
Zorn (“Panic-aware portfolio optimization,” 2019)</p>
<h3>2.2 Comprehensive list of references</h3>
<p><strong>2.2.1 Scenarios incorporating interactions and dependencies across and within market periods</strong>
List of references:
Bass et al. (“Factor Performance Across Market-Driven Scenarios,” 2018)
Czasonis et al. (“Enhanced Scenario Analysis,” 2020)
Czasonis et al. (“Relevance,” 2021)
Golub et al. (“Market-Driven Scenarios: An Approach for Plausible Scenario Construction,” 2018)
Kritzman et al. (“Portfolio Choice with Path-Dependent Scenarios,” 2021)
Kritzman and Turkington (“History, Shocks and Drifts: A New Approach to Portfolio Formation,” 2021)
Papenbrock et al. (“Matrix Evolutions: Synthetic Correlations and Explainable Machine Learning for Con-
structing Robust Investment Portfolios,” 2021)</p>
<p><strong>2.2.2 Scenarios based on subsets of factors</strong>
List of references:
Glasserman et al. (“Stress scenario selection by empirical likelihood,” 2015)
Rosen and Saunders (“Regress under stress: A simple least-squares method for integrating economic scenarios
with risk simulations,” 2016)
Rosen and Saunders (“Regress Under Stress: A Simple Least-Squares Method for Integrating Economic Scenarios
with Risk Simulations,” 2015)
Rosen (“Integrating Economic Scenarios with Advanced Scenario Analytics to Manage Investment Portfolios,”
2015)
Rosen (“Re-Thinking Scenarios: Stress Testing of Multi-Asset Portfolios by Integrating Economic Scenarios
with Advanced Simulation Analytics,” 2015)</p>
<p><strong>2.2.3 Incorporating expert views within scenarios</strong>
List of references:
Bolger and Wright (“Use of expert knowledge to anticipate the future: Issues, analysis and directions,” 2017)
Colson and Cooke (“Cross validation for the classical model of structured expert judgment,” 2017)
Davis and Lleo (“A Simple Procedure for Combining Expert Opinion with Statistical Estimates to Achieve
Superior Portfolio Performance,” 2016)
Davis and Lleo (“Behaviouralizing Black-Litterman: Expert Opinions and Behavioural Biases in a Diffusion
Setting,” 2015)
Franses and Bruijn (“Benchmarking Judgmentally Adjusted Forecasts,” 2017)
Gzyl et al. (“Inferring probability densities from expert opinion,” 2017)
Hsu et al. (“Bridging the divide in financial market forecasting: machine learners vs. financial economists,”
2016)
Johnson and West (“Bayesian Predictive Synthesis: Forecast Calibration and Combination,” 2018)
Nguyen and Chamroukhi (“Practical and theoretical aspects of mixture-of-experts modeling: An overview,”
2018)
Panchekha et al. (“Ensemble Active Management,” 2018)
Silva et al. (“A more human-like portfolio optimization approach,” 2017)
Wood (“How sure are we? Two approaches to statistical inference,” 2018)</p>
<p><strong>2.2.4 Data augmentation and scenarios generated using machine learning within context of QWIM</strong>
List of references:
Buehler et al. (“Deep hedging,” 2019)
Buehler et al. (“A Data-driven Market Simulator for Small Data Environments,” 2020)
Buehler et al. (“Generating financial markets with signatures,” 2021)
Coletta et al. (“Towards Realistic Market Simulations: a Generative Adversarial Networks Approach,” 2021)
De Meer Pardo (“Enriching Financial Datasets with Generative Adversarial Networks,” 2019)</p>
<p>De Meer Pardo and Lopez (“Mitigating Overfitting on Financial Datasets with Generative Adversarial Net-
works,” 2020)
de Miranda Cardoso et al. (“Algorithms for Learning Graphs in Financial Markets,” 2020)
Eckerli (“Generative Adversarial Networks in finance: an overview,” 2021)
Fons et al. (“Adaptive Weighting Scheme for Automatic Time-Series Data Augmentation,” 2021)
Fons et al. (“Augmenting Transferred Representations for Stock Classification,” 2021)
Franco-Pedroso et al. (“Generating Virtual Scenarios of Multivariate Financial Data for Quantitative Trading
Applications,” 2019)
Franco-Pedroso et al. (“The ETS challenges: a machine learning approach to the evaluation of simulated financial
time series for improving generation processes,” 2019)
Heaton and Witte (“Synthetic Financial Data: An Application to Regulatory Compliance for Broker-Dealers,”
2021)
Henry-Labordere (“Generative models for financial data,” 2019)
Kondratyev and Schwarz (“The Market Generator,” 2020)
Koshiyama et al. (“Generative Adversarial Networks for Financial Trading Strategies Fine-Tuning and Combi-
nation,” 2021)
Lezmi et al. (“Improving the Robustness of Trading Strategy Backtesting with Boltzmann Machines and Gen-
erative Adversarial Networks,” 2020)
Marti (“CORRGAN: sampling realistic financial correlation matrices using generative adversarial networks,”
2020)
Marti (“Generating Realistic Synthetic Data in Finance: Applications of GANs,” 2020)
Rikli et al. (“Wasserstein GAN: Deep Generation applied on Bitcoins financial time series,” 2021)
Rosolia and Osterrieder (“Analyzing Deep Generated Financial Time Series for Various Asset Classes,” 2021)
Shah and Shroff (“Forecasting Market Prices using DL with Data Augmentation and Meta-learning: ARIMA
still wins!” 2021)
Takahashi et al. (“Modeling financial time-series with generative adversarial networks,” 2019)
Wiese et al. (“Quant GANs: deep generation of financial time series,” 2020)
Ziyin et al. (“What Data Augmentation Do We Need for Deep-Learning-Based Finance?” 2021)</p>
<p><strong>2.2.5 Scenarios based on flexible probabilities</strong>
List of references:
Ardia and Meucci (“Stress testing in non-normal markets via entropy pooling,” 2015)
Ardia and Bluteau (“Stress-Testing With Parametric Models and Fully Flexible Probabilities,” 2017)
Meucci (“Fully Flexible Views: Theory and Practice,” 2008)
Meucci et al. (“Fully Flexible Extreme Views,” 2012)
Sebastian and Gebbie (“Systematic Asset Allocation using Flexible Views for South African Markets,” 2019)</p>
<p><strong>2.2.6 Scenarios based on Monte Carlo simulation</strong>
List of references:
Chen and Chen ( <em>Monte-Carlo Simulation-Based Statistical Modeling</em> , 2017)
Juan et al. (“A review of the role of heuristics in stochastic optimisation: from metaheuristics to learnheuristics,”
2022)
Lam and Li (“Parametric Scenario Optimization under Limited Data: A Distributionally Robust Optimization
View,” 2020)
Ledermann et al. (“Random orthogonal matrix simulation,” 2011)
Ledermann and Alexander (“Further properties of random orthogonal matrix simulation,” 2012)
Lee (“Stress testing Monte Carlo assumptions,” 2013)
Leon and Reveiz (“Monte Carlo Simulation of Long-Term Dependent Processes: A Primer,” 2012)
Schissler et al. (“Simulating High-Dimensional Multivariate Data using the bigsimr R Package,” 2021)
Silva and Ferreira (“Surrogate Monte Carlo,” 2021)
Staum (“Monte Carlo Computation in Finance,” 2009)
Yuan and Yuan (“A Monte Carlo synthetic sample based performance evaluation method for covariance matrix
estimators,” 2021)</p>
<p><code>Zhang (“Modern Monte Carlo methods for efficient uncertainty quantification and propagation: A survey,” 2020)</code>
<strong>2.2.7 Scenarios constructed using bootstrapping approach</strong>
List of references:
Bertsimas and Van Parys (“Bootstrap Robust Prescriptive Analytics,” 2017)
Cavaliere et al. (“An Introduction to Bootstrap Theory in Time Series Econometrics,” 2020)
Cogneau and Zakamouline (“Block bootstrap methods and the choice of stocks for the long run,” 2013)
Davidson (“Diagnostics for the bootstrap and fast double bootstrap,” 2017)
El Karoui and Purdom (“Can we trust the bootstrap in high-dimensions? the case of linear models,” 2018)
Gilleland (“Bootstrap Methods for Statistical Inference. Part I: Comparative Forecast Verification for Continu-
ous Variables,” 2020)
Gilleland (“Bootstrap Methods for Statistical Inference. Part II: Extreme-Value Analysis,” 2020)
Goncalves and Perron (“Bootstrapping factor models with cross sectional dependence,” 2020)
Hambuckers and Heuchenne (“Estimating the Out-of-Sample Predictive Ability of Trading Rules: A Robust
Bootstrap Approach,” 2016)
Honore and Hu (“Poor (Wo)man’s Bootstrap,” 2017)
Horowitz (“Bootstrap methods in econometrics,” 2019)
Imbens and Menzel (“A causal bootstrap,” 2021)
Jaeger et al. (“Understanding machine learning for diversified portfolio construction by explainable AI,” 2020)
Kreiss and Paparoditis (“Bootstrap methods for dependent data: A review,” 2011)
Little and Badawy (“Causal bootstrapping,” 2020)
Page (“How to combine long and short return histories efficiently,” 2013)
Pathak and Rao (“The Sequential Bootstrap,” 2013)
Romano and Wolf (“Multiple Testing of One-Sided Hypotheses: Combining Bonferroni and the Bootstrap,”
2018)
Sani et al. (“The replacement bootstrap for dependent data,” 2015)
Tsamardinos et al. (“Bootstrapping the out-of-sample predictions for efficient and accurate cross-validation,”
2018)
Vinod (“Constructing Scenarios of Time Heterogeneous Series for Stress Testing,” 2012)
Wang and Tu (“Bootstrap methods: the classical theory and recent development,” 2014)
Xu et al. (“Applications of the Fractional-Random-Weight Bootstrap,” 2020)</p>
<p><strong>2.2.8 Scenarios constructed using resampling approach</strong>
List of references:
Cerqueira et al. (“Evaluating time series forecasting models: an empirical study on performance estimation
methods,” 2020)
Chihara and Hesterberg ( <em>Mathematical Statistics with Resampling and R, 2nd Edition</em> , 2018)
Dahl and Sorensen (“Time Series (re)sampling using Generative Adversarial Networks,” 2021)
Frahm (“A theoretical foundation of portfolio resampling,” 2015)
Hoffman (“Resampling Statistics,” 2015)
Huang and Yu (“A new procedure for resampled portfolio with shrinkaged covariance matrix,” 2020)
Mammen and Nandi (“Bootstrap and Resampling,” 2012)
Michaud and Michaud (“Estimation Error and Portfolio Optimization: A Resampling Solution,” 2015)
Oneto (“Resampling Methods,” 2019)
Sarris et al. (“Exploiting resampling techniques for model selection in forecasting: an empirical evaluation using
out-of-sample tests,” 2020)</p>
<p><strong>2.2.9 Scenarios based on similarities and discords within time series</strong>
List of references:
Gharghabi et al. (“Matrix profile XII: mpdist: A novel time series distance measure to allow data mining in
more challenging scenarios,” 2018)
Gonzalez et al. (“Similarity Metrics for Transfer Learning in Financial Markets,” 2021)</p>
<p>Kang et al. (“Déjà vu: A data-centric forecasting approach through time series cross-similarity,” 2021)
Kegel et al. (“Feature-based comparison and generation of time series,” 2018)
Kegel et al. (“Generating What-If Scenarios for Time Series Data,” 2017)
Linardi et al. (“VALMOD: A suite for easy and exact detection of variable length motifs in data series,” 2018)
Mikalsen et al. (“Time Series Cluster Kernel for Learning Similarities between Multivariate Time Series with
Missing Data,” 2018)
Snow (“DataGene: A Framework for Dataset Similarity,” 2020)
Stephanovitch et al. (“Optimal 1-Wasserstein Distance for WGANs,” 2022)
Yeh et al. (“Time series joins, motifs, discords and shapelets: a unifying view that exploits the matrix profile,”
2017)
Yeh (“Towards a Near Universal Time Series Data Mining Tool: Introducing the Matrix Profile,” 2020)
Zhu et al. (“Time series chains: A novel tool for time series data mining,” 2018)
Zhu et al. (“Introducing time series chains: a new primitive for time series data mining,” 2019)</p>
<h4>2.2.10 Data augmentation and scenario generation using machine learning models</h4>
<p>List of references:
Bandara et al. (“Improving the accuracy of global forecasting models using time series data augmentation,”
2021)
Bhattarai et al. (“Sampling Strategies for GAN Synthetic Data,” 2020)
Bond-Taylor et al. (“Deep Generative Modelling: A Comparative Review of VAEs, GANs, Normalizing Flows,
Energy-Based and Autoregressive Models,” 2022)
Chadebec and Allassonniere (“Data Augmentation with Variational Autoencoders and Manifold Sampling,”
2021)
Chalongvorachai and Woraratpanya (“A data generation framework for extremely rare case signals,” 2021)
Charte et al. (“A practical tutorial on autoencoders for nonlinear feature fusion: Taxonomy, models, software
and guidelines,” 2018)
Chen et al. (“An Empirical Survey of Data Augmentation for Limited Data Learning in NLP,” 2021)
Cao and Guo (“Generative Adversarial Network: Some Analytical Perspectives,” 2021)
Dahl and Sorensen (“Time Series (re)sampling using Generative Adversarial Networks,” 2021)
Debnath et al. (“Exploring Generative Data Augmentation in Multivariate Time Series Forecasting : Opportu-
nities and Challenges,” 2021)
De Meer et al. (“Tackling the exponential scaling of signature-based GANs for high-dimensional financial time
series generation,” 2021)
Dogariu et al. (“Towards Realistic Financial Time Series Generation via Generative Adversarial Learning,” 2021)
Dogariu et al. (“Generation of Realistic Synthetic Financial Time-Series,” 2021)
Eckerli and Osterrieder (“Generative Adversarial Networks in finance: an overview,” 2021)
Faez et al. (“Deep Graph Generators: A Survey,” 2020)
Fakoor et al. (“Fast, Accurate, and Simple Models for Tabular Data via Augmented Distillation,” 2020)
Fang and Lin (“Prior knowledge distillation based on financial time series,” 2020)
Fawaz et al. (“Data augmentation using synthetic data for time series classification with deep residual networks,”
2018)
Fons et al. (“Adaptive Weighting Scheme for Automatic Time-Series Data Augmentation,” 2021)
Fu et al. (“Data augmentation for time series,” 2020)
Goel et al. (“Model Patching: Closing the Subgroup Performance Gap with Data Augmentation,” 2020)
He et al. (“Data Augmentation Revisited: Rethinking the Distribution Gap between Clean and Augmented
Data,” 2019)
Hofert et al. (“Multivariate time-series modeling with generative neural networks,” 2021)
Hoffmann et al. (“Machine Learning in a data-limited regime: Augmenting experiments with synthetic data
uncovers order in crumpled sheets,” 2018)
Imokoyende (“Variational Autoencoder In Finance,” 2019)
Iwana and Uchida (“An empirical survey of data augmentation for time series classification with neural net-
works,” 2021)
Jabbar et al. (“A Survey on Generative Adversarial Networks: Variants, Applications, and Training,” 2020)</p>
<p>Javeri et al. (“Improving Neural Networks for Time-Series Forecasting using Data Augmentation and AutoML,”
2021)
Jiang et al. (“Deceive D: Adaptive Pseudo Augmentation for GAN Training with Limited Data,” 2021)
Jin and Rinard (“Towards Context-Agnostic Learning Using Synthetic Data,” 2021)
Kingma and Welling (“An introduction to variational autoencoders,” 2019)
Koesdwiady et al. (“Methods to Improve Multi-Step Time Series Prediction,” 2018)
Kong et al. (“Robust Optimization as Data Augmentation for Large-scale Graphs,” 2022)
Koochali et al. (“If You Like It, GAN It. Probabilistic Multivariate Times Series Forecast With GAN,” 2020)
Kuchnik and Smith (“Efficient Augmentation via Data Subsampling,” 2018)
Laskin et al. (“Reinforcement Learning with Augmented Data,” 2020)
Lawrence et al. (“Data Generating Process to Evaluate Causal Discovery Techniques for Time Series Data,”
2021)
Lezmi et al. (“Improving the Robustness of Trading Strategy Backtesting with Boltzmann Machines and Gen-
erative Adversarial Networks,” 2020)
Leznik et al. (“Multivariate Time Series Synthesis Using Generative Adversarial Networks,” 2021)
Li et al. (“Improving GAN with inverse cumulative distribution function for tabular data synthesis,” 2021)
Li et al. (“A Synthetic Regression Model for Large Portfolio Allocation,” 2022)
Lim et al. (“Noisy Feature Mixup,” 2021)
Liu et al. (“Efficient Time Series Augmentation Methods,” 2020)
Mannix and Cesa (“’Signatures’ promise quants a tool for all jobs,” 2021)
Ni et al. (“Conditional Sig-Wasserstein GANs for Time Series Generation,” 2020)
Padhi et al. (“Tabular Transformers for Modeling Multivariate Time Series,” 2021)
Pan et al. (“Data-Centric Engineering: integrating simulation, machine learning and statistics. Challenges and
Opportunities,” 2021)
Pei et al. (“Towards Generating Real-World Time Series Data,” 2021)
Perez et al. (“Data augmentation through multivariate scenario forecasting in Data Centers using Generative
Adversarial Networks,” 2022)
Raileanu et al. (“Automatic Data Augmentation for Generalization in Deep Reinforcement Learning,” 2021)
Rajabi and Garibay (“TabFairGAN: Fair Tabular Data Generation with Generative Adversarial Networks,”
2021)
Rocca and Rocca (“Intuitively Understanding Variational Autoencoders,” 2019)
Rosolia and Osterrieder (“Analyzing Deep Generated Financial Time Series for Various Asset Classes,” 2021)
Salazar et al. (“Generative Adversarial Networks and Markov Random Fields for oversampling very small training
sets,” 2021)
Saxena and Cao (“Generative Adversarial Networks (GANs),” 2022)
Saxena and Cao (“Generative Adversarial Networks (GANs): Challenges, Solutions, and Future Directions,”
2020)
Shah and Shroff (“Forecasting Market Prices using DL with Data Augmentation and Meta-learning: ARIMA
still wins!” 2021)
Shen et al. (“Towards Out-Of-Distribution Generalization: A Survey,” 2021)
Smith and Smith (“Conditional GAN for timeseries generation,” 2020)
Sun et al. (“Decision-Aware Conditional GANs for Time Series Data,” 2020)
Taylor and Nitschke (“Improving Deep Learning using Generic Data Augmentation,” 2017)
Tran et al. (“A Bayesian Data Augmentation Approach for Learning Deep Models,” 2017)
Vieira (“Generating Synthetic Sequential Data using GANs,” 2020)
Volpi et al. (“Generalizing to Unseen Domains via Adversarial Data Augmentation,” 2018)
Wang et al. (“Regularizing Deep Networks with Semantic Data Augmentation,” 2020)
Wang et al. (“Scalable Data Augmentation for Deep Learning,” 2019)
Wen et al. (“Time Series Data Augmentation for Deep Learning: A Survey,” 2021)
Xie et al. (“Unsupervised Data Augmentation,” 2019)
Yacoby et al. (“Characterizing and Avoiding Problematic Global Optima of Variational Autoencoders,” 2020)
Yao et al. (“Learning with Small Data,” 2020)
Ye and Dai (“Implementing transfer learning across different datasets for time series forecasting,” 2021)
Yoon et al. (“Time-series Generative Adversarial Networks,” 2019)</p>
<p><code>Xu et al. (“Unsupervised meta-learning for few-shot learning,” 2021)
Yu (“A Tutorial on VAEs: From Bayes’ Rule to Lossless Compression,” 2020)
Zhu et al. (“Pagan: Portfolio Analysis with Generative Adversarial Networks,” 2021)</code></p>
<h4>2.2.11 Scenarios for extreme events and stress testing</h4>
<p>List of references:
Bhatia et al. (“ExGAN: Adversarial Generation of Extreme Samples,” 2021)
Chalongvorachai and Woraratpanya (“A data generation framework for extremely rare case signals,” 2021)
Diffenbaugh (“Verification of extreme event attribution: Using out-of-sample observations to assess changes in
probabilities of unprecedented events.,” 2020)
Ding et al. (“Modeling Extreme Events in Time Series Prediction,” 2019)
Engelke and Ivanovs (“Sparse Structures for Multivariate Extremes,” 2021)
Lerch et al. (“Forecaster’s Dilemma: Extreme Events and Forecast Evaluation,” 2017)
Naveau et al. (“Statistical methods for extreme event attribution in climate science,” 2020)
Qi and Majda (“Using machine learning to predict extreme events in complex systems.,” 2019)
Schwaab et al. (“Modeling Extreme Events: Time-Varying Extreme Tail Shape,” 2021)
Zhao (“Event Prediction in the Big Data Era,” 2022)</p>
<h4>2.2.12 Scenarios for extreme events and stress testing within context of QWIM.</h4>
<p>List of references:
Al Janabi et al. (“Multivariate dependence and portfolio optimization algorithms under illiquid market scenar-
ios,” 2017)
Albanese et al. (“Reverse Stress Testing,” 2020)
Alokley and Albarrak (“Clustering of Extremes in Financial Returns: A Study of Developed and Emerging
Markets,” 2020)
Ardia and Meucci (“Stress testing in non-normal markets via entropy pooling,” 2015)
Ardia and Bluteau (“Stress-Testing With Parametric Models and Fully Flexible Probabilities,” 2017)
Arora et al. (“Extreme Yet Plausible: Choosing Scenarios to Stress Test Financial Institutions,” 2021)
Aste (“Stress testing and systemic risk measures using multivariate conditional probability,” 2021)
Baes and Schaanning (“Reverse Stress Testing: Scenario Design for Macroprudential Stress Tests,” 2020)
Breuer and Summer (“Systematic stress tests on public data,” 2020)
Bianchi et al. ( <em>Handbook of Heavy-Tailed Distributions in Asset Management and Risk Management</em> , 2019)
Bilgili et al. (“Stress Hedging in Portfolio Construction,” 2017)
Boubaker and Nguyen ( <em>Handbook of Global Financial Markets</em> , 2019)
Chalkis et al. (“Modeling of crisis periods in stock markets,” 2021)
Chen and Nasekin (“Quantifying systemic risk with factor copulas,” 2020)
Cohort et al. (“Analytical scores for stress scenarios,” 2020)
Denev and Mutnikas (“A Formalized, Integrated and Visual Approach to Stress Testing,” 2016)
Engle (“Stress Testing with Market Data,” 2020)
Flood and Korenko (“Systematic scenario selection: stress testing and the nature of uncertainty,” 2015)
Gao et al. (“Efficient Simulation of Financial Stress Testing Scenarios with Suppes-Bayes Causal Networks,”
2017)
Gao et al. (“Causal data science for financial stress testing,” 2018)
Glasserman et al. (“Stress scenario selection by empirical likelihood,” 2015)
Grundke (“Further recipes for quantitative reverse stress testing,” 2012)
Kantos and diBartolomeo (“How the pandemic taught us to turn smart beta into real alpha,” 2020)
Kopeliovich et al. (“Robust Risk Estimation and Hedging: A Reverse Stress Testing Approach,” 2015)
Meucci ( <em>A Fully Integrated Liquidity and Market Risk Model</em> , 2012)
Pesenti et al. (“Scenario weights for importance measurement (SWIM) - an R package for sensitivity analysis,”
2020)
Pesenti et al. (“Reverse sensitivity testing: What does it take to break the model?” 2019)
Rebonato (“The quickest way to lose the money you cannot afford to lose: reverse stress testing with maximum
entropy,” 2018)</p>
<p>Rojas and Dias (“Stress testing network reconstruction via graphical causal model,” 2021)
Rosen and Saunders (“Regress under stress: A simple least-squares method for integrating economic scenarios
with risk simulations,” 2016)
Ruenzi et al. (“Joint Extreme events in equity returns and liquidity and their cross-sectional pricing implications,”
2020)
Schwaab et al. (“Modeling Extreme Events: Time-Varying Extreme Tail Shape,” 2021)
Seabrook et al. (“An Information Filtering approach to stress testing: an application to FTSE markets,” 2021)
Siddique et al. ( <em>Stress Testing (Second Edition)</em> , 2019)
Skoglund (“Quantification of model risk in stress testing and scenario analysis,” 2019)
Tanaka (“Forecasting scenarios from the perspective of a reverse stress test using second-order cone program-
ming,” 2017)
Traccucci et al. (“A Triptych Approach for Reverse Stress Testing of Complex Portfolios,” 2019)
Wang et al. (“Forecasting stock volatility in the presence of extreme shocks: Short-term and long-term effects,”
2020)
Zorn (“Panic-aware portfolio optimization,” 2019)</p>
<h4>2.2.13 Economic scenario generators.</h4>
<p>List of references:
Barra Montevechi et al. (“A simulation-based approach to perform economic evaluation scenarios,” 2017)
Cheng and Planchet (“Stochastic Deflator for an Economic Scenario Generator with Five Factors,” 2018)
Chen et al. (“Personalised drawdown strategies and partial annuitisation to mitigate longevity risk,” 2021)
Chen et al. (“Using a stochastic economic scenario generator to analyse uncertain superannuation and retirement
outcomes,” 2021)
Czasonis et al. (“Enhanced Scenario Analysis,” 2020)
De Meo (“Scenario Design for Macro-Financial Stress Testing,” 2019)
Facchinato and Pola (“Managing uncertainty with diversification across macroeconomic scenarios (DAMS): from
asset segmentation to portfolio,” 2014)
Flaig and Junike (“Scenario generation for market risk models using generative neural networks,” 2022)
Golub et al. (“Market-Driven Scenarios: An Approach for Plausible Scenario Construction,” 2018)
Haldane and Turrell (“Drawing on different disciplines: macroeconomic agent-based models,” 2018)
Lee et al. (“How can an economic scenario generation model cope with abrupt changes in financial markets?”
2021)
Moudiki and Planchet (“Economic Scenario Generators,” 2016)
Ortec Finance (“Ex ante risk management with scenarios,” 2014)
Rosen (“Integrating Economic Scenarios with Advanced Scenario Analytics to Manage Investment Portfolios,”
2015)
Rosen (“Re-Thinking Scenarios: Stress Testing of Multi-Asset Portfolios by Integrating Economic Scenarios
with Advanced Simulation Analytics,” 2015)
Rosen and Saunders (“Regress Under Stress: A Simple Least-Squares Method for Integrating Economic Scenarios
with Risk Simulations,” 2015)
Rosen and Saunders (“Regress under stress: A simple least-squares method for integrating economic scenarios
with risk simulations,” 2016)
Schneider (“Sparse economic scenarios,” 2020)
Sharma et al. (“V- U-, L- or W- shaped economic recovery after Covid-19: Insights from an Agent Based Model,”
2021)
Siew et al. (“The Impact of Different Economic Scenarios Towards Portfolio Selection in Enhanced Index Tracking
Problem,” 2015)
Steehouwer (“Ex-ante risk management with scenarios,” 2014)
Steehouwer and Slater (“Macroeconomic Scenarios: A Frequency Domain Approach,” 2010)
Trimborn et al. (“SABCEMM: A Simulator for Agent-Based Computational Economic Market Models,” 2020)
van Beek (“Consistent Calibration of Economic Scenario Generators: The Case for Conditional Simulation,”
2020)
Wang (“Discriminating modelling approaches for Point in Time Economic Scenario Generation,” 2021)</p>
<p><code>Zhang (“Optimal Retirement Planning: Scenario Generation, Preferences, and Objectives,” 2018)</code></p>
<h4>2.2.14 Scenarios incorporating dependencies (correlations, covariances, copulas).</h4>
<p>List of references:
Alexander and Ledermann (“ROM Simulation: Applications to Stress Testing and VaR,” 2012)
Amengual and Sentana (“Is a Normal Copula the Right Copula?” 2020)
Benali et al. (“MTCopula: Synthetic Complex Data Generation Using Copula,” 2021)
Carrillo et al. (“A New Machine Learning Forecasting Algorithm Based on Bivariate Copula Functions,” 2021)
Czado and Nagler (“Vine Copula Based Modeling,” 2022)
Fritzsch et al. (“Marginals Versus Copulas: Which Account For More Model Risk In Multivariate Risk Fore-
casting?” 2021)
Fulle and Herwartz (“A Multivariate Markov-Switching GARCH Model with Copula-Distributed Innovations,”
2021)
Galeeva et al. (“Measuring correlation risk for Energy Derivatives,” 2012)
Großer and Okhrin (“Copulae: An overview and recent developments,” 2021)
Harutyunyan et al. (“Efficient Covariance Estimation from Temporal Data,” 2021)
Janke et al. (“Implicit Generative Copulas,” 2021)
Ledermann and Alexander (“Further properties of random orthogonal matrix simulation,” 2012)
Ledoit and Wolf (“Shrinkage estimation of large covariance matrices: Keep it simple, statistician?” 2021)
Li et al. (“SynC: A Copula based Framework for Generating Synthetic Data from Aggregated Sources,” 2020)
Lu and Ghosh (“Nonparametric estimation of multivariate copula using empirical bayes method,” 2021)
Ma (“copent: Estimating Copula Entropy and Transfer Entropy in R,” 2021)
Marti et al. (“Exploring and measuring non-linear correlations: Copulas, Lightspeed Transportation and Clus-
tering,” 2017)
Marti (“CORRGAN: sampling realistic financial correlation matrices using generative adversarial networks,”
2020)
Marti et al. (“cCorrGAN: Conditional Correlation GAN for Learning Empirical Conditional Distributions in the
Elliptope,” 2021)
Marti et al. (“A review of two decades of correlations, hierarchies, networks and clustering in financial markets,”
2021)
Meyer and Nagler (“Synthia: multidimensional synthetic data generation in Python,” 2021)
Nasri and Rémillard (“Copula-based dynamic models for multivariate time series,” 2019)
Nasri et al. (“Goodness-of-fit for regime-switching copula models with application to option pricing,” 2020)
Opdyke (“Full Probabilistic Control for Direct and Robust, Generalized and Targeted Stressing of the Correlation
Matrix (Even When Eigenvalues are Empirically Challenging,” 2020)
Packham and Woebbeking (“Correlation scenarios and correlation stress testing,” 2021)
Papenbrock et al. (“Matrix Evolutions: Synthetic Correlations and Explainable Machine Learning for Con-
structing Robust Investment Portfolios,” 2021)
Sahamkhadam and Stephan (“Portfolio Optimization Based on Forecasting Models Using Vine Copulas: An
Empirical Assessment for the Financial Crisis,” 2021)
Tan and Zohren (“Large Non-Stationary Noisy Covariance Matrices: A Cross-Validation Approach,” 2021)
Traccucci et al. (“A Triptych Approach for Reverse Stress Testing of Complex Portfolios,” 2019)
Trucı́os et al. (“Forecasting Conditional Covariance Matrices in High-Dimensional Time Series: a General Dy-
namic Factor Approach,” 2021)
Tsanakas and Zhu (“Copula model selection using image recognition,” 2021)
Waller (“Generating Correlation Matrices With Specified Eigenvalues Using the Method of Alternating Projec-
tions,” 2020)
Yu et al. (“Adjusting covariance matrix for risk management,” 2020)
Yuan and Yuan (“A Monte Carlo synthetic sample based performance evaluation method for covariance matrix
estimators,” 2021)</p>
<h4>2.2.15 Extreme events and scenarios.</h4>
<p>References:
Asch et al. (“Model-assisted deep learning of rare extreme events from partial observations,” 2022)
Bhatia et al. (“ExGAN: Adversarial Generation of Extreme Samples,” 2021)
Buczak et al. (“Crystal Cube: Forecasting Disruptive Events,” 2022)
Chevalier et al. (“Modeling Nonstationary Extreme Dependence With Stationary Max-Stable Processes and
Multidimensional Scaling,” 2021)
Diffenbaugh (“Verification of extreme event attribution: Using out-of-sample observations to assess changes in
probabilities of unprecedented events.,” 2020)
Ding et al. (“Modeling Extreme Events in Time Series Prediction,” 2019)
Faggini et al. (“Crises in economic complex networks: Black Swans or Dragon Kings?” 2019)
Lerch et al. (“Forecaster’s Dilemma: Extreme Events and Forecast Evaluation,” 2017)
Medina et al. (“Spectral learning of multivariate extremes,” 2021)
Naveau et al. (“Statistical methods for extreme event attribution in climate science,” 2020)
Qi and Majda (“Using machine learning to predict extreme events in complex systems.,” 2019)
Racca and Magri (“Statistical prediction of extreme events from small datasets,” 2022)
Yılmaz et al. (“Comparison of different estimation methods for extreme value distribution,” 2021)</p>
<h4>2.2.16 Extreme events and scenarios within context of QWIM</h4>
<p>References:
Cai et al. (“New volatility evolution model after extreme events,” 2022)
De Luca and Zuccolotto (“A double clustering algorithm for financial time series based on extreme events,”
2016)
Elkamhi and Stefanova (“Dynamic Hedging and Extreme Asset Co-movements,” 2015)
Kapoor and Shrivastava (“Extreme Values Theory and Return Level Analysis for Catastrophe Prediction,” 2014)
Kemp ( <em>Extreme Events: Robust Portfolio Construction in the Presence of Fat Tails</em> , 2014)
Lezmi et al. (“Portfolio Allocation with Skewness Risk: A Practical Guide,” 2019)
Ruenzi et al. (“Joint Extreme events in equity returns and liquidity and their cross-sectional pricing implications,”
2020)
Sapp (“Efficient Estimation of Distributional Tail Shape and the Extremal Index with Applications to Risk
Management,” 2017)
Zorn (“Panic-aware portfolio optimization,” 2019)</p>
<h4>2.2.17 Scenarios based on agent-based modeliing</h4>
<p>List of references:
Bai et al. (“Efficient Calibration of Multi-Agent Market Simulators from Time Series with Bayesian Optimiza-
tion,” 2021)
Beikirch et al. (“Robust Mathematical Formulation and Probabilistic Description of Agent-Based Computational
Economic Market Models,” 2021)
Chabi-Yo and Loudis (“A Decomposition of Conditional Risk Premia and Implications for Representative Agent
Models,” 2021)
Clark et al. (“Test case generation for agent-based models: A systematic literature review,” 2021)
De Gennaro Aquino et al. (“Portfolio Selection With Exploration of New Investment Opportunities,” 2021)
Foramitti (“AgentPy: A package for agent-based modeling in Python,” 2021)
Esmaeili et al. (“HAMLET: A Hierarchical Agent-based Machine Learning Platform,” 2021)
Harwick (“Helipad: A Framework for Agent-Based Modeling in Python,” 2021)
Istrate (“Models we Can Trust: Toward a Systematic Discipline of (Agent-Based) Model Interpretation and
Validation,” 2021)
Jericevich et al. (“Calibrating an adaptive Farmer-Joshi agent-based model for financial markets,” 2021)
Karaś and Serwatka (“Strong-hand conjecture: agent-based numerical simulation,” 2021)
Lindner et al. (“Learning What To Do by Simulating the Past,” 2021)
Lux (“Can heterogeneous agent models explain the alleged mispricing of the S&amp;P 500?” 2021)</p>
<p>Niemann et al. (“Data-driven model reduction of agent-based systems using the Koopman generator,” 2021)
Papoudakis et al. (“Agent Modelling under Partial Observability for Deep Reinforcement Learning,” 2021)
Perumal and van Zyl (“Surrogate Assisted Methods for the Parameterisation of Agent-Based Models,” 2020)
Sharma et al. (“A constraint-satisfaction agent-based model for the macroeconomy,” 2020)
Shi et al. (“Pyramid scheme in stock market: a kind of financial market simulation,” 2021)
Schuderer et al. (“Sim-Env: Decoupling OpenAI Gym Environments from Simulation Models,” 2021)
Sharma et al. (“V- U-, L- or W- shaped economic recovery after Covid-19: Insights from an Agent Based Model,”
2021)
ter Ellen et al. (“Comparing behavioural heterogeneity across asset classes,” 2021)
Thiem et al. (“Global and Local Reduced Models for Interacting, Heterogeneous Agents,” 2021)
Vandin et al. (“Automated and Distributed Statistical Analysis of Economic Agent-Based Models,” 2021)
Westphal and Sornette (“How Market Intervention Can Prevent Bubbles and Crashes,” 2020)</p>
<h4>2.2.18 Validating scenarios and augmented datasets</h4>
<p>List of references:
Alaa et al. (“How Faithful is your Synthetic Data? Sample-level Metrics for Evaluating and Auditing Generative
Models,” 2022)
Bahrpeyma et al. (“A Methodology for Validating Diversity in Synthetic Time Series Generation,” 2021)
Cramer et al. (“Validation Methods for Energy Time Series Scenarios from Deep Generative Models,” 2021)
De Meer et al. (“Tackling the exponential scaling of signature-based GANs for high-dimensional financial time
series generation,” 2021)
Ding et al. (“Modeling Extreme Events in Time Series Prediction,” 2019)
Franco-Pedroso et al. (“The ETS challenges: a machine learning approach to the evaluation of simulated financial
time series for improving generation processes,” 2019)
Franco-Pedroso et al. (“Generating Virtual Scenarios of Multivariate Financial Data for Quantitative Trading
Applications,” 2019)
Istrate (“Models we Can Trust: Toward a Systematic Discipline of (Agent-Based) Model Interpretation and
Validation,” 2021)
Lawrence et al. (“Data Generating Process to Evaluate Causal Discovery Techniques for Time Series Data,”
2021)
Ni et al. (“Conditional Sig-Wasserstein GANs for Time Series Generation,” 2020)
Snow (“DataGene: A Framework for Dataset Similarity,” 2020)</p>
<h4>2.2.19 Software implementations and frameworks.</h4>
<p>List of references:
Foramitti (“AgentPy: A package for agent-based modeling in Python,” 2021)
Esmaeili et al. (“HAMLET: A Hierarchical Agent-based Machine Learning Platform,” 2021)
Harwick (“Helipad: A Framework for Agent-Based Modeling in Python,” 2021)
Hu et al. (“Multiple Imputation and Synthetic Data Generation with the R package NPBayesImputeCat,” 2021)
Jiang et al. (“A set of efficient methods to generate high-dimensional binary data with specified correlation
structures,” 2021)
Kang et al. (“GRATIS: GeneRAting TIme Series with diverse and controllable characteristics,” 2020)
Li et al. (“SynC: A Copula based Framework for Generating Synthetic Data from Aggregated Sources,” 2020)
Lin et al. (“Generating High-fidelity, Synthetic Time Series Datasets with DoppelGANger,” 2019)
Meyer and Nagler (“Synthia: multidimensional synthetic data generation in Python,” 2021)
Pesenti et al. (“Scenario weights for importance measurement (SWIM) - an R package for sensitivity analysis,”
2020)
Siebert et al. (“A systematic review of Python packages for time series analysis,” 2021)
Snow (“DeltaPy: A Framework for Tabular Data Augmentation in Python,” 2020)
Tadayon and Pottie (“tsBNgen: A Python Library to Generate Time Series Data from an Arbitrary Dynamic
Bayesian Network Structure,” 2020)
Vinod (“Constructing Scenarios of Time Heterogeneous Series for Stress Testing,” 2012)
Vinod (“R Package GeneralCorr Functions for Portfolio Choice,” 2021)</p>
<p>Wang et al. (“VEGA: Towards an End-to-End Configurable AutoML Pipeline,” 2020)</p>
<h2>3 Practical details for the project</h2>
<p>The main purpose of the project described in this document is to provide exposure to students on important (and
interesting) practical topics in quantitative wealth and investment management QWIM.
The level of complexity depends on the number of hours designated for the project. For example, 50-60 hours for
a regular project, and 100-120 hours for a thesis/capstone project. Upon request, the scope (and the corresponding
number if hours) of any given project can be extended.
The students would work on the project as part of a team (usually with 2-3 students).
All QWIM projects were selected such that the students’ efforts have a good chance of producing results relevant
to the industry, and at least as good as the results presented in the QWIM literature. Thus for each project we
may consider (on an optional basis, based primarily on students’ preference) to submit a corresponding article to
journals widely followed by practitioners and academics in investment and wealth management, with participating
students included as the leading coauthors of the submitted article.
The main challenge for each project is to identify the criteria for what would be considered <strong>“good enough</strong> ”.
Similar to projects in the industry, the meaning of “good enough” is based on a combination of comprehensive
literature review, discussions within team and with me (and/or my colleagues) and analysis of results. Emphasis is
placed on creating a narrative (with the aid of an interactive visualizer) for convincing the intended audience that
what was done in the project delivers <strong>“good enough</strong> ” outcome.</p>
<h3>3.1 Interaction with students</h3>
<p>For each project I would make myself available for meetings on a weekly basis (for discussions and guidance).
Some of my colleagues have also expressed interest to participate in such meetings. Due to our work schedule and
deliverables, most of the discussions will have to be scheduled outisde working hours (in weekends or evenings).
The meetings will take place through video conferencing such as WebEx, Zoom, Google Meet, Microsoft Teams,
etc., based on the team’s preference. If the meetings are through WebEx, I would provide a link, while the student
team will provide a link for any other video conferencing tool.
The students working on a given project can also send questions by email (my recommendation is to aggregate
the questions from team members into an email sent once a day). We aim to provide answers within 1-2 days, either
by email or through a phone discussion.</p>
<h3>3.2 Data.</h3>
<p>Due to compliance reasons all projects would be based on publicly available, non-proprietary and non-confidential
data (indices, ETFs, mutual funds, etc.). Since neither I nor my team are allowed to provide these datasets, I can
only provide a list of suggested datasets. This list is included in a later section named Practical Info.
The datasets were selected to have the following features:</p>
<ul>
<li>be good proxies for most representative asset and subasset classes</li>
<li>to be widely available</li>
<li>to be as liquid as possible</li>
<li>to have daily granularity</li>
<li>to encompass periods with as many market regimes as possibles (most proposed daily datasets are from 1990
    or 1991)</li>
<li>time series have “nicer” statistical properties compared to time series of, say, individual stocks or bonds</li>
</ul>
<h3>3.3 Private GitHub repository for the QWIM project.</h3>
<p>The team will create a private GitHub repository, which will store relevant project materials, including codes. The
team will use Git Desktop application as source control repository linked to the GitHub repository.</p>
<h3>3.4 Deliverables.</h3>
<p>The project deliverables include literature survey, numerical results, analysis and visualization. For each project
references will be provided for a comprehensive literature survey, and students are encouraged to identify additional
relevant literature. Regarding the implementation, the project will primarily use existing codes:</p>
<ul>
<li>Python and R packages from official repositories (PyPi for Python and CRAN for R)</li>
<li>machine learning platforms such as TensorFlow, PyTorch, CNTK, Chainer, mlr3, H20, PlaidML, mlpack, etc.</li>
<li>implementations of articles through codes available in repositories such as GitHub, BitBucket, GitLab, etc.
Visualization of data and results visualization will be interactive and it will be based on Shiny R framework; to
reduce programming effort, a template for such a Shiny visualizer will be provided in the team private GitHub
repository.
The deliverables are:</li>
<li>written report including literature survey and numerical results</li>
<li>interactive visualizer (most likely Shiny-based visualizer using R and Python packages)</li>
<li>(optional) presentation slides, and/or RMarkdown presentation, and/or Jupyter Notebook(s)</li>
</ul>
<h3>3.5 (Optional) Article submission to leading journals</h3>
<p>On an optional basis (based primarily on students’ preference), a version of the report can be prepared for submision
to leading journals such as Journal of Financial Data Science, Journal of Portfolio Management, Journal of Asset
Management, Journal of Investment Strategies, Quantitative Finance, Journal of Wealth Management, Journal of
Investing, Journal of Machine Learning in Finance, etc.</p>
<h2>4 Project tasks and timelines</h2>
<p>For each project the main tasks are:
1) literature review
2) decide on the appropriate metrics and quantitative methods within context of "good enough" for the project
3) write-up summary of literature review: methods, metrics, testing procedures
4) identification of Python and/or R packages which are most appropriate for the selected methods and metrics
5) code design to decide on main code components
6) implementation of code components
7) interactive visualization of numerical results
8) project report containing description of methods, metrics, and tests, and analysis of results.</p>
<h3>4.1 Suggested timelines for project tasks</h3>
<p>The table below suggests a timeline for the project tasks and the corresponding percentages of project time:</p>
<p><code>Table 1: Suggested timeline for project tasks
Task ID Task Name Percentage of project time
1 Literature review 15%
2 Identification of "good enough" metrics and quantitative methods 5%
3 Write-up of summary of literature review 5%
4 Identification of appropriate packages in Python and/or R 10%
5 Code design for main components of project coding framework 5%
6 Implementation of coding framework and components 40%
7 Interactive visualizer using the provided Shiny template 10%
8 Project report and presentation 10%</code></p>
<h3>4.2 Literature review.</h3>
<p>The first task is based on a comprehensive literature survey, included in the preliminary document of the project.
Students are encouraged to identify additional relevant literature.
This task may be the most important of the project, since it provides an overview of what was done, what works
well and less well, and what appear to be the most promising avenues to complete the project.
Emphasis is placed on information contained in the Main References; the other References would be considered
only if time permits and the team is interested in exploring other avenues.
When reading the literature, there are 4 main directions to consider:
1) methods
2) metrics to assess the performance/robustness of the methods
3) testing procedures
4) numerical results
The primary focus would be on the the references included in "Main References" subsection of the document for your
QWIM project. Then, to the extent there is time, to consider the other references included in the project document.
In the same time, you are encouraged to identify other references that might be considered "Main references", and
to share those references with me for discussion.
For the articles in Main References category, the suggested approach would be the following:</p>
<ul>
<li>For each article focus primarily on Abstract, Conclusion, and Numerical Results</li>
<li>Do this for all articles considered to be Main References, such that you gain a high-level understanding of
    what is currently done in the literature</li>
<li>Select the metrics that you may want to use in order to quantify the meaning of "good enough" for the project.</li>
<li>Select the quantitative methods which appear to be most likely to be "good enough" for the project.</li>
<li>Perform a "deeper dive" into the articles containing the approaches you consider the most promising,
For the articles which are not in "Main References" category, read Abstract, Conclusion, and Numerical Results, to
see whether any of those articles might need to be considered for inclusion in your summary.</li>
</ul>
<h3>4.3 Write-up summary of literature review.</h3>
<p>The write-up summary summarizes the methods, metrics, testing procedures, and numerical results identified during
the literature review. The write-up could also be incorporated within reports and/or presentations for the QWIM
project.</p>
<h3>4.4 Identification of appropriate Python and/or R packages</h3>
<p>Based on the literature review and on diiscussions, we identify the most potentially useful methods, metrics and
testing procedures. Then wee identify the most appropriate implementations of the selected methods and metrics.
The primary sources of implementatins are existing codes from:</p>
<ul>
<li>Python and R packages from official repositories (PyPi for Python and CRAN for R)</li>
<li>machine learning platforms such as TensorFlow, PyTorch, CNTK, Chainer, mlr3, H20, PlaidML, mlpack, etc.</li>
<li>Codes available in repositories such as GitHub, BitBucket, GitLab, etc.</li>
</ul>
<h3>4.5 Code design.</h3>
<p>An important task is to have a code design session to decide in advance on the main code components, which are
meant to be modular and encapsulated, such that the entire team can work on the codes.
Examples of such main components include extracting data, calculate metrics for the considered procedures,
portfolio metrics, performing tests, construct interactive visualizer, etc.
The code design procedure consists of:
1) visual display of major components of the coding framework
2) UML diagrams for each of the components.
The Appendix contains an illustrative example within context of a QWIM project on forecasting of financial
time series. The first figure shows the major components, while the second figure shows UML diagrams of those
components (the names of data members and methods are currently generic, and one would need to change them
to appropriate names)
While these figures were obtained through Microsoft Visio using a code design file (.vsd file), there are other
software tools (either online or installed locally) which can be used to create such code design diagrams. NOTE: if
you have access to Microsoft Visio and you want to use it for code design diagrams, you can ask me for the .vsd
file which was exported into the PDF from which I have extracted the snapshots.
List of software tools for code design diagrams, which are either free (open source) or have a free type of account</p>
<ul>
<li>Modelio (eitherdesktopversion oronlineversion)</li>
<li>LucidChart (online)</li>
<li>
<p>draw.io (eitherdesktopversion oronlineversion, now called app.diagrams.net)</p>
</li>
<li>
<p>Visual Paradigm (online)</p>
</li>
<li>UMLet (eitherdesktopor onlineversion)</li>
<li>Curated list of UML tools – 2019 edition</li>
<li>Top online UML modeling tools in 2019</li>
</ul>
<h3>4.6 Implementation of coding framework and components</h3>
<p>The implementation is done using identified packages or codes, in Python and/or R. The project will primarily use
existing codes:</p>
<ul>
<li>Python and R packages from official repositories (PyPi for Python and CRAN for R)</li>
<li>machine learning platforms such as TensorFlow, PyTorch, CNTK, Chainer, mlr3, H20, PlaidML, mlpack, etc.</li>
<li>implementations of articles through codes available in repositories such as GitHub, BitBucket, GitLab, etc.</li>
</ul>
<h3>4.7 Interactive visualizer.</h3>
<p>While visualization of data and numerical results can be done through various tools (including Jupyter notebooks
or Dash in Python), my recommendation is to consider an interactive visualizer based on Shiny framework in R.
A template for the Shiny visualizer will be provided in the private GitHub repository set up by the team for the
project.
Some information about Shiny:</p>
<ul>
<li>Shiny from RStudio: tutorialsand gallery</li>
<li>Why R Shiny Trumps UI and JavaScript Based Visualization Tools</li>
<li>Shiny’s Holy Grail: Interactivity with reproducibility</li>
</ul>
<h3>4.8 Project report and presentation.</h3>
<p>The report containing description of methods, metrics, and tests, and analysis of results.
While the report can be written using various tools (including Microsoft Word), my recommendation is to use
LyX to write both the project report and the project presentation. Two LyX templates for creating reports and,
respectively, presentations will be provided in the private GitHub repository set up by the team for the project.
Some information about Shiny:</p>
<ul>
<li>LyX features</li>
<li>LyX tutorialwith PDFhere</li>
<li>LyX Tutorial videoPart Oneand Part Two</li>
<li>LyX tutorial videoPart Oneand Part Twoand Part Threeand Part Four</li>
<li>Introduction to LyX</li>
<li>Insert figures in LyX</li>
<li>Essentials of LyX</li>
</ul>
<h2>5 Design and implementation for the project codes</h2>
<p>This section describes a possible approach for the design process and for the implementation (folder structure) of
the project. This approach is presented only to exemplify how it could be done. Each student team has freedom to
consider their own design process.
Design and implementation would be based on following principles:</p>
<ul>
<li>coding framework is Python based, with calls to functions available in existing Python and R packages</li>
<li>leverage common components (such as data input/output, numerical methods, time series, testing, interactive
    visualization and reporting, etc.)</li>
<li>reusability</li>
<li>incorporate best practices in coding and numerical implementations</li>
<li>use, augment and enhance (to largest extent possible) existing Python and R packages and codes</li>
</ul>
<h3>5.1 Visualize project workflow and coding framework.</h3>
<p>The starting point is to visualize the project workflow in terms of major components, and then to design the code
framework.
The code design procedure consists of:
1) visual display of major components of the coding framework
2) UML diagrams for each of the components.
We present examples below for projects including time series forecasting and analysis, machine learning for portfolio
construction, etc.</p>
<p><code>Figure 1: Examples of architecture of coding framework: AlphaPy</code>
Source:AlphaPy</p>
<p><code>Figure 2: Examples of architecture of coding framework: Greykite</code>
Source:Geykite</p>
<p><code>Figure 3: QLib Framework</code>
<code>Trading Agent</code>
<code>Meta Controller</code>
<code>Analyser</code>
<code>Decision</code>
<code>Forecast Model</code>
<code>Interface</code>
<code>Multi-level Workflow</code>
<code>Infrastracture</code>
<code>Forecasting...Portfolio A...Execution...</code>
<code>Information Extractor</code>
<code>Online Serving</code>
<code>Graph Event</code>
<code>Factor Text
Alpha Risk</code>
<code>Data Server
local remote</code>
<code>Trainer
Algorithms Auto-ML</code>
<code>Model Manager
ModelsModelModel Decision GeneratorsModelModel</code>
<code>Model Interpreter</code>
<code>Decision Generator
Order executi...</code>
<code>Execution Results</code>
<code>Execution Env
VWAP/Close/......Sub-workfl...</code>
<code>Highly Customiz...
Module in devel...</code>
<code>Explanation</code>
<code>Sub-workflow(1) (E.g. High-frequ...
Execution E...
...</code>
<code>(1) The sub-workflow will make more fine-grained decisions according to the decision from the upper-level trading agent</code>
<code>Asset allocat...Stock selecti...</code>
<code>Trading...</code>
<code>Viewer does not support full SVG 1.1</code></p>
<p>Figure 4: Examples of major components of coding framework (top) and UML diagrams (bottom)</p>
<p><code>Figure 5: Financial Machine Learning in Portfolio Construction</code>
Source:Machine Learning in Asset Management^27</p>
<h3>5.2 Representative examples of Python libraries with well designed folder structure</h3>
<p>List of Python libraries</p>
<ul>
<li>QLib is a AI-oriented quantitative investment platform in Python developed by Microsoft researchers</li>
<li>GluonTSis a Python library deveoped by Amazon researchers for probabilistic time series modeling</li>
<li>sktimeis a unified framework for machine learning with time series, developed by researchers at Alan Turing
    Institute for data science and artificial intelligence.</li>
<li>darts is a Python library for easy manipulation and forecasting of time series, developed by researchers at
    Unit8 AI and data analytics company.</li>
<li>Kats is a Python library developed by Facebook researchers to analyze time series data.</li>
<li>Kats is a Python library developed by Tinkoff AI researchers to analyze time series data.</li>
<li>MLFinLab(Machine Learning Financial Laboratory) is a Python library developed by researchers at Hudson
    &amp; Thames.</li>
</ul>
<h2>6 Practical Info</h2>
<h3>6.1 Recommended software tools</h3>
<p>The sections below describe the recommended software tools, including corresponding versions/subversions, tutorials
and details</p>
<h4>6.1.1 Python</h4>
<p>The recommended versions are:</p>
<ul>
<li>Python version 3.8 (subversion Python 3.8.10 or 3.8.15)</li>
<li>Python version 3.9 (subversion Python 3.9.10 or 3.9.15)</li>
<li>Python version 3.10 (latest subversion, currently Python 3.10.8)
There are also relevant Python packages, identified while you are working the project. As a starting point you can
consider the packages included in section on Potentially useful Python and R packages.</li>
</ul>
<h4>6.1.2 R.</h4>
<p>The recommended versions are:</p>
<ul>
<li>R version 4.2 (recommended is latest subversion, currently R 4.2.2)</li>
<li>R version 3.6 (subversion R 3.6.3)
On Windows computers you also need to installRtoolsto build R packages from source through compilation, since
not all packages have associated Windows binaries.
There are also relevant R packages, identified while you are working the project. As a starting point you can
consider the packages included in section on Potentially useful Python and R packages.</li>
</ul>
<h4>6.1.3 R IDE.</h4>
<p>The recommended R IDE is RStudio Desktop Open Source</p>
<ul>
<li>latest version, currently 2022.07.2+576</li>
</ul>
<h4>6.1.4 Python IDE.</h4>
<p>The recommended Python IDE is Visual Studio Code VSC</p>
<ul>
<li>latest version, currently VSC 1.73
Then add Python extension and other Visual Studio Code extensions from Visual Studio MarketPlace.
Note: Upon request I can provide a list of potentially useful VSC extensions, which can be installed on your
computer (see for examplelink)</li>
</ul>
<h4>6.1.5 Bibliography Manager</h4>
<p>The recomemnded bibliography manager isJabRef</p>
<ul>
<li>latest version: version 5.7, or</li>
<li>latest development version fromlink</li>
</ul>
<p>I can provide you with a bibliography file which contains all refeernces mentioned in the project description, This
file (of extension bib) can be viewed and edited with JabRef, and used together with LyX to write your project
related documents (report, presentation, etc.).
You can easily add/delete/edit this bib file using JabRef.
There are video tutorials on using JabRef:link 1 , link 2 , link 3.
In addition to these video tutorials, I can also have a video online session, to provide an overview and answer
your questions on using LyX and JabRef. This online session (through Google Meet Google Meet) can be recorded
and shared with you afterwards.</p>
<h4>6.1.6 Document processor</h4>
<p>The recommended document processor isLyX, which is a document processor that encourages an approach to
writing based on the structure of your documents (WYSIWYM) and not simply their appearance (WYSIWYG).
LyX combines the power and flexibility of TeX/LaTeX with the ease of use of a graphical interface. It shoudl
be emohasized that you do not need to know/learn LaTeX in order to tuse LyX.
To install LyX, you need to download and install first TeXLive (seelink), which is a packaged distribution of
LaTeX and associated packages
Then install LyX usinginstallers, making sure that you are pointing to location of installed TeXLive when asked
for a LaTeX distribution during the run of LyX installer.
Recommended versions:</p>
<ul>
<li>TexLive (recommended is latest version, currently TeXLive 2022)</li>
<li>LyX (recommended is latest subversion, currently LyX 2.3.6.1)
There are video tutorials (link 1and link 2 ).
In addition to these video tutorials, I can also have a video online session, to provide an overview and answer
your questions on using LyX and JabRef. This online session (through Google Meet Google Meet) can be recorded
and shared with you afterwards.</li>
</ul>
<h4>6.1.7 Source control manager</h4>
<p>The recommended source control manager isGitHub desktop, which can be used in conjunction with thr private
GitHub repository that each student team will create for their project</p>
<ul>
<li>latest subversion, currently GitHub Desktop 3.1.2</li>
</ul>
<h4>6.1.8 File editor.</h4>
<p>The recommended file editor isNotepad++</p>
<ul>
<li>latest subversion (currently Notepad++ 8.4.7) with various plugins (see list of available plugins atlink 1and
    link 2 )</li>
</ul>
<h4>6.1.9 Runtime libraries.</h4>
<p>Many Python and R packages require runtime libraries such asMicrosoft Visual C++ Redistributable</p>
<ul>
<li>latest version, currently Microsoft Visual C++ Redistributable 64-bit for Visual Studio 2015, 2017, 2019, and
    2022</li>
</ul>
<h3>6.2 Recommended datasets</h3>
<p>The datasets below were selected to have the following features:</p>
<ul>
<li>to be representative proxies for most relevant asset and subasset classes</li>
<li>
<p>to be widely available</p>
</li>
<li>
<p>to be as liquid as possible</p>
</li>
<li>to have daily granularity</li>
<li>to encompass time periods containing as many market regimes as possibles (under this consideration, the
    recommended daily datasets start from early 1990s)</li>
<li>to have “nicer” statistical properties, which will make modeling easier (under this consideration, time series of
    recommended financial indices have “nicer” statistical properties compared to time series of individual stocks
    or bonds)
The following datasets are suggested</li>
</ul>
<p><code>Table 2: Daily data sets
Name Description Name Description
BCOMTR Bloomberg Commodity Index Total
Return</code>
<code>RU20VATR iShares Russell 2000 Value ETF
HFRIFWI HFRI Fund Weighted Composite Index RUMCINTR iShares Russell Mid-Cap ETF
LBUSTRUU Bloomberg Barclays US Aggregate Bond
Index</code>
<code>RUMRINTR iShares Micro-Cap ETF
LG30TRUU Bloomberg Barclays Global High Yield
Total Return Index Value Unhedge</code>
<code>RUTPINTR iShares Russell Top 200 ETF
LMBITR Bloomberg Barclays Municipal Bond
Index Total Return Index Value
Unhedged USD</code>
<code>S5COND S&amp;P 500 Consumer Discretionary Index</code>
<code>NDDUE15X Amundi MSCI Europe Ex UK Ucits ETF
Dr</code>
<code>S5CONS S&amp;P 500 Consumer Staples Index
NDDUJN MSCI Japan Index S5ENRS S&amp;P 500 Energy Index
NDDUNA iShares MSCI North America UCITS
ETF</code>
<code>S5FINL S&amp;P 500 Financials Sector GICS Level 1
Index
NDDUPXJ MSCI Pacific ex Japan UCITS ETF S5HLTH S&amp;P 500 Health Care Index
NDDUUK iShares MSCI UK ETF S5INDU S&amp;P 500 Industrials Index
NDDUWXUS MSCI World ex USA total net return S5INFT S&amp;P 500 Information Technology Index
NDUEEGF SPDR MSCI Emerging Markets UCITS
ETF</code>
<code>S5MATR S&amp;P 500 Materials Index
RU10GRTR iShares Russell 1000 Growth ETF S5RLST S&amp;P 500 Real Estate Index
RU10VATR  iShares Russell 1000 Value ETF S5TELS S&amp;P 500 Communication Services Index
RU20GRTR  iShares Russell 2000 Growth ETF S5UTIL S&amp;P 500 Utilities Index
RU20INTR Russell 2000 Total Return SPXT Proshares S&amp;P 500 EX Technology ETF</code></p>
<p>Table 3: Monthly data sets
Name Description Name Description
IBXXSHY1 iShares 0-5 Year High Yield Corporate
Bond ETF</p>
<p><code>M2USEV MSCI USA Enhanced Value Index</code>
IDCT20RT ICE U.S. Treasury 20+ Year Bond Total
Return Index</p>
<p><code>M2USRWGT MSCI USA Risk Weighted Index</code>
LBUSTRUU Bloomberg Barclays US Agg Total Return
Value Unhedged USD</p>
<p><code>M2USSNQ MSCI USA Sector Neutral Quality Index</code>
LC07TRUU Bloomberg Barclays U.S. Universal Total
Return Index Value Unhedged</p>
<p><code>MID S&amp;P 400 Mid Cap Index index</code>
LD01TRUU Bloomberg Barclays 1-3 Yr Credit Total
Return Index Value Unhedged US</p>
<p><code>MXEA MSCI EAFE Index</code>
LT01TRUU Bloomberg Barclays US Treasury 1-3
Year Index</p>
<p><code>MXEF MSCI Emerging Markets Index</code>
LUICTRUU Bloomberg Barclays U.S. Intermediate
Credit Total Return Index</p>
<p><code>MXUSMVOL MSCI USA Minimum Volatility Index</code>
LULCTRUU Bloomberg Barclays U.S. Long Credit
Index</p>
<p><code>MXWD MSCI All Countries World Index</code>
M1CXBRU iShares Core MSCI International
Developed Markets ETF</p>
<p><code>MXWOUIM MSCI All Countries World Index</code>
M1USMVOL MSCI USA Minimum Volatility (USD)
Index</p>
<p>NDDUUS MSCI Daily Total Return Net USA USD
Index
M2US000$ iShares Edge MSCI USA Momentum
Factor ETF</p>
<p><code>SPX S&amp;P 500 Index</code></p>
<h2>7 Potentially useful Python and R software implementations: packages, codes and frameworks</h2>
<h2>ages, codes and frameworks</h2>
<h3>7.1 Collections and repositories of resources</h3>
<p><strong>For Data Science, Numerical Methods/ Algorithms, Programming</strong>
List of links:</p>
<ul>
<li>Data Science CheatSheet</li>
<li>professional-programming: collection of full-stack resources for programmers.</li>
</ul>
<p><strong>For Python</strong>
List of links:</p>
<ul>
<li>Awesome Python</li>
<li>Awesome Python frameworks, libraries, software and resources</li>
<li>Best of Python</li>
<li>Curated list of Python frameworks, libraries, software and resources</li>
<li>Pythonidae: Curated decibans of scientific programming resources in Python</li>
<li>Ranked list of Python open-source Machine Learning libraries and tools</li>
<li>Ranked list of Python open-source libraries and tools</li>
<li>Ranked list of Python developer tools and libraries</li>
<li>Time series: analytics, statistics, machine learning, frameworks and databases</li>
<li>Time series Python packages</li>
</ul>
<p><strong>For R</strong>
List of links:</p>
<ul>
<li>Available CRAN Packages By Date of Publication</li>
<li>CRAN Task Views</li>
</ul>
<h3>7.2 Connection between Python and R codes</h3>
<p>List of links:</p>
<ul>
<li>arrow: R interface to ’Apache’ ’Arrow’, a cross-language for accelerated data interchange in-memory data</li>
<li>pyarrow: Python library for Apache Arrow</li>
<li>reticulate: R Interface to ’Python’ modules, classes, and functions</li>
<li>rpy2: Python interface to the R language</li>
<li>rpy2-arrow: Share Apache Arrow datasets between Python and R</li>
<li>R Extension for Visual Studio Code</li>
</ul>
<h3>7.3 Anomaly detection and data outliers</h3>
<p><strong>Collections of resources</strong>
List of links:</p>
<ul>
<li>Anomaly detection related books, papers, videos, and toolboxes</li>
</ul>
<p><strong>Python software implementations</strong>
List of packages and/or codes and/or frameworks and/or links:</p>
<ul>
<li>adtk: Python toolkit for rule-based/unsupervised anomaly detection in time series</li>
<li>Anomaly Detection Learning Resources</li>
<li>Awesome anomaly detection resources</li>
<li>Curve: time series data anomaly detection by Baidu</li>
<li>kats: kit to analyze time series data by Facebook</li>
<li>luminaire: ML driven package by Zillow for monitoring time series data</li>
<li>Merlion: A Machine Learning Framework for Time Series Intelligence by SalesForce</li>
<li>PyGOD: Graph Outlier Detection (Anomaly Detection)</li>
<li>PyOD: Python Toolbox for Scalable Outlier Detection (Anomaly Detection)</li>
<li>PyODDS: An End-to-end Outlier Detection System</li>
<li>ruptures: change point detection in Python</li>
<li>seriesdistancematrix: implements the Series Distance Matrix framework, a flexible component-based frame-
    work that bundles various Matrix Profile related techniques</li>
<li>Software tools and datasets for anomaly detection on time series data</li>
<li>Tools and datasets for anomaly detection on time-series data.</li>
<li>tsad: Time Series Forecasting and Anomaly Detection</li>
<li>TODS: An Automated Time-series Outlier Detection System</li>
<li>tsmoothie: time-series smoothing and outlier detection</li>
</ul>
<p><strong>R software implementations</strong>
List of packages and/or codes and/or frameworks and/or links:</p>
<ul>
<li>amelie: Anomaly Detection with Normal Probability Functions</li>
<li>ANN2: Artificial Neural Networks for Anomaly Detection</li>
<li>anomaly: Detecting Anomalies in Data</li>
<li>AnomalyDetection: package by Twitter to detect anomalies</li>
<li>anomalize: Tidy Anomaly Detection</li>
<li>composits: Compositional, Multivariate and Univariate Time Series Outlier Ensemble</li>
<li>
<p>dobin: Dimension Reduction for Outlier Detection</p>
</li>
<li>
<p>dsos: Dataset Shift with Outlier Scores</p>
</li>
<li>HDoutliers: Leland Wilkinson’s Algorithm for Detecting Multidimensional Outliers</li>
<li>isotree: Isolation-Based Outlier Detection</li>
<li>kssa: automatically identify and validate the best method for missing data imputation in a time series</li>
<li>lookout: Leave One Out Kernel Density Estimates for Outlier Detection</li>
<li>mvoutlier: Multivariate Outlier Detection Based on Robust Methods</li>
<li>odetector: Outlier Detection Using Partitioning Clustering Algorithms</li>
<li>otsad: Online Time Series Anomaly Detectors</li>
<li>outForest: Multivariate Outlier Detection and Replacement</li>
<li>outliers: Tests for Outliers</li>
<li>outliertree: Explainable Outlier Detection Through Decision Tree Conditioning</li>
<li>stray: Anomaly Detection in High Dimensional and Temporal Data</li>
<li>TagAnomaly: Anomaly detection analysis and labeling tool by Microsoft</li>
<li>trendsegmentR: Linear Trend Segmentation and Point Anomaly Detection</li>
<li>tsoutliers: Detection of Outliers in Time Series</li>
<li>univOutl: Detection of Univariate Outliers</li>
</ul>
<h3>7.4 Bayesian analysis and modeling.</h3>
<p><strong>Python software implementations</strong>
List of packages and/or codes and/or frameworks and/or links:</p>
<ul>
<li>ArviZ: Exploratory analysis of Bayesian models with Python</li>
<li>baal: enable Bayesian active learning in your research or labeling work</li>
<li>bambi: BAyesian Model-Building Interface (Bambi)</li>
<li>bilby: Bayesian inference library</li>
<li>BayesianOptimization: implementation of global optimization with gaussian processes</li>
<li>BayesTSA: ayesian methods for solving estimation and forecasting problems in time series analysis</li>
<li>BoTorch: Bayesian optimization in PyTorch</li>
<li>Bumps: data fitting and uncertainty estimation</li>
<li>nutpie: A fast sampler for bayesian posteriors</li>
<li>Orbit: Bayesian forecasting package by Uber</li>
<li>PyApprox: high-dimensional approximation and uncertainty quantification</li>
<li>pyMC: Bayesian Modeling and Probabilistic Machine Learning with Aesara</li>
<li>PyStan: Python interface to Stan, a platform for statistical modeling</li>
<li>zeus: Lightning Fast MCMC</li>
</ul>
<p><strong>R software implementations</strong>
List of packages and/or codes and/or frameworks and/or links:</p>
<ul>
<li>ashr: Methods for Adaptive Shrinkage, using Empirical Bayes</li>
<li>bain: Bayes Factors for Informative Hypotheses (equality, inequality, and about equality constrained hypothe-
    ses)</li>
<li>bamp: Bayesian Age-Period-Cohort Modeling and Prediction</li>
<li>bsamGP: Bayesian Spectral Analysis Models using Gaussian Process Priors</li>
<li>bayesdfa: Bayesian Dynamic Factor Analysis (DFA) with ’Stan’</li>
<li>bayefdr: Bayesian Estimation and Optimisation of Expected False Discovery Rate</li>
<li>BayesFM: Bayesian Inference for Factor Modeling</li>
<li>bayesforecast: Bayesian Time Series Modeling with Stan</li>
<li>BayesHMM: Full Bayesian Inference for Hidden Markov Models</li>
<li>bayesian: Bindings for Bayesian TidyModels</li>
<li>bayesmodels: The ’Tidymodels’ Extension for Bayesian Models</li>
<li>bayesplot: Plotting for Bayesian Models</li>
<li>BayesPostEst: Generate Postestimation Quantities for Bayesian MCMC Estimation</li>
<li>bayestestR: Understand and Describe Bayesian Models and Posterior Distributions</li>
<li>BayesTools: Tools for Bayesian Analyses</li>
<li>BayesVarSel: Bayes Factors, Model Choice and Variable Selection in Linear Models</li>
<li>BEST: Bayesian Estimation Supersedes the t-Test</li>
<li>beyondWhittle: Bayesian Spectral Inference for Stationary Time Series</li>
<li>BFpack: Flexible Bayes Factor Testing of Scientific Expectations</li>
<li>BMAmevt: Multivariate Extremes: Bayesian Estimation of the Spectral Measure</li>
<li>bmixture: Bayesian Estimation for Finite Mixture of Distributions</li>
<li>bnmonitor: An Implementation of Sensitivity Analysis in Bayesian Networks</li>
<li>BNPmix: Bayesian Nonparametric Mixture Models</li>
<li>bpcs: Bayesian Paired Comparison Analysis with Stan</li>
<li>bpgmm: Bayesian Model Selection Approach for Parsimonious Gaussian Mixture Models</li>
<li>brms: Bayesian Regression Models using ’Stan’</li>
<li>BSL: Bayesian Synthetic Likelihood</li>
<li>bspec: Bayesian Spectral Inference</li>
<li>bsvars: Bayesian Estimation of Structural Vector Autoregressive Models</li>
<li>dalmatian: Automating the Fitting of Double Linear Mixed Models in ’JAGS’ and ’nimble’</li>
<li>
<p>dbnR: Dynamic Bayesian Network Learning and Inference</p>
</li>
<li>
<p>DEBBI: Differential Evolution-Based Bayesian Inference</p>
</li>
<li>ensembleBMA: Probabilistic Forecasting using Ensembles and Bayesian Model Averaging</li>
<li>fbst: The Full Bayesian Evidence Test, Full Bayesian Significance Test and the e-Value</li>
<li>greta: scalable statistical modelling in R</li>
<li>LaplacesDemon: Complete Environment for Bayesian Inference</li>
<li>mBvs: Bayesian Variable Selection Methods for Multivariate Data</li>
<li>mlr3mbo: Flexible Bayesian Optimization</li>
<li>mombf: Bayesian Model Selection and Averaging for Non-Local and Local Priors</li>
<li>networkABC: Network Reverse Engineering with Approximate Bayesian Computation</li>
<li>nimble: MCMC, Particle Filtering, and Programmable Hierarchical Modeling</li>
<li>Nmix: Bayesian Inference on Univariate Normal Mixtures</li>
<li>posterior: Tools for Working with Posterior Distributions</li>
<li>rBayesianOptimization: Bayesian Optimization of Hyperparameters</li>
<li>Rbeast: Bayesian Change-Point Detection and Time Series Decomposition</li>
<li>REBayes: Empirical Bayes Estimation and Inference</li>
<li>Revticulate: Interaction with ”RevBayes” in R</li>
<li>rstan: R Interface to Stan</li>
<li>rstanarm: Bayesian Applied Regression Modeling via Stan</li>
<li>SequenceSpikeSlab: Exact Bayesian Model Selection Methods for the Sparse Normal Sequence Model</li>
<li>shrinkTVP: Efficient Bayesian Inference for Time-Varying Parameter Models with Shrinkage</li>
<li>tidybayes: Tidy Data and ’Geoms’ for Bayesian Models</li>
</ul>
<h3>7.5 Causality, inference and dependencies</h3>
<p><strong>Python software implementations</strong>
List of packages and/or codes and/or frameworks and/or links:</p>
<ul>
<li>bilby: Bayesian inference library</li>
<li>CausalDiscoveryToolbox: causal inference in graphs and in the pairwise settings</li>
<li>causality: Tools for causal analysis</li>
<li>causalml: package by Uber for Uplift modeling and causal inference with machine learning algorithms</li>
<li>copulae: Multivariate data modelling with Copulas</li>
<li>DoWhy: library by Microsoft for causal inference that supports explicit modeling and testing of causal as-
    sumptions</li>
<li>HiDimStat: High-dimensional statistical inference tool</li>
<li>tigramite: time series analysis python module for causal discovery</li>
</ul>
<p><strong>R software implementations</strong>
List of packages and/or codes and/or frameworks and/or links:</p>
<ul>
<li>causal.decomp: Causal Decomposition Analysis</li>
<li>CausalImpact: toolkit by Google to infer Causal Effects using Bayesian Structural Time-Series Models</li>
<li>causaloptim: An Interface to Specify Causal Graphs and Compute Bounds on Causal Effects</li>
<li>copula: Multivariate Dependence with Copulas</li>
<li>dCovTS: Distance Covariance and Correlation for Time Series Analysis</li>
<li>estimatr: Fast Estimators for Design-Based Inference</li>
<li>flipr: Flexible Inference via Permutations in R</li>
<li>generalCorr: Generalized Correlations, Causal Paths and Portfolio Selection</li>
<li>HellCor: The Hellinger Correlation</li>
<li>infer: Tidy Statistical Inference</li>
<li>jackstraw: Statistical Inference for Unsupervised Learning</li>
<li>konfound: Quantify the Robustness of Causal Inferences</li>
<li>mashr: Multivariate Adaptive Shrinkage</li>
<li>multivariance: Measuring Multivariate Dependence Using Distance Multivariance</li>
<li>NlinTS: Models for Non Linear Causality Detection in Time Series</li>
<li>NNS: Nonlinear nonparametric statistics using partial moments</li>
<li>pcalg: Methods for Graphical Models and Causal Inference</li>
<li>qmd: Quantification of Multivariate Dependence</li>
<li>rmcfs: The MCFS-ID Algorithm for Feature Selection and Interdependency Discovery</li>
<li>sherlock: package by Netflix for causal machine learning for segment discovery and analysis</li>
<li>SIHR: Statistical Inference in High Dimensional Regression</li>
<li>tlverse: One Stop to Targeted Learning in R</li>
<li>tscopula: Time Series Copula Models</li>
<li>VLTimeCausality: Variable-Lag Time Series Causality Inference Framework</li>
</ul>
<h3>7.6 Classification, Motifs, Neighbors, Wavelets, Transforms.</h3>
<p><strong>Python software implementations</strong>
List of packages and/or codes and/or frameworks and/or links:</p>
<ul>
<li>abess: Fast Best-Subset Selection Library</li>
<li>catboost: Gradient Boosting on Decision Trees by Yandex</li>
<li>
<p>HiClass: hierarchical classification compatible with scikit-learn</p>
</li>
<li>
<p>LightGBM: fast, distributed, high performance gradient boosting (GBT, GBDT, GBRT, GBM or MART)
    framework by Microsoft</p>
</li>
<li>Local Cascade Ensemble (LCE) is a high-performing, scalable and user-friendly machine learning method for
    the general tasks of Classification and Regression</li>
<li>matrixprofile: time series data mining tasks, utilizing matrix profile algorithms</li>
<li>pyts: time series classification</li>
<li>scikit-learn: machine learning in Python</li>
<li>seriesdistancematrix: implements the Series Distance Matrix framework, a flexible component-based frame-
    work that bundles various Matrix Profile related techniques</li>
<li>sktime: unified framework for machine learning with time series</li>
<li>stumpy: modern time series analysis</li>
<li>tslearn: machine learning toolkit dedicated to time-series data</li>
</ul>
<p><strong>R software implementations</strong>
List of packages and/or codes and/or frameworks and/or links:</p>
<ul>
<li>abess: Fast Best-Subset Selection Library</li>
<li>AUC: Threshold Independent Performance Measures for Probabilistic Classifiers</li>
<li>bcTSNE: Projected t-SNE for Batch Correction</li>
<li>biwavelet: Conduct Univariate and Bivariate Wavelet Analyses</li>
<li>caret: Classification and Regression Training</li>
<li>classmap: Visualizing Classification Results</li>
<li>classifly: Explore Classification Models in High Dimensions</li>
<li>ContaminatedMixt: Clustering and Classification with the Contaminated Normal</li>
<li>CORElearn: Classification, Regression and Feature Evaluation</li>
<li>cvms: Cross-Validation for Model Selection</li>
<li>ddalpha: Depth-Based Classification and Calculation of Data Depth</li>
<li>dtw: Dynamic Time Warping Algorithms</li>
<li>greed: Clustering and Model Selection with the Integrated Classification Likelihood</li>
<li>ipred: Improved Predictors</li>
<li>klaR: Classification and Visualization</li>
<li>matrixProfile: Matrix Profile</li>
<li>matrixprofiler: Matrix Profile for R</li>
<li>mclust: Gaussian Mixture Modelling for Model-Based Clustering, Classification, and Density Estimation</li>
<li>MixGHD: Model Based Clustering, Classification and Discriminant Analysis Using the Mixture of Generalized
    Hyperbolic Distributions</li>
<li>
<p>MixMatrix: Classification with Matrix Variate Normal and t Distributions</p>
</li>
<li>
<p>mixSPE: Mixtures of Power Exponential and Skew Power Exponential Distributions for Use in Model-Based
    Clustering and Classification</p>
</li>
<li>mixture: Mixture Models for Clustering and Classification</li>
<li>randomUniformForest: Random Uniform Forests for Classification, Regression and Unsupervised Learning</li>
<li>rbooster: AdaBoost Framework for Any Classifier</li>
<li>rebmix: Finite Mixture Modeling, Clustering &amp; Classification</li>
<li>regtools: Regression and Classification Tools</li>
<li>Rmixmod: Classification with Mixture Modelling</li>
<li>RSSL: Implementations of Semi-Supervised Learning Approaches for Classification</li>
<li>Rtsne: T-Distributed Stochastic Neighbor Embedding using a Barnes-Hut Implementation</li>
<li>sbfc: Selective Bayesian Forest Classifier</li>
<li>SKNN: A Super K-Nearest Neighbor (SKNN) Classification Algorithm</li>
<li>stacks: Tidy Model Stacking</li>
<li>TSMining: Mining Univariate and Multivariate Motifs in Time-Series Data</li>
<li>tsmp: Time Series with Matrix Profile</li>
<li>yardstick: Tidy Characterizations of Model Performance</li>
</ul>
<h3>7.7 Clustering.</h3>
<p><strong>Python software implementations</strong>
List of packages and/or codes and/or frameworks and/or links:</p>
<ul>
<li>cclust: Convex Clustering Methods and Clustering Indexes</li>
<li>ChronoClust: perform clustering on each of a time-series of discrete datasets, and explicitly track the evolution
    of clusters over time</li>
<li>classix: Fast and explainable clustering based on sorting</li>
<li>ClusterEnsembles: package for cluster ensembles</li>
<li>clustergram: Visualization and diagnostics for cluster analysis in Python</li>
<li>Clusteval: methods for unsupervised cluster validation</li>
<li>deeptime: analysis of time series data including dimensionality reduction, clustering, and Markov model
    estimation</li>
<li>dtaidistance: Time series distances: Dynamic Time Warping</li>
<li>DTCR: Learning Representations for Time Series Clustering</li>
<li>DTW_kmedoids: Multivariate time series clustering using Dynamic Time Warping (DTW) and k-mediods</li>
<li>ETNA Time Series Library by Tinkoff AI</li>
<li>faiss: efficient similarity search and clustering of dense vectors</li>
<li>
<p>fastcluster: Fast hierarchical clustering routines</p>
</li>
<li>
<p>genieclust: Fast and Robust Hierarchical Clustering with Noise Point Detection</p>
</li>
<li>hcluster: Hierarchical Clustering Algorithms</li>
<li>hdbscan: high performance implementation of HDBSCAN clustering</li>
<li>scikit-learn: machine learning in Python</li>
<li>TimeSeriesDeepClustering: End-to-end deep representation learning for time series clustering</li>
<li>tslearn: machine learning toolkit dedicated to time-series data</li>
<li>validclust: Validate clustering results</li>
</ul>
<p><strong>R software implementations</strong>
List of packages and/or codes and/or frameworks and/or links:</p>
<ul>
<li>apcluster: Affinity Propagation Clustering</li>
<li>bahc: bahc: Filter Covariance and Correlation Matrices with Bootstrapped-Averaged Hierarchical Ansatz</li>
<li>bootcluster: Bootstrapping Estimates of Clustering Stability</li>
<li>cclust: Convex Clustering Methods and Clustering Indexes</li>
<li>clue: Cluster Ensembles</li>
<li>clusrank: Wilcoxon Rank Tests for Clustered Data</li>
<li>clustAnalytics: Cluster Evaluation on Graphs</li>
<li>ClustAssess: Tools for Assessing Clustering</li>
<li>ClustBlock: Hierarchical and partitioning algorithms of blocks of variables</li>
<li>cluster: ”Finding Groups in Data”: Cluster Analysis Extended Rousseeuw et al.</li>
<li>clusterability: Performs Tests for Cluster Tendency of a Data Set</li>
<li>ClusterBootstrap: Analyze Clustered Data with Generalized Linear Models using the Cluster Bootstrap</li>
<li>Clustering: Techniques for Evaluating Clustering</li>
<li>clusterSEs: Calculate Cluster-Robust p-Values and Confidence Intervals</li>
<li>ClusterR: Gaussian Mixture Models, K-Means, Mini-Batch-Kmeans, K-Medoids and Affinity Propagation
    Clustering</li>
<li>clusterSim: Searching for Optimal Clustering Procedure for a Data Set</li>
<li>clustrd: Methods for Joint Dimension Reduction and Clustering</li>
<li>clustree: Visualise Clusterings at Different Resolutions</li>
<li>clValid: Validation of Clustering Results</li>
<li>cmbClust: Conditional Mixture Modeling and Model-Based Clustering</li>
<li>Ckmeans.1d.dp: Optimal, Fast, and Reproducible Univariate Clustering</li>
<li>diceR: Diverse Cluster Ensemble in R</li>
<li>
<p>dtwclust: Time Series Clustering Along with Optimizations for the Dynamic Time Warping Distance</p>
</li>
<li>
<p>evclust: Evidential Clustering</p>
</li>
<li>fastcluster: Fast Hierarchical Clustering Routines for R and ’Python’</li>
<li>fastkmedoids: Faster K-Medoids Clustering Algorithms: FastPAM, FastCLARA, FastCLARANS</li>
<li>FCPS: Fundamental Clustering Problems Suite</li>
<li>flexclust: Flexible Cluster Algorithms</li>
<li>fpc: Flexible Procedures for Clustering</li>
<li>genie: Fast, Robust, and Outlier Resistant Hierarchical Clustering</li>
<li>genieclust: The Genie++ Hierarchical Clustering Algorithm with Noise Points Detection</li>
<li>heatmaply: Interactive Cluster Heat Maps Using ’plotly’ and ’ggplot2’</li>
<li>HierPortfolios: Hierarchical Clustering-Based Portfolio Allocation Strategies</li>
<li>htestClust: Reweighted Marginal Hypothesis Tests for Clustered Data</li>
<li>kselection: Selection of K in K-Means Clustering</li>
<li>l1spectral: An L1-Version of the Spectral Clustering</li>
<li>leaderCluster: Leader Clustering Algorithm</li>
<li>LearnClust: Learning Hierarchical Clustering Algorithms</li>
<li>MatTransMix: Clustering with Matrix Gaussian and Matrix Transformation Mixture Models</li>
<li>mclust: Gaussian Mixture Modelling for Model-Based Clustering, Classification, and Density Estimation</li>
<li>mclustcomp: Measures for Comparing Clusters</li>
<li>mdendro: Extended Agglomerative Hierarchical Clustering</li>
<li>Mercator: Clustering and Visualizing Distance Matrices</li>
<li>MixGHD: Model Based Clustering, Classification and Discriminant Analysis Using the Mixture of Generalized
    Hyperbolic Distributions</li>
<li>MixSim: Simulating Data to Study Performance of Clustering Algorithms</li>
<li>mixSPE: Mixtures of Power Exponential and Skew Power Exponential Distributions for Use in Model-Based
    Clustering and Classification</li>
<li>mixture: Mixture Models for Clustering and Classification</li>
<li>MKMeans: A Modern K-Means (MKMeans) Clustering Algorithm</li>
<li>mlr3cluster: Cluster Extension for ’mlr3’</li>
<li>motifcluster: Motif-Based Spectral Clustering of Weighted Directed Networks</li>
<li>MSclust: Multiple-Scaled Clustering</li>
<li>mstknnclust: MST-kNN Clustering Algorithm</li>
<li>NNS: Nonlinear nonparametric statistics using partial moments</li>
<li>ProjectionBasedClustering: Projection Based Clustering</li>
<li>
<p>protoclust: Hierarchical Clustering with Prototypes</p>
</li>
<li>
<p>pytorch_cluster: PyTorch Extension Library of Optimized Graph Cluster Algorithms</p>
</li>
<li>QuClu: Quantile-Based Clustering Algorithms</li>
<li>rebmix: Finite Mixture Modeling, Clustering &amp; Classification</li>
<li>RCTS: Clustering Time Series While Resisting Outliers</li>
<li>RMBC: Robust Model Based Clustering</li>
<li>sClust: R Toolbox for Unsupervised Spectral Clustering</li>
<li>sigclust: Statistical Significance of Clustering</li>
<li>SLBDD: Statistical Learning for Big Dependent Data</li>
<li>Spectrum: Fast Adaptive Spectral Clustering for Single and Multi-View Data</li>
<li>T4cluster: Tools for Cluster Analysis</li>
<li>tclust: Robust Trimmed Clustering</li>
<li>tglkmeans: Efficient Implementation of K-Means++ Algorithm</li>
<li>TSclust: Time Series Clustering Utilities</li>
<li>vimpclust: Variable Importance in Clustering</li>
</ul>
<h3>7.8 Coding utilities and frameworks.</h3>
<p><strong>Python software implementations</strong>
List of packages and/or codes and/or frameworks and/or links:</p>
<ul>
<li>Algviz is an algorithm visualization tool for your Python code</li>
<li>asteval: minimalistic evaluator of python expression using ast module</li>
<li>autoflake: Removes unused imports and unused variables as reported by pyflakes</li>
<li>autopep8: automatically formats Python code to conform to the PEP 8 style guide</li>
<li>autoray: Write numeric code that automatically works with any numpy-ish libraries</li>
<li>bandit: find common security issues in Python code</li>
<li>birdseye: Graphical debugger to view the values of all evaluated expressions</li>
<li>black: uncompromising Python code formatter</li>
<li>BLUE: The slightly less uncompromising Python code formatter</li>
<li>Bowler: Safe code refactoring by Facebook for modern Python</li>
<li>Comprehensive Python Cheatsheet</li>
<li>conda-deps: Generate conda environment files from Python and R source code</li>
<li>Crashtest is a Python library that makes exceptions handling and inspection easier.</li>
<li>darker: Apply black reformatting to Python files only in regions changed since a given commit</li>
<li>enum_tools: Tools to expand Python’s enum module.</li>
<li>
<p>erdantic: tool for drawing entity relationship diagrams (ERDs) for Python data model classes.</p>
</li>
<li>
<p>flake8: glues together pycodestyle, pyflakes, mccabe, and third-party plugins to check the style and quality of
    code</p>
</li>
<li>flake8-black: flake8 plugin to run black for checking Python coding style</li>
<li>friendly: replaces standard tracebacks by something easier to understand</li>
<li>Hatch is a modern, extensible Python project manager.</li>
<li>icecream: Never use print() to debug again</li>
<li>ipdb: exports functions to access the IPython debugger</li>
<li>isort: utility / library to sort imports</li>
<li>jedi: autocompletion, static analysis and refactoring library</li>
<li>jsonschema: implementation of the JSON Schema specification for Python</li>
<li>kedro: framework for creating reproducible, maintainable and modular data science code</li>
<li>kedro-viz: Visualise your Kedro data and machine-learning pipelines and track your experiments.</li>
<li>libfyaml: Fully feature complete YAML parser and emitter</li>
<li>luddite: Checks for out-of-date package versions</li>
<li>makepackage: easy packaging of Python code</li>
<li>mamba: Fast Cross-Platform Package Manager (reimplementation of the conda package manager in C++)</li>
<li>memray: memory profiler for Python</li>
<li>metaflow: build and manage real-life data science projects</li>
<li>mkdocs: Project documentation with Markdown</li>
<li>mkdocs-material: Technical documentation that just works</li>
<li>MonkeyType: toolkit by Instagram to generate static type annotations by collecting runtime types</li>
<li>Monty: supplementary useful functions for Python that are not part of the standard library</li>
<li>mypy: Optional static typing for Python</li>
<li>nptyping: Type hints for Numpy</li>
<li>numpydoc: Numpy’s Sphinx extensions</li>
<li>pdbpp: a drop-in replacement for pdb (the Python debugger)</li>
<li>PlantUML: Generate UML diagram from textual description</li>
<li>poetry: dependency management and packaging made easy</li>
<li>Pretty_Errors: Prettify Python exception output to make it legible</li>
<li>prospector: Inspects source files and provides information about type and location of classes, methods</li>
<li>ptvsd: debugger package by Microsoft for use with Visual Studio and Visual Studio Code</li>
<li>pudb: Full-screen console debugger for Python</li>
<li>pyan: Static call graph generator</li>
<li>
<p>pycodestyle: Simple Python style checker</p>
</li>
<li>
<p>pydantic: Data parsing and validation using Python type hints</p>
</li>
<li>pyDeprecate: tooling for marking deprecated functions or classes and re-routing to the new successors’ in-
    stance.</li>
<li>pyflakes: checks Python source files for errors</li>
<li>pylint: static code analysis tool</li>
<li>pyquickhelper: automation of many things</li>
<li>pyre: framework for building scientific applications in Python</li>
<li>pyre-check: Performant type-checking toolkit by Facebook</li>
<li>pyright: Static type checker by Microsoft</li>
<li>PyScaffold: Python project template generator with batteries included</li>
<li>PySnooper: Never use print for debugging again</li>
<li>py-spy: Sampling profiler for Python programs</li>
<li>pytools: a big bag of things that are ”missing” from the Python standard library</li>
<li>pytype: static type analyzer by Google</li>
<li>radon: tool that computes various metrics from the source code</li>
<li>rope: refactoring library</li>
<li>scalene: high-performance, high-precision CPU, GPU, and memory profiler for Python</li>
<li>sphinx: Sphinx documentation builder</li>
<li>StrictYAML is a type-safe YAML parser that parses and validates a restricted subset of the YAML specification</li>
<li>tryceratops: linter to prevent exception handling antipatterns in Python</li>
<li>typeguard: Run-time type checker for Python</li>
<li>TypePigeon: type converter focused on converting values between various Python data types.</li>
<li>varname:Dark magics about variable names in python</li>
<li>vulture: Find dead Python code</li>
<li>xlwings: ibrary that makes it easy to call Python from Excel and vice versa</li>
<li>yapf: formatter by Google for Python files</li>
<li>yappi: Yet Another Python Profiler, but this time multithreading, asyncio and gevent aware.</li>
</ul>
<p><strong>R software implementations</strong>
List of packages and/or codes and/or frameworks and/or links:</p>
<ul>
<li>adaptalint: Check Code Style Painlessly</li>
<li>baguette: Efficient Model Functions for Bagging</li>
<li>box: Write Reusable, Composable and Modular R Code</li>
<li>butcher: Model Butcher: axe components of fitted model objects and help reduce the size of model objects
    saved to disk</li>
<li>cartbonate: Create beautiful images of source code using ’carbon.js</li>
<li>checkmate: Fast and Versatile Argument Checks</li>
<li>checkpoint: Install Packages from Snapshots on the Checkpoint Server for Reproducibility</li>
<li>cleanr: Helps You to Code Cleaner</li>
<li>delayed: A Framework for Parallelizing Dependent Tasks</li>
<li>goodpractice: Advice on R Package Building</li>
<li>hardhat: Construct Modeling Packages</li>
<li>IRdisplay: ’Jupyter’ Display Machinery</li>
<li>IRkernel: Native R Kernel for the ’Jupyter Notebook’</li>
<li>jetpack: A Friendly Package Manager</li>
<li>leprechaun: Create Simple ’Shiny’ Applications as Packages</li>
<li>lintr: A ’Linter’ for R Code</li>
<li>lvec: Out of Memory Vectors</li>
<li>memuse: Memory Estimation Utilities</li>
<li>metaflow: build and manage real-life data science projects</li>
<li>miniCRAN: Create a Mini Version of CRAN Containing Only Selected Packages</li>
<li>mongolite: Fast and Simple ’MongoDB’ Client for R</li>
<li>packager: Create, Build and Maintain Packages</li>
<li>parsnip: A Common API to Modeling and Analysis Functions</li>
<li>prettifyAddins: ’RStudio’ Addins to Prettify ’JavaScript’, ’C++’, ’Python’, and More</li>
<li>R6: Encapsulated Classes with Reference Semantics</li>
<li>R6P: Design Patterns in R</li>
<li>recipes: Preprocessing and Feature Engineering Steps for Modeling</li>
<li>renv: Project Environments</li>
<li>rhino: A Framework for Enterprise Shiny Applications</li>
<li>roxut: Document Unit Tests Roxygen-Style</li>
<li>
<p>roxygen2: In-Line Documentation for R</p>
</li>
<li>
<p>rstudio.prefs: Set ’RStudio’ Preferences</p>
</li>
<li>tidymodules: obust framework for developing ‘Shiny’ modules based on R6 classes which should facilitates
    inter-modules communication.</li>
<li>waldo: Find Differences Between R Objects</li>
<li>vetiver: Version, Share, Deploy, and Monitor Models</li>
<li>workflows: Modeling Workflows</li>
<li>workflowsets: Create a Collection of ’tidymodels’ Workflows</li>
</ul>
<h3>7.9 Computational performance.</h3>
<p><strong>Python software implementations</strong>
List of packages and/or codes and/or frameworks and/or links:</p>
<ul>
<li>Aesara: definie, optimize, and efficiently evaluate mathematical expressions involving multi-dimensional ar-
    rays.</li>
<li>arctic: High performance datastore by Man Group for time series and tick data</li>
<li>bottleneck: Fast NumPy array functions written in C</li>
<li>Dask: Parallel computing with task scheduling</li>
<li>Dask-ML provides scalable machine learning in Python using Dask alongside popular machine learning libraries</li>
<li>datatable: library for fast multi-threaded data manipulation and munging</li>
<li>fairscale: PyTorch extensions for high performance and large scale training.</li>
<li>fastcore: Python supercharged for the fastai library</li>
<li>hypre: high performance preconditioners</li>
<li>jax: automatically differentiate native Python and NumPy functions</li>
<li>modin: ake your pandas code run faster by changing one line of code</li>
<li>multiprocess: better multiprocessing and multithreading in python</li>
<li>numexpr: Fast numerical expression evaluator for NumPy</li>
<li>PandaPy: speed of NumPy and the usability of Pandas but much faster</li>
<li>pandarallel: parallelize Pandas operations on all available CPUs</li>
<li>pandasvault:Advanced Pandas Vault - Utilities, Functions and Snippets</li>
<li>polars: Fast multi-threaded DataFrame library</li>
<li>ppft: distributed and parallel python</li>
<li>PyArma: Linear algebra library for Python</li>
<li>PyArmadillo: an alternative approach to linear algebra in Python</li>
<li>pyperf: Toolkit to run Python benchmarks</li>
<li>pyperformance: Python Performance Benchmark Suite</li>
<li>
<p>py-spy: Sampling profiler for Python programs</p>
</li>
<li>
<p>scalene: high-performance, high-precision CPU, GPU, and memory profiler for Python</p>
</li>
<li>swifter: efficiently applies any function to a pandas dataframe or series in the fastest available manner</li>
<li>tempeh is a framework to TEst Machine learning PErformance exHaustively which includes tracking memory
    usage and run time.</li>
</ul>
<p><strong>R software implementations</strong>
List of packages and/or codes and/or frameworks and/or links:</p>
<ul>
<li>collapse: Advanced and Fast Data Transformation</li>
<li>dataPreparation: Automated Data Preparation</li>
<li>delayed: A Framework for Parallelizing Dependent Tasks</li>
<li>dplyr: A Grammar of Data Manipulation</li>
<li>MatrixStats: Methods that Apply to Rows and Columns of Matrices (and to Vectors)</li>
<li>mirai: Minimalist Async Evaluation Framework for R</li>
<li>purrr: Functional Programming Tools</li>
<li>tidyverse: set of packages that work in harmony because they share common data representations and ’API’
    design</li>
<li>timetk: A Tool Kit for Working with Time Series in R</li>
<li>tibble: Simple Data Frames</li>
<li>tidytidbits: A Collection of Tools and Helpers Extending the Tidyverse</li>
<li>tsibble: Tidy Temporal Data Frames and Tools</li>
</ul>
<h3>7.10 Containers, projects, pipelines and deployment</h3>
<p><strong>Python software implementations</strong>
List of packages and/or codes and/or frameworks and/or links:</p>
<ul>
<li>Driblet - Google Cloud based ML pipeline by Google</li>
<li>MLflow: A Machine Learning Lifecycle Platform</li>
<li>metaflow: Python/R library by Netflix to build and manage real-life data science projects</li>
<li>mlflow: Interface to ’MLflow’</li>
<li>mlxtend: extension and helper modules for data analysis and machine learning libraries</li>
<li>NNI: toolkit by Microsoft to help users automate Feature Engineering, Neural Architecture Search, Hyperpa-
    rameter Tuning and Model Compression</li>
<li>petastorm: toolkit by Uber for single machine or distributed training and evaluation of deep learning models
    (Tensorflow, Pytorch, and PySpark) from datasets in Apache Parquet format</li>
<li>pipelines: Machine Learning Pipelines for Kubeflow</li>
<li>Prefect: second-generation dataflow coordination and orchestration platform</li>
<li>PyTorch Lightning: The lightweight PyTorch wrapper for high performance AI research</li>
<li>Tango: toolkit by Allen Institute of Articial Intelligence for choreographing machine learning research</li>
</ul>
<p><strong>R software implementations</strong>
List of packages and/or codes and/or frameworks and/or links:</p>
<ul>
<li>DriveML: Self-Drive Machine Learning Projects</li>
<li>metaflow: Python/R library by Netflix to build and manage real-life data science projects</li>
<li>mlflow: Interface to ’MLflow’</li>
</ul>
<h3>7.11 Covariances, correlations and volatilities.</h3>
<p><strong>Python software implementations</strong>
List of packages and/or codes and/or frameworks and/or links:</p>
<ul>
<li>numpy: scientific computing</li>
<li>precise: online covariance and precision forecasting, portfolios, and model ensembles</li>
<li>PyPortfolioOpt: Financial portfolio optimization</li>
<li>sklearn.covariance: covariance estimation in scikit-learn</li>
<li>statsmodels: statistical modeling and econometrics</li>
</ul>
<p><strong>R software implementations</strong>
List of packages and/or codes and/or frameworks and/or links:</p>
<ul>
<li>bahc: Filter Covariance and Correlation Matrices with Bootstrapped-Averaged Hierarchical Ansatz</li>
<li>BBcor: Bayesian Bootstrapping Correlations</li>
<li>BEKKs: Multivariate Conditional Volatility Modelling and Forecasting</li>
<li>BSCOV: Detection of Multiple Structural Breaks in Large Covariance Matrices</li>
<li>clubSandwich: Cluster-Robust (Sandwich) Variance Estimators with Small-Sample Corrections</li>
<li>cocor: Comparing Correlations</li>
<li>corpcor: Efficient Estimation of Covariance and (Partial) Correlation</li>
<li>correlation: Methods for Correlation Analysis</li>
<li>corx: Create and Format Correlation Matrices</li>
<li>CovTools: Statistical Tools for Covariance Analysis</li>
<li>cvCovEst: Cross-Validated Covariance Matrix Estimation</li>
<li>dcortools: Providing Fast and Flexible Functions for Distance Correlation Analysis</li>
<li>dCovTS: Distance Covariance and Correlation for Time Series Analysis</li>
<li>fitHeavyTail: Mean and Covariance Matrix Estimation under Heavy Tails</li>
<li>FRCC: Fast Regularized Canonical Correlation Analysis</li>
<li>gencor: Generate Customized Correlation Matrices</li>
<li>generalCorr: Generalized Correlations, Causal Paths and Portfolio Selection</li>
<li>
<p>mashr: Multivariate Adaptive Shrinkage</p>
</li>
<li>
<p>MatrixCorrelation: Matrix Correlation Coefficients</p>
</li>
<li>MTS: All-Purpose Toolkit for Analyzing Multivariate Time Series (MTS) and Estimating Multivariate Volatil-
    ity Models</li>
<li>NonParRolCor: a Non-Parametric Statistical Significance Test for Rolling Window Correlation</li>
<li>NNS: Nonlinear nonparametric statistics using partial moments</li>
<li>rags2ridges: Ridge Estimation of Precision Matrices from High-Dimensional Data</li>
<li>rmcorr: Repeated Measures Correlation</li>
<li>robcor: Robust Correlations</li>
<li>robustcov: Collection of Robust Covariance and (Sparse) Precision Matrix Estimators</li>
<li>RSC: Robust and Sparse Correlation Matrix</li>
<li>sandwich: Robust Covariance Matrix Estimators</li>
<li>WGCNA: Weighted Correlation Network Analysis</li>
</ul>
<h3>7.12 Data analysis and exploration.</h3>
<p><strong>Python software implementations</strong>
List of packages and/or codes and/or frameworks and/or links:</p>
<ul>
<li>AutoViz: Automatically Visualize any dataset, any size with a single line of code.</li>
<li>daal4py: simplified API to Intel oneAPI Data Analytics Library</li>
<li>DeepGraph: scalable, general-purpose data analysis with Pandas-based Networks</li>
<li>D-tale:Visualizer by Man Group for pandas data structures</li>
<li>dython: Data analysis tools</li>
<li>empiricaldist: empirical distribution functions</li>
<li>hyperspy: Multidimensional data analysis</li>
<li>Lux: automate the visualization and data analysis process</li>
<li>mlxtend: extension and helper modules for Python’s data analysis and machine learning libraries.</li>
<li>numericalunits: Units and dimensional analysis compatible with everything</li>
<li>Orange: Interactive data analysis</li>
<li>pandas-profiling: Create HTML profiling reports from pandas DataFrame objects</li>
<li>PyApprox: high-dimensional approximation and uncertainty quantification</li>
<li>sweetviz: Visualize and compare datasets, target values and associations</li>
</ul>
<p><strong>R software implementations</strong>
List of packages and/or codes and/or frameworks and/or links:</p>
<ul>
<li>checkmate: Fast and Versatile Argument Checks</li>
<li>collapse: Advanced and Fast Data Transformation</li>
<li>datacleanr: Interactive and Reproducible Data Cleaning</li>
<li>DataEditR: An Interactive Editor for Viewing, Entering, Filtering &amp; Editing Data</li>
<li>DataExplorer: Automate Data Exploration and Treatment</li>
<li>datamods: Modules to Import and Manipulate Data in ’Shiny’</li>
<li>dataprep: Efficient and Flexible Data Preprocessing Tools</li>
<li>DataVisualizations: Visualizations of High-Dimensional Data</li>
<li>datawizard: Easy Data Wrangling</li>
<li>DescTools: Tools for Descriptive Statistics</li>
<li>dimensio: Multivariate Data Analysis</li>
<li>discoveR: Exploratory Data Analysis System</li>
<li>dlookr: Tools for Data Diagnosis, Exploration, Transformation</li>
<li>EasyDescribe: A Convenient Way of Descriptive Statistics</li>
<li>esquisse: Explore and Visualize Your Data Interactively</li>
<li>explor: Interactive Interfaces for Results Exploration</li>
<li>exploratory: A Tool for Large-Scale Exploratory Analyses</li>
<li>explore: Simplifies Exploratory Data Analysis</li>
<li>factoextra: extract and visualize the output of multivariate data analyses, including ’PCA’ (Principal Compo-
    nent Analysis), ’CA’ (Correspondence Analysis), ’MCA’ (Multiple Correspondence Analysis), ’FAMD’ (Factor
    Analysis of Mixed Data), ’MFA’ (Multiple Factor Analysis) and ’HMFA’ (Hierarchical Multiple Factor Anal-
    ysis)</li>
<li>FactoInvestigate: Automatic Description of Factorial Analysis</li>
<li>FactoMineR: Multivariate Exploratory Data Analysis and Data Mining</li>
<li>ggESDA: Exploratory Symbolic Data Analysis with ’ggplot2’</li>
<li>HDTSA: High Dimensional Time Series Analysis Tools</li>
<li>infotheo: Information-Theoretic Measures</li>
<li>kfa: K-Fold Cross Validation for Factor Analysis</li>
<li>MazamaRollUtils: Efficient Rolling Functions</li>
<li>mmpca: Integrative Analysis of Several Related Data Matrices</li>
<li>praznik: Tools for Information-Based Feature Selection and Scoring</li>
<li>
<p>predictoR: Predictive Data Analysis System</p>
</li>
<li>
<p>rigr: Regression, Inference, and General Data Analysis Tools in R</p>
</li>
<li>robCompositions: Compositional Data Analysis</li>
<li>rrcov: Scalable Robust Estimators with High Breakdown Point</li>
<li>SmartEDA: Summarize and Explore the Data</li>
<li>statsExpressions: Tidy Dataframes and Expressions with Statistical Details</li>
<li>Statsomat: Shiny Apps for Automated Data Analysis and Automated Interpretation</li>
<li>thinkr: Tools for Cleaning Up Messy Files</li>
<li>tswge: Time Series for Data Science.Accompanies the texts Time Series for Data Science and Applied Time
    Series Analysis with R,</li>
<li>validata: Validate Data Frames</li>
<li>validate: Data Validation Infrastructure</li>
<li>validatetools: Checking and Simplifying Validation Rule Sets</li>
<li>wrangle: A Systematic Data Wrangling Idiom</li>
</ul>
<h3>7.13 Data augmentation, scenario generation and synthetic time series.</h3>
<p><strong>Collections of resources</strong>
List of links:</p>
<ul>
<li>Synthetic data generation by Van Der Schaar Lab</li>
<li>Useful data augmentation resources</li>
</ul>
<p><strong>Python software implementations</strong>
List of packages and/or codes and/or frameworks and/or links:</p>
<ul>
<li>agots: Anomaly Generator on Time Series</li>
<li>benchmark_VAE: Unifying Generative Autoencoder implementations in Python</li>
<li>Copulas: model multivariate data using copulas</li>
<li>CTGAN: Conditional GAN for Tabular Data</li>
<li>COMET Flows: Towards Generative Modeling of Multivariate Extremes and Tail Dependence</li>
<li>DataGeneration: Synthetic financial correlation matrix and time series generation</li>
<li>DECAF: Generating Fair Synthetic Data Using Causally-Aware Generative Networks</li>
<li>DeepEcho: Synthetic Data Generation for mixed-type, multivariate time series</li>
<li>deltapy: Tabular Data Augmentation</li>
<li>extremeIndex: Forecast Verification for Extreme Events</li>
<li>ixmp: platform for integrated and cross-cutting scenario analysis</li>
<li>MLlforHealthLab: Machine Learning and Artificial Intelligence for Medicine</li>
<li>
<p>pydantic-factories: Pydantic based mock data generation</p>
</li>
<li>
<p>pythae: Unifying Generative Autoencoder implementations in Python</p>
</li>
<li>RDT: Reversible Data Transforms to reproduce realistic data</li>
<li>scattering_covariance: analysis and generation of time series</li>
<li>SDMetrics: Metrics for Synthetic Data Generation Projects</li>
<li>SDGym: Benchmarking synthetic data generation methods</li>
<li>SDV: Synthetic Data Generation for tabular, relational and time series data</li>
<li>SignalFilters: Signal Filtering and Generation of Synthetic Time-Series</li>
<li>snorkel: system for quickly generating training data with weak supervision</li>
<li>synthia: Multidimensional synthetic data generation in Python</li>
<li>TGAN: Generative adversarial training for generating synthetic tabular data</li>
<li>TimeGAN: Time-series Generative Adversarial Networks</li>
<li>time-series-generator: Time Series Generator</li>
<li>TimeSynth: Synthetic Time Series Generation</li>
<li>tsaug: time series augmentation</li>
<li>tsBNgen: Generate Time Series Data Based on an Arbitrary Bayesian Network Structure</li>
<li>tsGAN: Time-series Generative Adversarial Networks</li>
<li>ydata-synthetic: Synthetic structured data generators</li>
</ul>
<p><strong>R software implementations</strong>
List of packages and/or codes and/or frameworks and/or links:</p>
<ul>
<li>anySim: Simulation of Non-Gaussian Correlated Random Variables, Stochastic Processes and Random Fields</li>
<li>bootComb: Combine Parameter Estimates via Parametric Bootstrap</li>
<li>conjurer: A Parametric Method for Generating Synthetic Data</li>
<li>covsim: VITA, IG and PLSIM Simulation for Given Covariance and Marginals</li>
<li>fabricatr: Imagine Your Data Before You Collect It</li>
<li>fwb: Fractional Weighted Bootstrap</li>
<li>gencor: Generate Customized Correlation Matrices</li>
<li>gratis: Generating Time Series with Diverse and Controllable Characteristics</li>
<li>meboot: Maximum Entropy Bootstrap for Time Series</li>
<li>metamer: Create Data with Identical Statistics</li>
<li>missMethods: Methods for Missing Data</li>
<li>MixSim: Simulating Data to Study Performance of Clustering Algorithms</li>
<li>modeltime.resample: Resampling Tools for Time Series Forecasting</li>
<li>
<p>MonteCarlo: Automatic Parallelized Monte Carlo Simulations</p>
</li>
<li>
<p>MSCMT: Multivariate Synthetic Control Method Using Time Series</p>
</li>
<li>mvlognCorrEst: Sampling from Multivariate Lognormal Distributions and Estimating Correlations from Un-
    complete Correlation Matrix</li>
<li>naive: Empirical Extrapolation of Time Feature Patterns</li>
<li>RMT4DS: Computation of Random Matrix Models</li>
<li>rsample: General Resampling Infrastructure</li>
<li>segen: Sequence Generalization Through Similarity Network</li>
<li>SimJoint: Simulate Joint Distribution</li>
<li>simmer: Discrete-Event Simulation for R</li>
<li>simts: Time Series Analysis Tools</li>
<li>spooky: Time Feature Extrapolation Using Spectral Analysis and Jack-Knife Resampling</li>
<li>Synth: Synthetic Control Group Method for Comparative Case Studies</li>
<li>synthesis: Generate Synthetic Data from Statistical Models</li>
<li>tetragon: Automatic Sequence Prediction by Expansion of the Distance Matrix</li>
<li>TidyDensity: Functions for Tidy Analysis and Generation of Random Data</li>
<li>tscopula: Time Series Copula Models</li>
</ul>
<h3>7.14 Data cleaning, preparation and validation</h3>
<p><strong>Python software implementations</strong>
List of packages and/or codes and/or frameworks and/or links:</p>
<ul>
<li>cerberus: Lightweight, extensible data validation library</li>
<li>datatest: Tools for test driven data-wrangling and data validation</li>
<li>doubtlab: Doubt your data, find bad labels</li>
<li>framework: Data management framework for Python that provides functionality to describe, extract, validate,
    and transform tabular data</li>
<li>formencode: validation and form generation</li>
<li>pandera: perform data validation on dataframes</li>
<li>pydantic: Data parsing and validation using Python type hints</li>
<li>pyjanitor: Clean APIs for data cleaning. Python implementation of R package Janitor</li>
<li>PyOptimus: framework for cleaning and pre-processing data in a distributed fashion</li>
<li>scikit-learn: machine learning in Python</li>
<li>schema: library for validating Python data structures</li>
<li>serde: framework for defining, serializing, deserializing, and validating data structures</li>
<li>typical: Fast, simple, &amp; correct data-validation using Python 3 typing.</li>
<li>
<p>validators: Python data validation for Humans</p>
</li>
<li>
<p>Voluptuous: data validation library.</p>
</li>
<li>validr: simple, fast, extensible python library for data validation</li>
<li>wtforms: flexible forms validation and rendering library</li>
</ul>
<p><strong>R software implementations</strong>
List of packages and/or codes and/or frameworks and/or links:</p>
<ul>
<li>cleanTS: Testbench for Univariate Time Series Cleaning</li>
<li>dataPreparation: Automated Data Preparation</li>
<li>data.validator: Automatic Data Validation and Reporting</li>
<li>datawizard: Easy Data Wrangling</li>
<li>errorlocate: Locate Errors with Validation Rules</li>
<li>pointblank: Data Validation and Organization of Metadata for Local and Remote Tables</li>
<li>testdat: Data Unit Testing for R</li>
<li>tsrobprep: Robust Preprocessing of Time Series Data</li>
<li>validate: Data Validation Infrastructure</li>
<li>validatetools: Checking and Simplifying Validation Rule Sets</li>
<li>wrangle: A Systematic Data Wrangling Idiom</li>
</ul>
<h3>7.15 Data Imputation</h3>
<p><strong>Python software implementations</strong>
List of packages and/or codes and/or frameworks and/or links:</p>
<ul>
<li>AutoImpute: Imputation Methods</li>
<li>Clairvoyance: a Unified, End-to-End AutoML Pipeline for Medical Time Series</li>
<li>fancyimpute: Multivariate imputation and matrix completion algorithms</li>
<li>HyperImpute: framework for prototyping and benchmarking imputation methods</li>
<li>imputena: automated and customized treatment of missing values in datasets</li>
<li>miceforest: Fast, Memory Efficient Imputation with LightGBM</li>
<li>MissForestExtra: nonparametric imputation on missing values</li>
<li>scikit-learn: machine learning in Python</li>
<li>statsmodels: statistical modeling and econometrics</li>
<li>tsai: time series tasks like classification, regression, forecasting, imputation</li>
</ul>
<p><strong>R software implementations</strong>
List of packages and/or codes and/or frameworks and/or links:</p>
<ul>
<li>Amelia: A Program for Missing Data</li>
<li>CoImp: Copula Based Imputation Method</li>
<li>deductive: Data Correction and Imputation Using Deductive Methods</li>
<li>ggmice: Visualizations for ’mice’ with ’ggplot2’</li>
<li>howManyImputations: Calculate How many Imputations are Needed for Multiple Imputation</li>
<li>imputeFin: Imputation of Financial Time Series with Missing Values and/or Outliers</li>
<li>imputeGeneric: Ease the Implementation of Imputation Methods</li>
<li>imputeTestbench: Test Bench for the Comparison of Imputation Methods</li>
<li>imputeTS: Time Series Missing Value Imputation</li>
<li>Iscores: Proper Scoring Rules for Missing Value Imputation</li>
<li>mdgc: Missing Data Imputation Using Gaussian Copulas</li>
<li>mice: Multivariate Imputation by Chained Equations</li>
<li>miceadds: Some Additional Multiple Imputation Functions, Especially for ’mice’</li>
<li>miceafter: Data and Statistical Analyses after Multiple Imputation</li>
<li>miceFast: Fast Imputations Using ’Rcpp’ and ’Armadillo’</li>
<li>micemd: Multiple Imputation by Chained Equations with Multilevel Data</li>
<li>misPRIME: Partial Replacement Imputation Estimation for Missing Covariates</li>
<li>missMDA: Handling Missing Values with Multivariate Data Analysis</li>
<li>missMethods: Methods for Missing Data</li>
<li>missRanger: Fast Imputation of Missing Values</li>
<li>mlim: Multiple Imputation with Automated Machine Learning</li>
<li>NADIA: NA Data Imputation Algorithms</li>
<li>naniar: Data Structures, Summaries, and Visualisations for Missing Data</li>
<li>rego: Automatic Time Series Forecasting and Missing Value Imputation</li>
<li>Rforestry: Random Forests, Linear Trees, and Gradient Boosting for Inference and Interpretability</li>
<li>simputation: Simple Imputation</li>
<li>SLBDD: Statistical Learning for Big Dependent Data</li>
<li>smcfcs: Multiple Imputation of Covariates by Substantive Model Compatible Fully Conditional Specification</li>
<li>univOutl: Detection of Univariate Outliers</li>
<li>VIM: Visualization and Imputation of Missing Values</li>
<li>yaImpute: Nearest Neighbor Observation Imputation and Evaluation Tools</li>
</ul>
<h3>7.16 Data regimes, states and changepoints: analysis and modeling.</h3>
<p><strong>Collections of resources</strong>
List of links:</p>
<ul>
<li>Classifying market regimes</li>
<li>TCPD: toolkit by UK national institute for data science and artificial intelligence for Turing Change Point
    Dataset - A collection of time series for the evaluation and development of change point detection algorithms</li>
<li>TCPDBench: toolkit by UK national institute for data science and artificial intelligence for Turing Change
    Point Detection Benchmark: An Extensive Benchmark Evaluation of Change Point Detection Algorithms on
    real-world data</li>
</ul>
<p><strong>Python software implementations</strong>
List of packages and/or codes and/or frameworks and/or links:</p>
<ul>
<li>changeforest: Random Forests for Change Point Detection</li>
<li>deeptime: analysis of time series data including dimensionality reduction, clustering, and Markov model
    estimation</li>
<li>greykite: flexible, intuitive and fast forecasting library</li>
<li>HMMLearn: Hidden Markov Models in Python with scikit-learn like API</li>
<li>kalmanfilter: Kalman Filter</li>
<li>kats: tookit by Facebook for time series analysis and forecasting</li>
<li>kimfilter: Rcpp’ implementation of the multivariate Kim filter, which combines the Kalman and Hamilton
    filters for state probability inference</li>
<li>Merlion: A Machine Learning Framework for Time Series Intelligence by SalesForce</li>
<li>msmtools: estimation and analysis of discrete state space Markov chains via Markov state models (MSM)</li>
<li>PyEMMA: Emma’s Markov Model Algorithms</li>
<li>pyGPCCA: Generalized Perron Cluster Cluster Analysis to coarse-grain reversible and non-reversible Markov
    state models.</li>
<li>pyhsmm: Bayesian inference in HSMMs and HMMs</li>
<li>pymc3-hmm: Hidden Markov models in PyMC3</li>
<li>ruptures: change point detection</li>
<li>SST: fast implementation of Singular Spectrum Transformation</li>
<li>Stone-Soup: framework for the development and testing of tracking algorithms</li>
<li>statsmodels: Markov switching models in statsmodels</li>
<li>transitionMatrix: Statistical analysis and visualization of state transition phenomena</li>
<li>tsmoothie: time-series smoothing and outlier detection</li>
</ul>
<p><strong>R software implementations</strong>
List of packages and/or codes and/or frameworks and/or links:</p>
<ul>
<li>BayesHMM: Full Bayesian Inference for Hidden Markov Models</li>
<li>breakfast: Methods for Fast Multiple Change-Point Detection and Estimation</li>
<li>BSCOV: Detection of Multiple Structural Breaks in Large Covariance Matrices</li>
<li>ChangepointInference: Tools to test for a change in mean after changepoint detection</li>
<li>changepoints: A Collection of Change-Point Detection Methods</li>
<li>ChangePointTaylor: Identify Changes in Mean</li>
<li>chngpt: Estimation and Hypothesis Testing for Threshold Regression</li>
<li>cpss: Change-Point Detection by Sample-Splitting Methods</li>
<li>crossvalidationCP: Cross-Validation for Change-Point Regression</li>
<li>depmixS4: Dependent Mixture Models - Hidden Markov Models of GLMs and Other Distributions in S4</li>
<li>dynr: Dynamic Models with Regime-Switching</li>
<li>earlywarnings: Early Warning Signals Toolbox for Detecting Critical Transitions in Timeseries</li>
<li>fabisearch: Change Point Detection in High-Dimensional Time Series Networks</li>
<li>fHMM: Fitting Hidden Markov Models to Financial Data</li>
<li>inflection: Finds the Inflection Point of a Curve</li>
<li>InspectChangepoint: High-Dimensional Changepoint Estimation via Sparse Projection</li>
<li>jcp: Joint Change Point Detection</li>
<li>HMM: Hidden Markov Models</li>
<li>hmm.discnp: Hidden Markov Models with Discrete Non-Parametric Observation Distributions</li>
<li>hmmr: ”Mixture and Hidden Markov Models with R” Datasets and Example Code</li>
<li>KFAS: Kalman Filter and Smoother for Exponential Family State Space Models</li>
<li>ldhmm: Hidden Markov Model for Financial Time-Series Based on Lambda Distribution</li>
<li>mHMMbayes: Multilevel Hidden Markov Models Using Bayesian Estimation</li>
<li>MSGARCH: Markov-Switching GARCH Models</li>
<li>MSTest: Hypothesis Testing for Markov Switching Models</li>
<li>NHMSAR: Non-Homogeneous Markov Switching Autoregressive Models</li>
<li>onlineBcp: Online Bayesian Methods for Change Point Analysis</li>
<li>plotHMM: Plot Hidden Markov Models</li>
<li>pomp: Statistical Inference for Partially Observed Markov Processes</li>
<li>Rbeast: Bayesian Change-Point Detection and Time Series Decomposition</li>
<li>
<p>RChest: Locating Distributional Changes in Highly Dependent Time Series</p>
</li>
<li>
<p>robcp: Robust Change-Point Tests</p>
</li>
<li>segmented: Regression Models with Break-Points / Change-Points Estimation</li>
<li>seqHMM: Mixture Hidden Markov Models for Social Sequence Data and Other Multivariate, Multichannel
    Categorical Time Series</li>
<li>trendchange: Innovative Trend Analysis and Time-Series Change Point Analysis</li>
<li>tsDyn: Nonlinear Time Series Models with Regime Switching</li>
<li>wbsts: Multiple Change-Point Detection for Nonstationary Time Series</li>
</ul>
<h3>7.17 Data structures, storage and serialization</h3>
<p><strong>Python software implementations</strong>
List of packages and/or codes and/or frameworks and/or links:</p>
<ul>
<li>addict: Python Dict</li>
<li>anndata: package for handling annotated data matrices in memory and on disk</li>
<li>arctic: High performance datastore by Man Group for time series and tick data</li>
<li>cloudpickle: serialize Python constructs not supported by the default pickle module</li>
<li>dataclassy is a reimplementation of data classes in Python</li>
<li>datatable: fast multi-threaded data manipulation and munging</li>
<li>dill: extends Python’s pickle module for serializing and deserializing python objects to the majority of the
    built-in python types.</li>
<li>extendedjson: Easily extend JSON to encode and decode arbitrary Python objects</li>
<li>framework: Data management framework for Python that provides functionality to describe, extract, validate,
    and transform tabular data</li>
<li>MarketStore: DataFrame Server for Financial Timeseries Data</li>
<li>marshmallow: lightweight library for converting complex objects to and from simple Python datatypes</li>
<li>modin.pandas DataFrame is a parallel and distributed drop-in replacement for panda</li>
<li>Mongita is to MongoDB as SQLite is to SQL</li>
<li>mongo-arrow: Tools for using Apache Arrow with MongoDB</li>
<li>multidict: multidict implementation</li>
<li>Odo provides a uniform API for moving data between different formats</li>
<li>pandas: data structures for data analysis, time series, and statistics</li>
<li>pandasvault: Advanced Pandas Vault - Utilities, Functions and Snippets</li>
<li>pickle: Python object serialization</li>
<li>polars: Fast multi-threaded DataFrame library</li>
<li>
<p>pyarrow: Python API for Apache Arrow, a language independent columnar memory format for flat and
    hierarchical data</p>
</li>
<li>
<p>PyMongo - the Python driver for MongoDB</p>
</li>
<li>PyStore: Fast data store for Pandas time-series data</li>
<li>PyTables: package for managing hierarchical datasets</li>
<li>rpy2-arrow: Share Apache Arrow datasets between Python and R</li>
<li>serde: framework for defining, serializing, deserializing, and validating data structures</li>
<li>sklearn-pandas: bridge between Scikit-Learn’s machine learning methods and pandas-style Data Frames</li>
<li>sortedcontainers: Sorted Containers – Sorted List, Sorted Dict, Sorted Set</li>
<li>sqlite: Persistent dict, backed by sqlite3 and pickle, multithread-safe.</li>
<li>sparse: Sparse Multidimensional Arrays</li>
<li>srsly: Modern high performance serialization utilities</li>
<li>tablib: Module for Tabular Datasets in XLS, CSV, JSON, YAML,</li>
<li>tabmat: Efficient matrix representations for working with tabular data</li>
<li>TileDB: powerful engine for storing and accessing dense and sparse multi-dimensional arrays</li>
<li>tidypandas: grammar of data manipulation for pandas inspired by tidyverse</li>
<li>tinyarray: Tinyarrays are similar to NumPy arrays, but optimized to be much faster for small sizes</li>
<li>TinyDB is a lightweight document oriented database optimized for your happiness</li>
<li>tinyflux: iny time series database optimized for your happiness</li>
<li>torcharrow: torch.Tensor-like DataFrame library by Facebook using Arrow as a common memory format</li>
<li>ubermagtable: package for manipulating tabular data</li>
<li>ultrajson: Ultra fast JSON decoder and encoder written in C with Python bindings</li>
<li>Vector: arrays of 2D, 3D, and Lorentz vectors</li>
<li>Woodwork is a Python library that provides robust methods for managing and communicating data typing
    information</li>
<li>xarray: multidimensional labeled arrays and datasets</li>
<li>xpandas: Universal 1d/2d data containers with Transformers functionality for data analysis</li>
</ul>
<p><strong>R software implementations</strong>
List of packages and/or codes and/or frameworks and/or links:</p>
<ul>
<li>arrow: Integration to Apache Arrow</li>
<li>dibble: Dimensional Data Frames</li>
<li>fst: Lightning Fast Serialization of Data Frames</li>
<li>gluedown: Wrap Vectors in Markdown Formatting</li>
<li>listdown: Create R Markdown from Lists</li>
<li>
<p>motifcluster: Motif-Based Spectral Clustering of Weighted Directed Networks</p>
</li>
<li>
<p>qs: Quick Serialization of R Objects</p>
</li>
<li>RcppSimdJson: ’Rcpp’ Bindings for the ’simdjson’ Header-Only Library for ’JSON’ Parsing</li>
<li>tibble: stricter checking and better formatting than the traditional data frame</li>
<li>tibblify: Rectangle Nested Lists</li>
<li>tidytable: Tidy Interface to ’data.table’</li>
<li>tiledb: Universal Storage Engine for Sparse and Dense Multidimensional Arrays</li>
<li>tsibble: Tidy Temporal Data Frames and Tools</li>
<li>tsbox: Class-Agnostic Time Series</li>
<li>vtreat: A Statistically Sound data.frame Processor/Conditioner</li>
</ul>
<h3>7.18 Dates and times</h3>
<p><strong>Python software implementations</strong>
List of packages and/or codes and/or frameworks and/or links:</p>
<ul>
<li>arrow: Better dates and times for Python</li>
<li>dateparser: parser for human readable dates</li>
<li>dateutil: Useful extensions to the standard Python datetime features</li>
<li>orjson: Fast, correct Python JSON library supporting dataclasses, datetimes, and numpy</li>
<li>parsedatetime: human-readable date/time strings</li>
<li>pendulum: datatimes made easy</li>
<li>Pyrsistent: Persistent/Functional/Immutable data structures</li>
<li>python-dateutil: Useful extensions to the standard Python datetime features</li>
<li>PyTime: operate datetime by string</li>
</ul>
<p><strong>R software implementations</strong>
List of packages and/or codes and/or frameworks and/or links:</p>
<ul>
<li>clock: Date-Time Types and Tools</li>
<li>lubridate: Make Dealing with Dates a Little Easier</li>
<li>qlcal: R Bindings to the Calendaring Functionality of ’QuantLib’</li>
<li>tidyquant: Tidy Quantitative Financial Analysis</li>
<li>timechange: Efficient Manipulation of Date-Times</li>
<li>timetk: A Tool Kit for Working with Time Series in R</li>
<li>tsbox: Class-Agnostic Time Series</li>
<li>TSrepr: Time Series Representations</li>
<li>xts: eXtensible Time Series</li>
<li>zoo: S3 Infrastructure for Regular and Irregular Time Series</li>
</ul>
<h3>7.19 Dimensionality reduction</h3>
<p><strong>Python</strong>
List of packages/codes/frameworks/links:</p>
<ul>
<li>abess: Fast Best-Subset Selection Library</li>
<li>deeptime: analysis of time series data including dimensionality reduction, clustering, and Markov model
    estimation</li>
<li>direpack: State-of-the-Art Statistical Dimension Reduction Methods</li>
<li>EZyRB: Easy Reduced Basis method ; performs a data-driven model order reduction for parametrized prob-
    lems exploiting the recent approaches.</li>
<li>humap: Hierarchical Manifold Approximation and Projection (HUMAP) is a technique based on UMAP for
    hierarchical non-linear dimensionality reduction.</li>
<li>pyFIt-SNE: FFT-accelerated Interpolation-based t-SNE (FIt-SNE)</li>
<li>scikit-dimension: intrinsic dimension estimation</li>
<li>scikit-learn: machine learning in Python</li>
<li>(t-SNE: t-Distributed Stochastic Neighbor Embedding (t-SNE) for dimensionality reduction</li>
<li>UMAP: Uniform Manifold Approximation and Projection</li>
</ul>
<p><strong>R software implementations</strong>
List of packages and/or codes and/or frameworks and/or links:</p>
<ul>
<li>abess: Fast Best-Subset Selection Library</li>
<li>abundant: High-Dimensional Principal Fitted Components and Abundant Regression</li>
<li>bayesdfa: Bayesian Dynamic Factor Analysis (DFA) with ’Stan’</li>
<li>clustrd: Methods for Joint Dimension Reduction and Clustering</li>
<li>dimRed: A Framework for Dimensionality Reduction</li>
<li>DLPCA: The Distributed Local PCA Algorithm</li>
<li>dobin: Dimension Reduction for Outlier Detection</li>
<li>dyndimred: Dimensionality Reduction Methods in a Common Format</li>
<li>EMD: Empirical Mode Decomposition and Hilbert Spectral Analysis</li>
<li>ForeCA: Forecastable Component Analysis</li>
<li>freqdom: Frequency Domain Based Analysis: Dynamic PCA</li>
<li>ica: Independent Component Analysis</li>
<li>ICtest: Estimating and Testing the Number of Interesting Components in Linear Dimension Reduction</li>
<li>prinvars: Principal Variables (methods for reducing the number of features within a data set)</li>
<li>quantdr: Dimension Reduction Techniques for Conditional Quantiles</li>
<li>
<p>rrpack: Reduced-Rank Regression</p>
</li>
<li>
<p>Rdimtools: Dimension Reduction and Estimation Methods</p>
</li>
<li>RSpectra: Solvers for Large-Scale Eigenvalue and SVD Problems</li>
<li>shrinkTVP: Efficient Bayesian Inference for Time-Varying Parameter Models with Shrinkage</li>
<li>spcr: Sparse Principal Component Regression</li>
<li>SuperPCA: Supervised Principal Component Analysis</li>
<li>svd: Interfaces to Various State-of-Art SVD and Eigensolvers</li>
<li>tapkee: tapkee: Wrapper for ’tapkee’ Dimension Reduction Library</li>
<li>tidydr: Unify Dimensionality Reduction Results</li>
<li>TSrepr: Time Series Representations (dimensionality reduction, preprocessing, feature extraction)</li>
<li>umap: Uniform Manifold Approximation and Projection</li>
</ul>
<h3>7.20 Distances and Similarity.</h3>
<p><strong>Python software implementations</strong>
List of packages and/or codes and/or frameworks and/or links:</p>
<ul>
<li>DataGene: Identify How Similar TS Datasets Are to One Another</li>
<li>dcor: Distance correlation and related E-statistics</li>
<li>dtaidistance: Distance measures for time series</li>
<li>dtw-python: comprehensive implementation of dynamic time warping (DTW) algorithms</li>
<li>faiss: efficient similarity search and clustering of dense vectors</li>
<li>FLANN: Fast Library for Approximate Nearest Neighbors</li>
<li>GraKeL: scikit-learn compatible library for graph kernels</li>
<li>khiva-python: Python binding for Khiva library for time series analytics</li>
<li>mass-ts: MASS (Mueen’s Algorithm for Similarity Search)</li>
<li>MatrixProfile: ime series data mining tasks utilizing matrix profile</li>
<li>matrixprofile-ts: detect patterns and anomalies in massive datasets using Matrix Profile</li>
<li>netrd: library for network {reconstruction, distances, dynamics}</li>
<li>POT : Python Optimal Transport</li>
<li>PyMD: imple but general framework for embedding, called Minimum-Distortion Embedding (MDE), for finite
    sets of items, such as images, biological cells, nodes in a network, or any other abstract object</li>
<li>PySCAMP: SCAlable Matrix Profile</li>
<li>seriesdistancematrix: implements the Series Distance Matrix framework, a flexible component-based frame-
    work that bundles various Matrix Profile related techniques</li>
<li>sktime: unified framework for machine learning with time series by UK national institute for data science and
    artificial intelligence</li>
<li>
<p>Stone-Soup: framework for the development and testing of tracking algorithms</p>
</li>
<li>
<p>stumpy: variety of time series data mining tasks</p>
</li>
<li>tidydr: Unify Dimensionality Reduction Results</li>
<li>timesmash: Quantifier of universal similarity amongst arbitrary data streams without a priori knowledge,
    features, or training</li>
<li>wildboar: Time series learning</li>
</ul>
<p><strong>R software implementations</strong>
List of packages and/or codes and/or frameworks and/or links:</p>
<ul>
<li>dispRity: Measuring Disparity (multidimensional space occupancy)</li>
<li>Distance: Distance Sampling Detection Function and Abundance Estimation</li>
<li>distantia: Assessing Dissimilarity Between Multivariate Time Series</li>
<li>dtw: Dynamic Time Warping Algorithms</li>
<li>dtwclust: Time Series Clustering Along with Optimizations for the Dynamic Time Warping Distance</li>
<li>fICA: Classical, Reloaded and Adaptive FastICA Algorithms</li>
<li>gdm: Generalized Dissimilarity Modeling</li>
<li>IncDTW: Incremental Calculation of Dynamic Time Warping</li>
<li>KernelKnn: Extends the simple k-nearest neighbors algorithm by incorporating numerous kernel functions
    and a variety of distance metrics</li>
<li>MatrixCorrelation: Matrix Correlation Coefficients</li>
<li>mclustcomp: Measures for Comparing Clusters</li>
<li>Mercator: Clustering and Visualizing Distance Matrices</li>
<li>philentropy: Similarity and Distance Quantification Between Probability Functions</li>
<li>proxy: Distance and Similarity Measures</li>
<li>segen: Sequence Generalization Through Similarity Network</li>
<li>tetragon: Automatic Sequence Prediction by Expansion of the Distance Matrix</li>
<li>TSclust: set of measures of dissimilarity between time series to perform time series clustering</li>
<li>TSdist: Distance Measures for Time Series Data</li>
<li>tsmp: UCR Matrix Profile Algorithm</li>
<li>VPdtw: Variable Penalty Dynamic Time Warping</li>
</ul>
<h3>7.21 ESG and Impact Investing.</h3>
<p><strong>Python software implementations</strong>
List of packages and/or codes and/or frameworks and/or links:</p>
<ul>
<li>ESG AI: ESG scoring as an automatic, data-driven process</li>
<li>ESG-BERT: Domain Specific BERT Model for Text Mining in Sustainable Investing</li>
</ul>
<p><strong>R software implementations</strong>
List of packages and/or codes and/or frameworks and/or links:</p>
<ul>
<li>EnvStats: Package for Environmental Statistics, Including US EPA Guidance</li>
<li>ESGBoost: ESG and ECHO-based model for smart investing</li>
<li>gfer: Green Finance and Environmental Risk</li>
<li>text2sdg: Detecting UN Sustainable Development Goals in Text</li>
</ul>
<h3>7.22 Explainability, Interpretability, Fairness, Data Privacy</h3>
<p><strong>Python software implementations</strong>
List of packages and/or codes and/or frameworks and/or links:</p>
<ul>
<li>AIF360: comprehensive set of fairness metrics for datasets and machine learning models, explanations for
    these metrics, and algorithms to mitigate bias in datasets and models</li>
<li>captum: Model interpretability and understanding for PyTorch</li>
<li>CrypTen: framework for Privacy Preserving Machine Learning</li>
<li>Dice-ML: Generate Diverse Counterfactual Explanations for any machine learning model</li>
<li>DoWhy: toolkit by Microsoft for causal inference that supports explicit modeling and testing of causal as-
    sumptions</li>
<li>Interpret: Fit interpretable models by Microsoft. Explain blackbox machine learning</li>
<li>Interpretability dashboard, for understanding model predictions</li>
<li>Lime: Local Interpretable Model-Agnostic Explanations for machine learning classifiers</li>
<li>Lucid: neural network interpretability</li>
<li>PyExplainer: A Local Rule-Based Model-Agnostic Technique</li>
<li>Skater: Model Interpretation/Explanations</li>
<li>transformers-interpret: Model explainability that works seamlessly with transformers</li>
<li>XAI: eXplainability toolbox for machine learning</li>
<li>Xplique: toolkit dedicated to explainability, currently based on Tensorflow</li>
</ul>
<p><strong>R software implementations</strong>
List of packages and/or codes and/or frameworks and/or links:</p>
<ul>
<li>DALEX: moDel Agnostic Language for Exploration and eXplanation</li>
<li>distillML: Model Distillation and Interpretability Methods for Machine Learning Models</li>
<li>fairml: Fair Models in Machine Learning</li>
<li>iml: Interpretable Machine Learning</li>
<li>interpret: Fit Interpretable Machine Learning Models</li>
<li>modelDown: Make Static HTML Website for Predictive Models</li>
<li>
<p>modelStudio: Interactive Studio for Explanatory Model Analysis</p>
</li>
<li>
<p>pdp: Partial Dependence Plots</p>
</li>
<li>pre: Prediction Rule Ensembles</li>
<li>Rforestry: Random Forests, Linear Trees, and Gradient Boosting for Inference and Interpretability</li>
<li>rSAFE: Surrogate-Assisted Feature Extraction</li>
<li>sensitivity: Global Sensitivity Analysis of Model Outputs</li>
<li>triplot: Explaining Correlated Features in Machine Learning Models</li>
<li>yhat: Interpreting Regression Effects</li>
</ul>
<h3>7.23 Features for time series.</h3>
<p><strong>Python software implementations</strong>
List of packages and/or codes and/or frameworks and/or links:</p>
<ul>
<li>cesium: Platform for Time Series Inference</li>
<li>Clairvoyance: a Unified, End-to-End AutoML Pipeline for Medical Time Series</li>
<li>FeatureTools: automated feature engineering</li>
<li>Featurewiz: advanced feature engineering strategies</li>
<li>khiva-python: Python binding for Khiva library for time series analytics</li>
<li>mne-features: MNE-Features software for extracting features from multivariate time series</li>
<li>scikit-learn: machine learning in Python</li>
<li>seglearn: integrated pipeline for segmentation, feature extraction, feature processing, and final estimator</li>
<li>tsfeatures: Calculates various features from time series data</li>
<li>tsfel: extract features from time series</li>
<li>tsflex: Flexible time series feature extraction &amp; processing</li>
<li>tsfresh: extract features from time series</li>
</ul>
<p><strong>R software implementations</strong>
List of packages and/or codes and/or frameworks and/or links:</p>
<ul>
<li>autostsm: Automatic Structural Time Series Models</li>
<li>bfast: Breaks for Additive Season and Trend</li>
<li>entropy: Estimation of Entropy, Mutual Information and Related Quantities</li>
<li>feasts: Feature Extraction and Statistics for Time Series</li>
<li>fsMTS: Feature Selection for Multivariate Time Series</li>
<li>naive: Empirical Extrapolation of Time Feature Patterns</li>
<li>plsVarSel: Variable Selection in Partial Least Squares</li>
<li>MDFS: MultiDimensional Feature Selection</li>
<li>
<p>Rcatch22: Calculation of 22 CAnonical Time-Series CHaracteristics</p>
</li>
<li>
<p>theft: Tools for Handling Extraction of Features from Time Series</p>
</li>
<li>tsfeatures: Time Series Feature Extraction</li>
<li>TSrepr: Time Series Representations (dimensionality reduction, preprocessing, feature extraction)</li>
</ul>
<h3>7.24 Filtering and spectral analysis for time series</h3>
<p><strong>Python software implementations</strong>
List of packages and/or codes and/or frameworks and/or links:</p>
<ul>
<li>FilterPy: Kalman filtering and optimal estimation library</li>
<li>mkl_fft: NumPy-based Python interface to Intel (R) MKL FFT functionality</li>
<li>pyfilter: Particle filtering and sequential parameter inference</li>
<li>PyWavelets: Wavelet Transforms in Python</li>
<li>simdkalman: Kalman filters vectorized as Single Instruction, Multiple Data</li>
<li>Stone-Soup: framework for the development and testing of tracking algorithms</li>
</ul>
<p><strong>R software implementations</strong>
List of packages and/or codes and/or frameworks and/or links:</p>
<ul>
<li>ASSA: Applied Singular Spectrum Analysis (ASSA)</li>
<li>beyondWhittle: Bayesian Spectral Inference for Stationary Time Series</li>
<li>BMAmevt: Multivariate Extremes: Bayesian Estimation of the Spectral Measure</li>
<li>bsamGP: Bayesian Spectral Analysis Models using Gaussian Process Priors</li>
<li>bspec: Bayesian Spectral Inference</li>
<li>cohortBuilder: Data Source Agnostic Filtering Tools</li>
<li>EMD: Empirical Mode Decomposition and Hilbert Spectral Analysis</li>
<li>FKF: Fast Kalman Filter</li>
<li>FKF.SP: Fast Kalman Filtering Through Sequential Processing</li>
<li>frequencyConnectedness: Spectral Decomposition of Connectedness Measures</li>
<li>kalmanfilter: Kalman Filter</li>
<li>KFAS: Kalman Filter and Smoother for Exponential Family State Space Models</li>
<li>kimfilter: Rcpp’ implementation of the multivariate Kim filter, which combines the Kalman and Hamilton
    filters for state probability inference</li>
<li>LMfilteR: Filter Methods for Parameter Estimation in Linear and Non Linear Regression Models</li>
<li>mlr3filters: Filter Based Feature Selection for ’mlr3’</li>
<li>multitaper: Spectral Analysis Tools using the Multitaper Method</li>
<li>neverhpfilter: An Alternative to the Hodrick-Prescott Filter</li>
<li>
<p>praznik: Tools for Information-Based Feature Selection and Scoring</p>
</li>
<li>
<p>psd: Adaptive, Sine-Multitaper Power Spectral Density and Cross Spectrum Estimation</p>
</li>
<li>psdr: Use Time Series to Generate and Compare Power Spectral Density</li>
<li>quantspec: Quantile-Based Spectral Analysis of Time Series</li>
<li>Rfssa: Functional Singular Spectrum Analysis</li>
<li>rhosa: Higher-Order Spectral Analysis</li>
<li>robfilter: Robust Time Series Filters</li>
<li>RobKF: Innovative and/or Additive Outlier Robust Kalman Filtering</li>
<li>RSpectra: Solvers for Large-Scale Eigenvalue and SVD Problems</li>
<li>Rssa: A Collection of Methods for Singular Spectrum Analysis</li>
<li>Rwave: Time-Frequency Analysis of 1-D Signals</li>
<li>SLBDD: Statistical Learning for Big Dependent Data</li>
<li>spectral: Common Methods of Spectral Data Analysis</li>
<li>Spectrum: Fast Adaptive Spectral Clustering for Single and Multi-View Data</li>
<li>spooky: Time Feature Extrapolation Using Spectral Analysis and Jack-Knife Resampling</li>
<li>wavethresh: Wavelets Statistics and Transforms</li>
</ul>
<h3>7.25 Forecasting time series.</h3>
<p><strong>Collections of resources</strong>
List of links:</p>
<ul>
<li>Popular Python Time Series Packages</li>
<li>State of the art research (with codes) on time series forecasting</li>
</ul>
<p><strong>Python software implementations</strong>
List of packages and/or codes and/or frameworks and/or links:</p>
<ul>
<li>anticipy: time series forecasting</li>
<li>atspy: Automated Time Series Models in Python</li>
<li>Autoformer: Decomposition Transformers with Auto-Correlation for Long-Term Series Forecasting</li>
<li>AutoTS: Automated Time Series Forecasting</li>
<li>Auto_TS: Automatically build multiple Time Series models using a Single Line of Code</li>
<li>Clairvoyance: Unified, End-to-End AutoML Pipeline for Medical Time Series</li>
<li>darts: toolkit by Unit8 for easy manipulation and forecasting of time series</li>
<li>ETNA Time Series Library by Tinkoff AI</li>
<li>fbprophet: forecasting toolkit by Facebook</li>
<li>fireTS: multi-variate time series prediction library working with sklearn</li>
<li>
<p>Flow Forecast: Deep learning PyTorch library for time series forecasting, classification, and anomaly detection</p>
</li>
<li>
<p>glum: Generalized linear models</p>
</li>
<li>GluonTS: toolkit by Amazon for Probabilistic time series modeling in Python</li>
<li>greykite: flexible, intuitive and fast forecasting library by LinkedIn</li>
<li>hcrystallball: unifies the API for most commonly used libraries and modeling techniques for time-series
    forecasting in the Python ecosystem</li>
<li>HierarchicalForecast: Hierarchical forecasting with statistical and econometric methods</li>
<li>kats: tookit by Facebook for time series analysis and forecasting</li>
<li>lazypredict: build models without much code</li>
<li>Local Cascade Ensemble (LCE) is a high-performing, scalable and user-friendly machine learning method for
    the general tasks of Classification and Regression</li>
<li>MAPIE: scikit-learn-compatible module for estimating prediction intervals.</li>
<li>Merlion: A Machine Learning Framework for Time Series Intelligence by SalesForce</li>
<li>MLForecast: Scalable machine learning based time series forecasting</li>
<li>NGBoost: Natural Gradient Boosting for Probabilistic Prediction</li>
<li>N-HiTS: Neural Hierarchical Interpolation for Time Series Forecasting</li>
<li>NeuralForecast: time series forecasting with deep learning models</li>
<li>nixtla: Automated time series processing and forecasting</li>
<li>Orbit: Bayesian forecasting package by Uber</li>
<li>piecewise-regression: For fitting straight line models to data with one or more breakpoints where the gradient
    changes</li>
<li>pmdarima: tatistical library designed to fill the void in Python’s time series analysis capabilities</li>
<li>predictionrevisited: implements the core statistical concepts from the book ”Prediction Revisited: The Im-
    portance of Observation”</li>
<li>Prophet: Automatic Forecasting Procedure by Facebook</li>
<li>PyAF: Automatic Time Series Forecasting</li>
<li>PyFlux: modern time series models, nference options (frequentist and Bayesian) that can be applied to these
    models</li>
<li>pyFTS: Fuzzy Time Series for Python</li>
<li>pysf: Supervised forecasting of sequential data by UK national institute for data science and artificial intelli-
    gence</li>
<li>PyTorch Forecasting: Forecasting timeseries with PyTorch - dataloaders, normalizers, metrics and models</li>
<li>pyts: time series classification</li>
<li>pytsal: Time Series analysis, visualization, forecasting along with AutoTS</li>
<li>scikit-hts: Hierarchical Time Series Forecasting</li>
<li>
<p>scikit-learn: machine learning in Python</p>
</li>
<li>
<p>sktime: unified framework for machine learning with time series by UK national institute for data science and
    artificial intelligence</p>
</li>
<li>slearn: package linking symbolic representation with scikit-learn machine learning</li>
<li>statsforecast: Lightning � fast forecasting with statistical and econometric models</li>
<li>Statsmodels: statistical modeling and econometrics in Python</li>
<li>tbats: BATS and TBATS time series forecasting methods</li>
<li>timemachines: Autonomous, univariate, k-step ahead time-series forecasting functions assigned Elo ratings</li>
<li>TIMEX: time series forecasting as a service</li>
<li>TSCV: Time Series CrossValidation</li>
<li>ts-eval: Time Series analysis and evaluation tools</li>
<li>tslearn: machine learning toolkit dedicated to time series data</li>
</ul>
<p><strong>R software implementations</strong>
List of packages and/or codes and/or frameworks and/or links:</p>
<ul>
<li>ACV: Optimal Out-of-Sample Forecast Evaluation and Testing under Stationarity</li>
<li>AIafter: Forecast Combination Using the AI-AFTER Algorithm</li>
<li>arfima: Fractional ARIMA (and Other Long Memory) Time Series Modeling</li>
<li>ATAforecasting: Automatic Time Series Analysis and Forecasting Using the Ata Method</li>
<li>autoTS: Automatic Model Selection and Prediction for Univariate Time Series</li>
<li>baguette: Efficient Model Functions for Bagging</li>
<li>bigtime: Sparse Estimation of Large Time Series Models</li>
<li>BINtools: Bayesian BIN (Bias, Information, Noise) Model of Forecasting</li>
<li>boot.pval: Bootstrap p-Values</li>
<li>caretForecast: Time Series Forecasting Using Caret Infrastructure</li>
<li>cvms: Cross-Validation for Model Selection</li>
<li>dsos: Dataset Shift with Outlier Scores</li>
<li>ensembleBMA: Probabilistic Forecasting using Ensembles and Bayesian Model Averaging</li>
<li>fable: Forecasting Models for Tidy Time Series</li>
<li>fable.ata: ATAforecasting Modelling Interface for fable Framework</li>
<li>fable.prophet: Prophet Modelling Interface for ’fable’</li>
<li>fabletools: Core Tools for Packages in the ’fable’ Framework</li>
<li>FinnTS: Microsoft Finance Time Series Forecasting Framework</li>
<li>flexmix: Flexible Mixture Modeling</li>
<li>
<p>ForeCA: Forecastable Component Analysis</p>
</li>
<li>
<p>ForecastComb: Forecast Combination Methods</p>
</li>
<li>forecastHybrid: Convenient Functions for Ensemble Time Series Forecasts</li>
<li>forecastML: Time Series Forecasting with Machine Learning Methods</li>
<li>forecastSNSTS: Forecasting for Stationary and Non-Stationary Time Series</li>
<li>ForecastTB: Test Bench for the Comparison of Forecast Methods</li>
<li>FoReco: Point Forecast Reconciliation</li>
<li>forecTheta: Forecasting Time Series by Theta Models</li>
<li>fpp3: Data for ”Forecasting: Principles and Practice” (3rd Edition)</li>
<li>fracdiff: Fractionally Differenced ARIMA aka ARFIMA(P,d,q) Models</li>
<li>fwildclusterboot: Fast Wild Cluster Bootstrap Inference for Linear Models</li>
<li>greybox: Toolbox for Model Building and Forecasting</li>
<li>Greymodels: Shiny App for Grey Forecasting Model</li>
<li>hts: Hierarchical and Grouped Time Series</li>
<li>ipred: Improved Predictors</li>
<li>legion: Forecasting Using Multivariate Models</li>
<li>MAPA: Multiple Aggregation Prediction Algorithm</li>
<li>mFLICA: Leadership-Inference Framework for Multivariate Time Series</li>
<li>modeltime: The Tidymodels Extension for Time Series Modeling</li>
<li>modeltime.ensemble: Ensemble Algorithms for Time Series Forecasting with Modeltime</li>
<li>modeltime.gluonts: ’GluonTS’ Deep Learning</li>
<li>modeltime.resample: Resampling Tools for Time Series Forecasting</li>
<li>ngboostForecast: Probabilistic Time Series Forecasting</li>
<li>OOS: Out-of-Sample Time Series Forecasting</li>
<li>origami: Generalized Framework for Cross-Validation</li>
<li>pre: Prediction Rule Ensembles</li>
<li>predtoolsTS: Time Series Prediction Tools</li>
<li>profoc: Probabilistic Forecast Combination Using CRPS Learning</li>
<li>prophet: Automatic Forecasting Procedure</li>
<li>PSF: Forecasting of Univariate Time Series Using the Pattern Sequence-Based Forecasting (PSF) Algorithm</li>
<li>PTSR: Positive Time Series Regression</li>
<li>RFpredInterval: Prediction Intervals with Random Forests and Boosted Forests</li>
<li>rigr: Regression, Inference, and General Data Analysis Tools in R</li>
<li>
<p>Rlgt: Bayesian Exponential Smoothing Models with Trend Modifications</p>
</li>
<li>
<p>robets: Forecasting Time Series with Robust Exponential Smoothing</p>
</li>
<li>robustarima: Robust ARIMA Modeling</li>
<li>scoringfunctions: A Collection of Scoring Functions for Assessing Point Forecasts</li>
<li>scoringRules: Scoring Rules for Parametric and Simulated Distribution Forecasts</li>
<li>scoringutils: Utilities for Scoring and Assessing Predictions</li>
<li>s2dverification: Set of Common Tools for Forecast Verification</li>
<li>see: Visualisation Toolbox for ’easystats’ and Extra Geoms, Themes and Color Palettes for ’ggplot2’</li>
<li>seer: Feature-Based Forecast Model Selection</li>
<li>segmented: Regression Models with Break-Points / Change-Points Estimation</li>
<li>sense: Automatic Stacked Ensemble for Regression Tasks</li>
<li>shrink: Global, Parameterwise and Joint Shrinkage Factor Estimation</li>
<li>SLBDD: Statistical Learning for Big Dependent Data</li>
<li>smooth: Forecasting Using State Space Models</li>
<li>spcr: Sparse Principal Component Regression</li>
<li>SPlit: Split a Dataset for Training and Testing</li>
<li>StabilizedRegression: Stabilizing Regression and Variable Selection</li>
<li>stacks: Tidy Model Stacking</li>
<li>subsemble: An Ensemble Method for Combining Subset-Specific Algorithm Fits</li>
<li>tensorTS: Factor and Autoregressive Models for Tensor Time Series</li>
<li>tfarima: Transfer Function and ARIMA Models</li>
<li>thief: Temporal Hierarchical Forecasting</li>
<li>tidymv: Tidy Model Visualisation for Generalised Additive Models</li>
<li>traineR: Predictive Models Homologator</li>
<li>TSdeeplearning: Deep Learning Model for Time Series Forecasting</li>
<li>tsDyn: Nonlinear Time Series Models with Regime Switching</li>
<li>tsensembler: Dynamic Ensembles for Time Series Forecasting</li>
<li>TSPred: Functions for Benchmarking Time Series Prediction</li>
<li>TSstudio: Functions for Time Series Analysis and Forecasting</li>
<li>tsutils: Time Series Exploration, Modelling and Forecasting</li>
<li>tswge: Time Series for Data Science.Accompanies the texts Time Series for Data Science and Applied Time
    Series Analysis with R,</li>
<li>vars: VAR Modelling</li>
<li>yardstick: Tidy Characterizations of Model Performance</li>
<li>yhat: Interpreting Regression Effects</li>
</ul>
<h3>7.26 Graphs and graphical modeling.</h3>
<p><strong>Python software implementations</strong>
List of packages and/or codes and/or frameworks and/or links:</p>
<ul>
<li>ogb: Benchmark datasets, data loaders, and evaluators for graph machine learning</li>
<li>pathpy: analysis of time series data on networks using higher-order and multi-order graphical models</li>
<li>PGM: Probabilistic Graphical Models</li>
<li>pgmpy: Probabilistic Graphical Models</li>
<li>PGM_PyLib: Inference and Learning of Probabilistic Graphical Models</li>
<li>pyaGrUM: Bayesian networks and other Probabilistic Graphical Models</li>
<li>scikit-network: nalysis of large graphs</li>
<li>skggm: Scikit-learn compatible estimation of general graphical models</li>
<li>vishwakarma: visualization library for Probabilistic Graphical Models, Discrete &amp; Continuous Distributions,
    and a lot more</li>
</ul>
<p><strong>R software implementations</strong>
List of packages and/or codes and/or frameworks and/or links:</p>
<ul>
<li>backbone: Extracts the Backbone from Graphs</li>
<li>deepgp: Deep Gaussian Processes using MCMC</li>
<li>gmgm: Gaussian Mixture Graphical Model Learning and Inference</li>
<li>pcalg: Methods for Graphical Models and Causal Inference</li>
<li>Revticulate: Interaction with ”RevBayes” in R</li>
<li>tgp: Bayesian Treed Gaussian Process Models</li>
<li>tidygraph: A Tidy API for Graph Manipulation</li>
</ul>
<h3>7.27 Linear algebra.</h3>
<p><strong>Python software implementations</strong>
List of packages and/or codes and/or frameworks and/or links:</p>
<ul>
<li>arctic: High performance datastore by Man Group for time series and tick data</li>
<li>PyArma: Linear algebra library for Python</li>
<li>PyArmadillo: an alternative approach to linear algebra in Python</li>
<li>PyPardiso: Python interface to the Intel MKL Pardiso library to solve large sparse linear systems of equations</li>
<li>Scipy: mathematics, science, and engineering</li>
</ul>
<p><strong>R software implementations</strong>
List of packages and/or codes and/or frameworks and/or links:</p>
<ul>
<li>EigenR: Complex Matrix Algebra with ’Eigen’</li>
<li>fastmatrix: Fast Computation of some Matrices Useful in Statistics</li>
<li>freqdom: Frequency Domain Based Analysis: Dynamic PCA</li>
<li>ica: Independent Component Analysis</li>
<li>Matrix: Sparse and Dense Matrix Classes and Methods</li>
<li>MatrixExtra: Extra Methods for Sparse Matrices</li>
<li>matsbyname: An Implementation of Matrix Mathematics</li>
<li>proxyC: Computes Proximity in Large Sparse Matrices</li>
<li>rARPACK: Solvers for Large Scale Eigenvalue and SVD Problems</li>
<li>RcppArmadillo: ’Rcpp’ Integration for the ’Armadillo’ Templated Linear Algebra Library</li>
<li>RcppEigen: ’Rcpp’ Integration for the ’Eigen’ Templated Linear Algebra Library</li>
<li>Rlinsolve: Iterative Solvers for (Sparse) Linear System of Equations</li>
<li>RSpectra: Solvers for Large-Scale Eigenvalue and SVD Problems</li>
<li>sanic: Solving Ax = b Nimbly in C++</li>
<li>SparseChol: Sparse Cholesky LDL Decomposition of Symmetric Matrices</li>
<li>SparseM: Sparse Linear Algebra</li>
<li>svd: Interfaces to Various State-of-Art SVD and Eigensolvers</li>
</ul>
<h3>7.28 Machine Learning.</h3>
<p><strong>Collections of resources</strong>
List of links:</p>
<ul>
<li>Curated list of open source libraries to deploy, monitor, version and scale machine learning</li>
<li>Dive into Machine Learning</li>
<li>Artificial Intelligence and Machine Learning For Quantum Technologies</li>
</ul>
<p><strong>Python software implementations</strong>
List of packages and/or codes and/or frameworks and/or links:</p>
<ul>
<li>abess: Fast Best Subset Selection</li>
<li>AIF360: comprehensive set of fairness metrics for datasets and machine learning models, explanations for
    these metrics, and algorithms to mitigate bias in datasets and models</li>
<li>benchmark_VAE: Unifying Generative Autoencoder implementations in Python</li>
<li>bindsnet: Simulation of spiking neural networks (SNNs) using PyTorch</li>
<li>
<p>biosphere: Simple, fast random forests</p>
</li>
<li>
<p>Catalyst: PyTorch framework for Deep Learning Research and Development</p>
</li>
<li>catboost: Gradient Boosting on Decision Trees by Yandex</li>
<li>Chainer: flexible framework of neural networks for deep learning</li>
<li>combo: A Python Toolbox for Machine Learning Model Combination</li>
<li>compose: machine learning tool for automated prediction engineering</li>
<li>coremltools: convert machine learning models from third-party libraries to the Core ML format (by Apple)</li>
<li>CrypTen: framework for Privacy Preserving Machine Learning</li>
<li>DeepChecks: Testing and Validating ML Models and Data</li>
<li>DoubleML: Double Machine Learning in Python</li>
<li>Driblet - Google Cloud based ML pipeline by Google</li>
<li>geotorch: Constrained optimization toolkit for PyTorch</li>
<li>GPyTorch: Gaussian processes for modern machine learning systems.</li>
<li>Hub for Tensorflow: library for transfer learning by reusing parts of TensorFlow models</li>
<li>Hummingbird: library by Microsoft for compiling trained traditional ML models into tensor computations</li>
<li>InvarianceUnitTests: Linear unit-tests for invariance discovery</li>
<li>JAX: toolkit by Google for composable transformations of Python+NumPy programs: differentiate, vectorize,
    JIT to GPU/TPU, and more</li>
<li>jraph: Graph Neural Network Library in Jax</li>
<li>karateclub: Framework for Unsupervised Learning on Graphs</li>
<li>keras: deep learning API written in Python, running on top of the machine learning platform TensorFlow</li>
<li>Local Cascade Ensemble (LCE) is a high-performing, scalable and user-friendly machine learning method for
    the general tasks of Classification and Regression</li>
<li>LightGBM: fast, distributed, high performance gradient boosting (GBT, GBDT, GBRT, GBM or MART)
    framework by Microsoft</li>
<li>Merlion: A Machine Learning Framework for Time Series Intelligence by SalesForce</li>
<li>mlflow: Interface to ’MLflow’</li>
<li>MLForecast: Scalable machine learning based time series forecasting</li>
<li>mlinsights: Extends scikit-learn with new models, transformers, metrics, plotting.</li>
<li>MLJAR Automated Machine Learning for Humans</li>
<li>mlxtend: extension and helper modules for Python’s data analysis and machine learning libraries.</li>
<li>MMdnn: toolkit by Microsoft to convert models between Caffe, Keras, MXNet, Tensorflow, CNTK, PyTorch
    Onnx and CoreML.</li>
<li>Model Garden for TensorFlow</li>
<li>
<p>mvlearn is an open-source Python software package for multiview learning tools.</p>
</li>
<li>
<p>NannyM: estimate post-deployment model performance (without access to targets), detect data drift, and
    intelligently link data drift alerts back to changes in model performance</p>
</li>
<li>NeuralForecast: time series forecasting with deep learning models</li>
<li>NGBoost: Natural Gradient Boosting for Probabilistic Prediction</li>
<li>nimbusml: toolkit by Microsoft that provides Python bindings for ML.NET</li>
<li>nolearn: Combines the ease of use of scikit-learn with the power of Theano/Lasagne</li>
<li>norse: Deep learning with spiking neural networks (SNNs) in PyTorch.</li>
<li>OPACUS: Training PyTorch models with differential privacy</li>
<li>ptgnn: PyTorch Graph Neural Network Library</li>
<li>PyCaret : machine learning library</li>
<li>PyTorch: Tensors and Dynamic neural networks in Python with strong GPU acceleration</li>
<li>PyTorch Lightning: lightweight PyTorch wrapper for ML researchers</li>
<li>Ray: packaged with RLlib, a scalable reinforcement learning library, and Tune, a scalable hyperparameter
    tuning librar</li>
<li>scikit-learn: machine learning in Python</li>
<li>scikit-learn-intelex: Intel Extension for Scikit-learn</li>
<li>sklearn-onnx converts scikit-learn models to ONNX</li>
<li>skorch: scikit-learn compatible neural network library that wraps PyTorch</li>
<li>SNNTORCH: Deep and online learning with spiking neural networks</li>
<li>tensorflow: end-to-end open source platform for machine learning</li>
<li>tf2onnx: Convert TensorFlow, Keras, Tensorflow.js and Tflite models to ONNX</li>
<li>Transfer Learning Library for Domain Adaptation, Task Adaptation, and Domain Generalization</li>
<li>transformers: State-of-the-art Machine Learning for Pytorch, TensorFlow, and JAX</li>
<li>Trax: Deep Learning by Google with Clear Code and Speed</li>
<li>tslearn: machine learning toolkit dedicated to time-series data</li>
<li>xformers: Hackable and optimized Transformers building blocks, supporting a composable construction</li>
<li>yellowbrick: Visual analysis and diagnostic tools to facilitate machine learning model selection</li>
</ul>
<p><strong>R software implementations</strong>
List of packages and/or codes and/or frameworks and/or links:</p>
<ul>
<li>abess: Fast Best Subset Selection</li>
<li>agua: ’tidymodels’ Integration with ’h2o’</li>
<li>APML: An Approach for Machine-Learning Modelling</li>
<li>arenar: Arena for the Exploration and Comparison of any ML Models</li>
<li>
<p>brulee: High-Level Modeling Functions with ’torch’</p>
</li>
<li>
<p>distillML: Model Distillation and Interpretability Methods for Machine Learning Models</p>
</li>
<li>elmNNRcpp: The Extreme Learning Machine Algorithm</li>
<li>fairmodels: Flexible Tool for Bias Detection, Visualization, and Mitigation</li>
<li>familiar: End-to-End Automated Machine Learning and Model Evaluation</li>
<li>KernelKnn: Extends the simple k-nearest neighbors algorithm by incorporating numerous kernel functions
    and a variety of distance metrics</li>
<li>lightgbm: Light Gradient Boosting Machine by Microsoft</li>
<li>MachineShop: Machine Learning Models and Tools</li>
<li>mcboost: Multi-Calibration Boosting</li>
<li>MetricsWeighted: Weighted Metrics, Scoring Functions and Performance Measures for Machine Learning</li>
<li>mikropml: User-Friendly R Package for Supervised Machine Learning Pipelines</li>
<li>mlflow: Interface to ’MLflow’</li>
<li>mlquantify: Algorithms for Class Distribution Estimation</li>
<li>mlr3: Machine Learning in R - Next Generation</li>
<li>mlr3cluster: Cluster Extension for ’mlr3’</li>
<li>mlr3learners: Recommended Learners for ’mlr3’</li>
<li>mlr3tuning: hyperparameter tuning with ’mlr3’</li>
<li>mlr3verse: package family is a set of packages for machine-learning purposes built in a modular fashion</li>
<li>mlr3viz: Visualizations for’mlr3</li>
<li>mlrintermbo: Model-Based Optimization for ’mlr3’ Through ’mlrMBO’</li>
<li>mlrMBO: Bayesian Optimization and Model-Based Optimization of Expensive Black-Box Functions</li>
<li>multiview: Cooperative Learning for Multi-View Analysis</li>
<li>rTorch: R Bindings to ’PyTorch’</li>
<li>SPlit: Split a Dataset for Training and Testing</li>
<li>tensorflow: R Interface to ’TensorFlow’</li>
<li>tfdatasets: Interface to ’TensorFlow’ Datasets</li>
<li>tfprobability: Interface to ’TensorFlow Probability’</li>
<li>TSdeeplearning: Deep Learning Model for Time Series Forecasting</li>
<li>xgboost: Extreme Gradient Boosting</li>
</ul>
<h3>7.29 Machine Learning frameworks (includes Automated ML and hyperparameters tuning)</h3>
<p><strong>Python software implementations</strong>
List of packages and/or codes and/or frameworks and/or links:</p>
<ul>
<li>AI2 Tango: library for choreographing machine learning research</li>
<li>AutoGluon: toolkit by Amazon on AutoML for Text, Image, and Tabular Data</li>
<li>AutoKeras: An AutoML system based on Keras</li>
<li>AutoPyTorch: Automatic architecture search and hyperparameter optimization for PyTorch</li>
<li>auto-sklearn: Automated Machine Learning with scikit-learn</li>
<li>BayesianOptimization: global optimization with gaussian processes.</li>
<li>cesium: Machine Learning Time-Series Platform</li>
<li>Clairvoyance: Unified, End-to-End AutoML Pipeline for Medical Time Series</li>
<li>Colossal-AI: A Unified Deep Learning System for Big Model Era</li>
<li>EvalML is an AutoML library which builds, optimizes, and evaluates machine learning pipelines using domain-
    specific objective functions.</li>
<li>FLAML: accurate machine learning models automatically, efficiently and economically (by Microsoft)</li>
<li>flax: neural network library for JAX that is designed for flexibility</li>
<li>H2O is an Open Source, Distributed, Fast &amp; Scalable Machine Learning Platform</li>
<li>Hypernets: General Automated Machine Learning framework</li>
<li>HyperOpt: Distributed Asynchronous Hyperparameter Optimization</li>
<li>hyperopt-sklearn: Hyper-parameter optimization for sklearn</li>
<li>kedro: framework for creating reproducible, maintainable and modular data science code</li>
<li>kedro-viz: Visualise your Kedro data and machine-learning pipelines and track your experiments.</li>
<li>keras-tuner: hyperparameter optimization framework</li>
<li>MLBox: Automated Machine Learning library</li>
<li>mlpack: ’Rcpp’ Integration for the ’mlpack’ Library</li>
<li>mlr3tuning: Tuning for ’mlr3’</li>
<li>model_search: framework (by Google) that implements AutoML algorithms for model architecture search at
    scale</li>
<li>NannyM: estimate post-deployment model performance (without access to targets), detect data drift, and
    intelligently link data drift alerts back to changes in model performance</li>
<li>NNI: toolkit by Microsoft to help users automate Feature Engineering, Neural Architecture Search, Hyperpa-
    rameter Tuning and Model Compression</li>
<li>oneflow: OneFlow is a deep learning framework designed to be user-friendly, scalable and efficient.</li>
<li>
<p>ONNX: Open Neural Network Exchange is an Open standard for machine learning interoperability</p>
</li>
<li>
<p>Optuna: hyperparameter optimization framework</p>
</li>
<li>PyCaret : machine learning library</li>
<li>squirrel-core: library that enables ML teams to share, load, and transform data in a collaborative, flexible,
    and efficient way.</li>
<li>Relevance AI - The ML Platform for Unstructured Data Analysis</li>
<li>Talos: Hyperparameter Optimization for TensorFlow, Keras and PyTorch</li>
<li>trax: end-to-end library (by Google Brain) for deep learning that focuses on clear code and speed.</li>
<li>tune-sklearn: drop-in replacement for Scikit-Learn’s GridSearchCV / RandomizedSearchCV – but with cutting
    edge hyperparameter tuning techniques</li>
<li>vowpal_wabbit: machine learning system which pushes the frontier of machine learning with techniques such
    as online, hashing, allreduce, reductions, learning2search, active, and interactive learning</li>
</ul>
<p><strong>R software implementations</strong>
List of packages and/or codes and/or frameworks and/or links:</p>
<ul>
<li>autokeras: R Interface to ’AutoKeras’</li>
<li>automl: Deep Learning with Metaheuristic</li>
<li>DriveML: Self-Drive Machine Learning Projects</li>
<li>familiar: End-to-End Automated Machine Learning and Model Evaluation</li>
<li>mlpack: ’Rcpp’ Integration for the ’mlpack’ Library</li>
<li>mlr3tuningspaces: Search Spaces for Hyperparameter Tuning</li>
<li>ParBayesianOptimization: Parallel Bayesian Optimization of Hyperparameters</li>
<li>rBayesianOptimization: Bayesian Optimization of Hyperparameters</li>
<li>RemixAutoML: automation of machine learning, forecasting, feature engineering, model evaluation, model
    interpretation, recommenders, and EDA.</li>
</ul>
<h3>7.30 Network and graph analysis.</h3>
<p><strong>Python software implementations</strong>
List of packages and/or codes and/or frameworks and/or links:</p>
<ul>
<li>dantro: handle, transform, and visualize hierarchically structured data</li>
<li>deeptime: nalysis of time series data including dimensionality reduction, clustering, and Markov model esti-
    mation</li>
<li>ETNA Time Series Library by Tinkoff AI</li>
<li>fastpath: find the path through a network of nodes</li>
<li>GraKeL: scikit-learn compatible library for graph kernels</li>
<li>grapharray: handle network link/node attributes as Numpy arrays</li>
<li>GraphVite: A General and High-performance Graph Embedding System</li>
<li>
<p>karateclub: Framework for Unsupervised Learning on Graphs</p>
</li>
<li>
<p>netrd: etwork {reconstruction, distances, dynamics}</p>
</li>
<li>networkit: toolkit for large-scale network analysis</li>
<li>NetworkX: Network Analysis in Python</li>
<li>pandana: Pandas Network Analysis: fast accessibility metrics and shortest paths, using contraction hierarchies</li>
<li>pyvis: visualizing interactive network graphs</li>
<li>rustworkx: high performance Python graph library implemented in Rust</li>
<li>scikit-learn: machine learning in Python</li>
<li>tslearn: machine learning toolkit dedicated to time-series data</li>
</ul>
<p><strong>R software implementations</strong>
List of packages and/or codes and/or frameworks and/or links:</p>
<ul>
<li>backbone: identify the most ‘important’ or ‘significant’ edges in a network</li>
<li>bnmonitor: An Implementation of Sensitivity Analysis in Bayesian Networks</li>
<li>bootnet: Bootstrap Methods for Various Network Estimation Routines</li>
<li>CINNA: Deciphering Central Informative Nodes in Network Analysis</li>
<li>dbnR: Dynamic Bayesian Network Learning and Inference</li>
<li>diceR: Diverse Cluster Ensemble in R</li>
<li>dtwclust: Time Series Clustering Along with Optimizations for the Dynamic Time Warping Distance</li>
<li>fabisearch: Change Point Detection in High-Dimensional Time Series Networks</li>
<li>fastkmedoids: Faster K-Medoids Clustering Algorithms: FastPAM, FastCLARA, FastCLARANS</li>
<li>gRain: Graphical Independence Networks</li>
<li>heatmaply: Interactive Cluster Heat Maps Using ’plotly’ and ’ggplot2’</li>
<li>influential: Identification and Classification of the Most Influential Nodes</li>
<li>MatTransMix: Clustering with Matrix Gaussian and Matrix Transformation Mixture Models</li>
<li>Mercator: Clustering and Visualizing Distance Matrices</li>
<li>MixSim: Simulating Data to Study Performance of Clustering Algorithms</li>
<li>mixture: Mixture Models for Clustering and Classification</li>
<li>MKMeans: A Modern K-Means (MKMeans) Clustering Algorithm</li>
<li>ndtv: Network Dynamic Temporal Visualizations</li>
<li>network: Classes for Relational Data</li>
<li>networkABC: Network Reverse Engineering with Approximate Bayesian Computation</li>
<li>networkDynamic: Dynamic Extensions for Network Objects</li>
<li>NetworKit: tool suite for high-performance network analysis</li>
<li>
<p>networktools: Tools for Identifying Important Nodes in Networks</p>
</li>
<li>
<p>statnet: Software Tools for the Statistical Analysis of Network Data</p>
</li>
<li>visNetwork: Network Visualization using ’vis.js’ Library</li>
<li>wdnet: Weighted and Directed Networks</li>
<li>WGCNA: Weighted Correlation Network Analysis</li>
</ul>
<h3>7.31 Numerical methods (includes numerical optimization)</h3>
<p><strong>Python software implementations</strong>
List of packages and/or codes and/or frameworks and/or links:</p>
<ul>
<li>ADE: Asynchronous Differential Evolution, with efficient multiprocessing</li>
<li>autoray: Write numeric code that automatically works with any numpy-ish libraries</li>
<li>BayesianOptimization: global optimization with gaussian processes</li>
<li>CasADi is a symbolic framework for numeric optimization implementing automatic differentiation in forward
    and reverse modes on sparse matrix-valued computational graphs</li>
<li>cmaes: Covariance Matrix Adaptation Evolution Strategy (CMA-ES)</li>
<li>coco: Numerical Black-Box Optimization Benchmarking Framework</li>
<li>cp_solver: CP-SAT Solver by Google</li>
<li>cvxopt: convex optimization</li>
<li>cvxpy: convex optimization</li>
<li>DEAP: Distributed Evolutionary Algorithms in Python</li>
<li>derivative: Numerical differentiation of noisy time series data</li>
<li>Differential Evolution expensiveopt</li>
<li>eigenpy: Efficient Python bindings between Numpy/Eigen</li>
<li>ELA drframework: Dimensionality Reduction Framework for Exploratory Landscape Analysis</li>
<li>evol: grammar for evolutionary algorithms and heuristics</li>
<li>fcmaes complements scipy optimize by providing additional optimization methods, faster C++/Eigen based
    implementations and a coordinated parallel retry mechanism.</li>
<li>gemseo: Generic Engine for Multi-disciplinary Scenarios, Exploration and Optimization</li>
<li>General Purpose Optimization Library GPOL</li>
<li>HiGHS: Linear optimization</li>
<li>hyperactive: optimization and data collection toolbox for convenient and fast prototyping of computationally
    expensive models</li>
<li>ipopt: Cython interface for the interior point optimzer IPOPT</li>
<li>ipyopt: interface for the interior point optimizer COIN-OR IPOpt</li>
<li>mystic: highly-constrained non-convex optimization and uncertainty quantification</li>
<li>
<p>nevergrad: Python toolbox for performing gradient-free optimization by Facebook</p>
</li>
<li>
<p>nlopt: nonlinear optimization</p>
</li>
<li>Open MDAO: optimization framework</li>
<li>optima: library for numerical optimization calculations</li>
<li>OR-Tools: optimization toolkit by Google</li>
<li>osqp: Operator Splitting QP Solver</li>
<li>pybobyqa: Derivative-Free Optimization with Bound Constraints</li>
<li>pycma: Covariance Matrix Adaptation Evolution Strategy (CMA-ES)</li>
<li>pymoo: Multi-objective Optimization</li>
<li>pyomo: supports a diverse set of optimization capabilities for formulating and analyzing optimization models.</li>
<li>PyOptSparse: object-oriented framework for formulating and solving nonlinear constrained optimization prob-
    lems</li>
<li>PyPDE: solve partial differential equations using finite differences.</li>
<li>qpsolvers: Quadratic programming solvers in Python with a unified API</li>
<li>root_numpy: interface between ROOT and NumPy</li>
<li>scikit-opt: Swarm Optimization methods</li>
<li>scikit-optimize: Sequential model-based optimization with a ‘scipy.optimize‘ interface</li>
<li>Scipy: Fundamental algorithms for scientific computing</li>
<li>SHADE: Success-History Based Parameter Adaptation for Differential Evolution</li>
<li>stgaircase: data analysis package based on mathematical step functions</li>
<li>theseus: differentiable nonlinear optimization</li>
<li>torchquad: High-performance numerical integration on the GPU with PyTorch, JAX and Tensorflow</li>
<li>torchsde: Differentiable SDE solvers with GPU support and efficient sensitivity analysis</li>
<li>trust-region:trust-region subproblem solvers for nonlinear optimization</li>
</ul>
<p><strong>R software implementations</strong>
List of packages and/or codes and/or frameworks and/or links:</p>
<ul>
<li>ao: Alternating Optimization</li>
<li>bbotk: Black-Box Optimization Toolkit</li>
<li>CGNM: Cluster Gauss-Newton Method: Find multiple solutions of a nonlinear least squares problem</li>
<li>CVXR: Disciplined Convex Optimization</li>
<li>DEoptim: Global Optimization by Differential Evolution</li>
<li>DEoptimR: Differential Evolution Optimization in Pure R</li>
<li>ECOSolveR: Embedded Conic Solver in R</li>
<li>
<p>ggblanket: Simplify ’ggplot2’ Visualisation</p>
</li>
<li>
<p>graDiEnt: derivative-free, optim-style Stochastic Quasi-Gradient Differential Evolution optimization</p>
</li>
<li>itp: The Interpolate, Truncate, Project (ITP) Root-Finding Algorithm</li>
<li>LowRankQP: Low Rank Quadratic Programming</li>
<li>miesmuschel: Mixed Integer Evolution Strategies</li>
<li>minqa: Derivative-Free Optimization Algorithms by Quadratic Approximation</li>
<li>mlr3mbo: Flexible Bayesian Optimization</li>
<li>NMOF: Numerical Methods and Optimization in Finance</li>
<li>osqp: Quadratic Programming Solver using the ’OSQP’ Library</li>
<li>RcppEnsmallen: Header-Only C++ Mathematical Optimization Library for ’Armadillo’</li>
<li>rvinecopulib: High Performance Algorithms for Vine Copula Modeling</li>
<li>rgenoud: R Version of GENetic Optimization Using Derivatives</li>
<li>rmoo: Multi-Objective Optimization in R</li>
<li>scs: Splitting Conic Solver for linear programs (’LPs’), second-order cone programs (’SOCPs’), semidefinite
    programs (’SDPs’), exponential cone programs (’ECPs’), and power cone programs (’PCPs’), or problems
    with any combination of those cone</li>
<li>SimEngine: A Modular Framework for Statistical Simulations in R</li>
<li>trustOptim: Trust Region Optimization for Nonlinear Functions with Sparse Hessians</li>
</ul>
<h3>7.32 Probabilistic modeling (includes mixture models and Gaussian Processes)</h3>
<p>Links to resources</p>
<ul>
<li>Professionally curated list of awesome Conformal Prediction videos, tutorials, books, papers, PhD and MSc
    theses, articles and open-source libraries</li>
</ul>
<p><strong>Python software implementations</strong>
List of packages and/or codes and/or frameworks and/or links:</p>
<ul>
<li>beanmachine: inference on probabilistic models</li>
<li>celerite2: fast and scalable Gaussian Process (GP) Regression</li>
<li>conformal-rnn: code for ”Conformal time-series forecasting”, NeurIPS 2021</li>
<li>crepes: Conformal Regressors and Conformal Predictive Systems</li>
<li>EnbPI: Ensemble batch prediction intervals</li>
<li>EnCQR: ensemble conformalized quantile regression (EnCQR)</li>
<li>GluonTS: toolkit by Amazon for Probabilistic time series modeling in Python</li>
<li>gptools: Gaussian processes with arbitrary derivative constraints and predictions.</li>
<li>GPy: Gaussian processes framework</li>
<li>GPyTorch: Gaussian processes for modern machine learning systems.</li>
<li>
<p>MAPIE: scikit-learn-compatible module for estimating prediction intervals</p>
</li>
<li>
<p>NGBoost: Natural Gradient Boosting for Probabilistic Prediction</p>
</li>
<li>orbit-ml: Bayesian forecasting package by Uber</li>
<li>pgmpy: Probabilistic Graphical Models – learning (Structure and Parameter), inference (Probabilistic and
    Causal), and simulations in Bayesian Networks</li>
<li>pplbench: Evaluation Framework for Probabilistic Programming Languages</li>
<li>PyMC: Bayesian Modeling and Probabilistic Machine Learning with Aesara</li>
<li>pyro: Deep universal probabilistic programming with Python and PyTorch</li>
<li>PySloth: Probabilistic Prediction</li>
<li>skpro: toolkit by UK national institute for data science and artificial intelligence for Supervised domain-
    agnostic prediction framework for probabilistic modelling</li>
<li>tinyGP: The tiniest of Gaussian Process libraries</li>
<li>zhusuan: probabilistic programming library for Bayesian deep learning, generative models, based on Tensor-
    flow</li>
</ul>
<p><strong>R software implementations</strong>
List of packages and/or codes and/or frameworks and/or links:</p>
<ul>
<li>AdequacyModel: Adequacy of Probabilistic Models and General Purpose Optimization</li>
<li>AdMit: Adaptive Mixture of Student-t Distributions</li>
<li>aldvmm: Adjusted Limited Dependent Variable Mixture Models</li>
<li>bgmm: Gaussian Mixture Modeling Algorithms and the Belief-Based Mixture Modeling</li>
<li>bmixture: Bayesian Estimation for Finite Mixture of Distributions</li>
<li>BNPmix: Bayesian Nonparametric Mixture Models</li>
<li>bpgmm: Bayesian Model Selection Approach for Parsimonious Gaussian Mixture Models</li>
<li>ClusterR: Gaussian Mixture Models, K-Means, Mini-Batch-Kmeans, K-Medoids and Affinity Propagation
    Clustering</li>
<li>conformalInference.multi: Conformal Inference Tools for Regression with Multivariate Response</li>
<li>DistributionOptimization: Distribution Optimization</li>
<li>distributionsrd: Distribution Fitting and Evaluation</li>
<li>EMCluster: EM Algorithm for Model-Based Clustering of Finite Mixture Gaussian Distribution</li>
<li>evmix: Extreme Value Mixture Modelling, Threshold Estimation and Boundary Corrected Kernel Density
    Estimation</li>
<li>flexmix: Flexible Mixture Modeling</li>
<li>flexmixNL: Finite Mixture Modeling of Generalized Nonlinear Models</li>
<li>GauPro: Gaussian Process Fitting</li>
<li>gmgm: Gaussian Mixture Graphical Model Learning and Inference</li>
<li>
<p>greta.gp: Gaussian Process Modelling in ’greta’</p>
</li>
<li>
<p>hmmr: ”Mixture and Hidden Markov Models with R” Datasets and Example Code</p>
</li>
<li>ltmix: Left-Truncated Mixtures of Gamma, Weibull, and Lognormal Distributions</li>
<li>MatrixMixtures: Model-Based Clustering via Matrix-Variate Mixture Models</li>
<li>MGMM: Missingness Aware Gaussian Mixture Models</li>
<li>mistr: Mixture and Composite Distributions</li>
<li>mixComp: Estimation of Order of Mixture Distributions</li>
<li>MixMatrix: Classification with Matrix Variate Normal and t Distributions</li>
<li>MixSim: Simulating Data to Study Performance of Clustering Algorithms</li>
<li>mixsmsn: Fitting Finite Mixture of Scale Mixture of Skew-Normal Distributions</li>
<li>mixreg: Functions to Fit Mixtures of Regressions</li>
<li>mixSPE: Mixtures of Power Exponential and Skew Power Exponential Distributions for Use in Model-Based
    Clustering and Classification</li>
<li>mixsqp: Sequential Quadratic Programming for Fast Maximum-Likelihood Estimation of Mixture Proportions</li>
<li>mixtools: Tools for Analyzing Finite Mixture Models</li>
<li>mixture: Mixture Models for Clustering and Classification</li>
<li>mclust: Gaussian Mixture Modelling for Model-Based Clustering, Classification, and Density Estimation</li>
<li>mlr3proba: Probabilistic Supervised Learning for ’mlr3’</li>
<li>MoMPCA: Inference and Clustering for Mixture of Multinomial Principal Component Analysis</li>
<li>mvgb: Multivariate Probabilities of Scale Mixtures of Multivariate Normal Distributions via the Genz and
    Bretz (2002) QRSVN Method</li>
<li>ngboostForecast: Probabilistic Time Series Forecasting</li>
<li>nlsmsn: Fitting Nonlinear Models with Scale Mixture of Skew-Normal Distributions</li>
<li>Nmix: Bayesian Inference on Univariate Normal Mixtures</li>
<li>nvmix: Multivariate Normal Variance Mixtures</li>
<li>opGMMassessment: Optimized Automated Gaussian Mixture Assessment</li>
<li>pgmm: Parsimonious Gaussian Mixture Models</li>
<li>pGPx: Pseudo-Realizations for Gaussian Process Excursions</li>
<li>pks: Probabilistic Knowledge Structures</li>
<li>plgp: Particle Learning of Gaussian Processes</li>
<li>plotmm: Tidy Tools for Visualizing Mixture Models</li>
<li>QuantileGH: Quantile Least Mahalanobis Distance Estimator for Tukey g-&amp;-h Mixture</li>
<li>rebmix: Finite Mixture Modeling, Clustering &amp; Classification</li>
<li>Revticulate: Interaction with ”RevBayes” in R</li>
<li>
<p>RGMM: Robust Mixture Model</p>
</li>
<li>
<p>RMixtComp: Mixture Models with Heterogeneous and (Partially) Missing Data</p>
</li>
<li>robmixglm: Robust Generalized Linear Models (GLM) using Mixtures</li>
<li>Rmixmod: Classification with Mixture Modelling</li>
<li>RobMixReg: Robust Mixture Regression</li>
<li>rrMixture: Reduced-Rank Mixture Models</li>
<li>seqHMM: Mixture Hidden Markov Models for Social Sequence Data and Other Multivariate, Multichannel
    Categorical Time Series</li>
<li>skewlmm: Scale Mixture of Skew-Normal Linear Mixed Models</li>
<li>skewMLRM: Estimation for Scale-Shape Mixtures of Skew-Normal Distributions</li>
<li>uGMAR: Estimate Univariate Gaussian and Student’s t Mixture Autoregressive Models</li>
</ul>
<h3>7.33 Reinforcement learning.</h3>
<p><strong>Collections of resources</strong>
List of links:</p>
<ul>
<li>Awesome Reinforcement Learning: Reinforcement learning resources curated</li>
<li>Awesome Deep RL: curated list of awesome Deep Reinforcement Learning resources</li>
</ul>
<p><strong>Python software implementations</strong>
List of packages and/or codes and/or frameworks and/or links:</p>
<ul>
<li>Acme: a research framework by DeepMind for reinforcement learning</li>
<li>Baconian: Model-based Reinforcement Learning Framework</li>
<li>Open AI Baselines: high-quality implementations by OpenAI of reinforcement learning algorithms</li>
<li>Catalyst.RL: Distributed Framework for Reproducible RL Research</li>
<li>ChainerRL: deep reinforcement learning library built on top of Chainer</li>
<li>Coach: Reinforcement Learning by Intel AI Lab</li>
<li>d3rlpy: offline deep reinforcement learning library</li>
<li>Decision Transformer: Reinforcement Learning via Sequence Modeling</li>
<li>DRL with PyTorch: PyTorch implementations of deep reinforcement learning algorithms and environments</li>
<li>Deep Reinforcement Learning Hands-On</li>
<li>deer: DEEp Reinforcement learning framework</li>
<li>Dopamine: research framework by Google for fast prototyping of reinforcement learning algorithms</li>
<li>ElegantRL: Lightweight and scalable deep reinforcement learning using PyTorch</li>
<li>FinRL: Deep Reinforcement Learning for Quantitative Finance</li>
<li>FinRL-Meta: Universe of Near-Real Market Environments for Data-Driven Financial Reinforcement Learning</li>
<li>
<p>garage: toolkit for reproducible reinforcement learning research</p>
</li>
<li>
<p>Gym: ttolkit by openAI for toolkit for developing and comparing reinforcement learning algorithms</p>
</li>
<li>HRAC: Generating Adjacency-Constrained Subgoals in Hierarchical Reinforcement Learning</li>
<li>keras-rl: Deep Reinforcement Learning for Keras</li>
<li>Mava: library of multi-agent reinforcement learning components and systems</li>
<li>Multi-Agent Resource Optimization (MARO) platform is an instance of Reinforcement Learning as a Service
    (RaaS) for real-world resource optimization problems.</li>
<li>MBRL-Lib: toolbox by Facebook for facilitating development of Model-Based Reinforcement Learning algo-
    rithms</li>
<li>Mushroom RL: modular toolkit able to use modularity allows to use libraries for tensor computation (e.g.
    PyTorch, Tensorflow) and RL benchmarks (e.g. OpenAI Gym, PyBullet, Deepmind Control Suite)</li>
<li>PettingZoo: Gym for multi-agent reinforcement learning</li>
<li>PFRL: PyTorch-based deep reinforcement learning library</li>
<li>PGPortfolio: Policy Gradient Portfolio</li>
<li>PyTorchRL: reinforcement learning library focused on modularity and simplicity</li>
<li>Rainbow: Combining Improvements in Deep Reinforcement Learning</li>
<li>ReAgent: platform by Facebook for Reasoning systems (Reinforcement Learning, Contextual Bandits, etc.)</li>
<li>rl: modular, primitive-first, python-first PyTorch library for Reinforcement Learning.</li>
<li>RLkit: Collection of reinforcement learning algorithms</li>
<li>RLlib: Ray is packaged with RLlib, a scalable reinforcement learning library, and Tune, a scalable hyperpa-
    rameter tuning librar</li>
<li>RLMeta is a light-weight flexible framework for Distributed Reinforcement Learning Research</li>
<li>rlpyt: Reinforcement Learning in PyTorch</li>
<li>rlstructures: Facebook library to facilitate the implementation of new reinforcement learning algorithms</li>
<li>skrl: Modular reinforcement learning</li>
<li>Stable Baselines3: PyTorch version of Stable Baselines, reliable implementations of reinforcement learning
    algorithms</li>
<li>Tensorforce: TensorFlow library for applied reinforcement learning</li>
<li>TensorLayer: Deep Learning and Reinforcement Learning Library for Scientists and Engineers</li>
<li>TF-Agents: TensorFlow library for Contextual Bandits and Reinforcement Learning</li>
<li>Tianshou: PyTorch deep reinforcement learning library</li>
<li>Tonic RL: Tonic RL library</li>
<li>TorchBeast: A PyTorch Platform by Facebook for Distributed RL</li>
<li>TRFL: TensorFlow Reinforcement Learning by DeepMind</li>
<li>vowpal_wabbit: machine learning system which pushes the frontier of machine learning with techniques such
    as online, hashing, allreduce, reductions, learning2search, active, and interactive learning</li>
</ul>
<p><strong>R software implementations</strong>
List of packages and/or codes and/or frameworks and/or links:</p>
<ul>
<li>Hands-On Reinforcement Learning</li>
<li>QLearning: Reinforcement Learning using the Q Learning Algorithm</li>
<li>reinforcelearn: reinforcement learning, including Q-Learning algorithm</li>
<li>ReinforcementLearning: Model-Free Reinforcement Learning</li>
<li>RLT: Reinforcement Learning Trees</li>
</ul>
<h3>7.34 Robust numerical methods.</h3>
<p><strong>Python software implementations</strong>
List of packages and/or codes and/or frameworks and/or links:</p>
<ul>
<li>derivative: Numerical differentiation of noisy time series data</li>
<li>hypothesize: hypothesis testing using robust statistics</li>
<li>robusta: interface to many common statistical analyses, performed using through R and RPY2.</li>
<li>Robustats is a Python library for high-performance computation of robust statistical estimators</li>
<li>robustbase: Statistical Estimators (Sn, Qn, MAD, IQR)</li>
</ul>
<p><strong>R software implementations</strong>
List of packages and/or codes and/or frameworks and/or links:</p>
<ul>
<li>clubSandwich: Cluster-Robust (Sandwich) Variance Estimators with Small-Sample Corrections</li>
<li>l1spectral: An L1-Version of the Spectral Clustering</li>
<li>L2E: Robust Structured Regression via the L2 Criterion</li>
<li>pcaPP: Robust PCA by Projection Pursuit</li>
<li>RCTS: Clustering Time Series While Resisting Outliers</li>
<li>RDnp: Robust Test for Complete Independence in High-Dimensions</li>
<li>revss: Robust Estimation in Very Small Samples</li>
<li>RGMM: Robust Mixture Model</li>
<li>rigr: Regression, Inference, and General Data Analysis Tools in R</li>
<li>robcp: Robust Change-Point Tests</li>
<li>robcor: Robust Correlations</li>
<li>robfilter: Robust Time Series Filters</li>
<li>robmixglm: Robust Generalized Linear Models (GLM) using Mixtures</li>
<li>RobMixReg: Robust Mixture Regression</li>
<li>RobStatTM: Robust Statistics: Theory and Methods</li>
<li>
<p>robust: Port of the S+ ”Robust Library”</p>
</li>
<li>
<p>RobustANOVA: Robust One-Way ANOVA Tests under Heteroscedasticity and Nonnormality</p>
</li>
<li>robustbase: Basic Robust Statistics</li>
<li>RobustCalibration: Robust Calibration of Imperfect Mathematical Models</li>
<li>robustcov: Collection of Robust Covariance and (Sparse) Precision Matrix Estimators</li>
<li>robustHD: Robust Methods for High-Dimensional Data</li>
<li>rrcov: Scalable Robust Estimators with High Breakdown Point</li>
<li>RSC: Robust and Sparse Correlation Matrix</li>
<li>sandwich: Robust Covariance Matrix Estimators</li>
<li>StabilizedRegression: Stabilizing Regression and Variable Selection</li>
<li>tsrobprep: Robust Preprocessing of Time Series Data</li>
<li>walrus: Robust Statistical Methods</li>
</ul>
<h3>7.35 Selection of features, variables, models, data splits</h3>
<p><strong>Collections of resources</strong>
List of links:</p>
<ul>
<li>Data Science Feature Engineering and Selection Tutorials</li>
<li>Feature Engineering and Selection: A Practical Approach for Predictive Models</li>
<li>Guide for Feature Engineering and Feature Selection</li>
</ul>
<p><strong>Python software implementations</strong>
List of packages and/or codes and/or frameworks and/or links:</p>
<ul>
<li>abess: Fast Best-Subset Selection Library</li>
<li>boruta_py: Boruta all-relevant feature selection method</li>
<li>dython: Data analysis tools</li>
<li>featureclass: Feature engineering library to keep track of feature dependencies, documentation and schema</li>
<li>feature_engine: library with multiple transformers to engineer and select features for use in machine learning
    models</li>
<li>FeatureTools: automated feature engineering</li>
<li>Featurewiz: advanced feature engineering strategies</li>
<li>ITMO_FS: Feature selection library</li>
<li>KnockPy: Knockoffs for controlled variable selection</li>
<li>kydavra: feature selection</li>
<li>Py_FS: Feature Selection</li>
<li>pyHSICLasso: Versatile Nonlinear Feature Selection Algorithm for High-dimensional Data</li>
<li>
<p>python_stepwiseSelection: Automated Backward and Forward Selection</p>
</li>
<li>
<p>scikit-learn: machine learning in Python</p>
</li>
<li>scikit-rebate: scikit-learn-compatible Python implementation of ReBATE, a suite of Relief-based feature
    selection algorithms</li>
<li>Sklearn-genetic-opt: Hyperparameters tuning and feature selection, using evolutionary algorithms</li>
<li>sktime: unified framework for machine learning with time series by UK national institute for data science and
    artificial intelligence</li>
<li>tsfeatures: Calculates various features from time series data. Python implementation of the R package
    tsfeatures</li>
<li>UltraNest: Fit and compare complex models reliably and rapidly. Advanced nested sampling</li>
<li>zoofs: feature selection using a variety of nature-inspired wrapper algorithms</li>
</ul>
<p><strong>R software implementations</strong>
List of packages and/or codes and/or frameworks and/or links:</p>
<ul>
<li>abess: Fast Best-Subset Selection Library</li>
<li>BAS: Bayesian Variable Selection and Model Averaging using Bayesian Adaptive Sampling</li>
<li>basad: Bayesian Variable Selection with Shrinking and Diffusing Priors</li>
<li>BayesVarSel: Bayes Factors, Model Choice and Variable Selection in Linear Models</li>
<li>bpgmm: Bayesian Model Selection Approach for Parsimonious Gaussian Mixture Models</li>
<li>bravo: Bayesian Screening and Variable Selection</li>
<li>care: High-Dimensional Regression and CAR Score Variable Selection</li>
<li>dials: Tools for Creating Tuning Parameter Values</li>
<li>EMVS: The Expectation-Maximization Approach to Bayesian Variable Selection</li>
<li>FeatureTerminatoR: Feature Selection Engine to Remove Features with Minimal Predictive Power</li>
<li>FSinR: Feature Selection</li>
<li>fsMTS: Feature Selection for Multivariate Time Series</li>
<li>gausscov: The Gaussian Covariate Method for Variable Selection</li>
<li>greybox: Toolbox for Model Building and Forecasting</li>
<li>hrqglas: Group Variable Selection for Quantile and Robust Mean Regression</li>
<li>knockoff: The Knockoff Filter for Controlled Variable Selection</li>
<li>mBvs: Bayesian Variable Selection Methods for Multivariate Data</li>
<li>MDFS: MultiDimensional Feature Selection</li>
<li>mlr3fselect: Feature Selection for ’mlr3’</li>
<li>mplot: Graphical Model Stability and Variable Selection Procedures</li>
<li>MXM: Feature Selection (Including Multiple Solutions) and Bayesian Networks</li>
<li>
<p>nestfs: Cross-Validated (Nested) Forward Selection</p>
</li>
<li>
<p>NonpModelCheck: Model Checking and Variable Selection in Nonparametric Regression</p>
</li>
<li>pcaPP: Robust PCA by Projection Pursuit</li>
<li>picR: Predictive Information Criteria for Model Selection</li>
<li>plsVarSel: Variable Selection in Partial Least Squares</li>
<li>praznik: Tools for Information-Based Feature Selection and Scoring</li>
<li>prinvars: Principal Variables (methods for reducing the number of features within a data set)</li>
<li>projpred: Projection Predictive Feature Selection</li>
<li>Rforestry: Random Forests, Linear Trees, and Gradient Boosting for Inference and Interpretability</li>
<li>rmcfs: The MCFS-ID Algorithm for Feature Selection and Interdependency Discovery</li>
<li>rSAFE: Surrogate-Assisted Feature Extraction</li>
<li>rstanarm: Bayesian Applied Regression Modeling via Stan</li>
<li>SelectBoost: A General Algorithm to Enhance the Performance of Variable Selection Methods in Correlated
    Datasets</li>
<li>SignifReg: Consistent Significance Controlled Variable Selection in Generalized Linear Regression</li>
<li>sivs: Stable Iterative Variable Selection</li>
<li>smoothic: Variable Selection Using a Smooth Information Criterion</li>
<li>SPlit: Split a Dataset for Training and Testing</li>
<li>splitTools: Tools for Data Splitting</li>
<li>stabiliser: Stabilising Variable Selection</li>
<li>stabm: Stability Measures for Feature Selection</li>
<li>stacks: Tidy Model Stacking</li>
<li>stepgbm: Stepwise Variable Selection for Generalized Boosted Regression Modeling</li>
<li>SWIM: Scenario Weights for Importance Measurement</li>
<li>theft: Tools for Handling Extraction of Features from Time Series</li>
<li>tornado: Plots for Model Sensitivity and Variable Importance</li>
<li>valse: Variable Selection with Mixture of Models</li>
<li>WLasso: Variable Selection for Highly Correlated Predictors</li>
</ul>
<h3>7.36 Sensitivity analysis and numerical derivatives</h3>
<p><strong>Python software implementations</strong>
List of packages and/or codes and/or frameworks and/or links:</p>
<ul>
<li>derivative: Numerical differentiation of noisy time series data</li>
<li>higher: obtain higher order gradients</li>
<li>jacobi: Numerical derivatives for Python</li>
<li>JAX: toolkit by Google for composable transformations of Python+NumPy programs: differentiate, vectorize,
    JIT to GPU/TPU, and more</li>
<li>OMSens: OpenModelica sensitivity analysis and optimization module</li>
<li>PyApprox: high-dimensional approximation and uncertainty quantification by Sandia Labs</li>
<li>SALib: Sensitivity Analysis Library (Contains Sobol, Morris, FAST, and other methods)</li>
<li>sensitivity: Sensitivity Analysis</li>
<li>tangent: library (by Google) for automatic differentiation providing Source-to-Source Debuggable Derivatives
    in Pure Python</li>
<li>torchsde: Differentiable SDE solvers with GPU support and efficient sensitivity analysis</li>
</ul>
<p><strong>R software implementations</strong>
List of packages and/or codes and/or frameworks and/or links:</p>
<ul>
<li>bnmonitor: An Implementation of Sensitivity Analysis in Bayesian Networks</li>
<li>GSA.UN: Global Sensitivity Analysis Tool</li>
<li>reval: Argument Table Generation for Sensitivity Analysis</li>
<li>samon: Sensitivity Analysis for Missing Data</li>
<li>sensemakr: Sensitivity Analysis Tools for Regression Models</li>
<li>sensitivity: Global Sensitivity Analysis of Model Outputs</li>
<li>sensobol: Computation of Variance-Based Sensitivity Indices</li>
<li>SWIM: Scenario Weights for Importance Measurement</li>
<li>tornado: Plots for Model Sensitivity and Variable Importance</li>
</ul>
<h3>7.37 Statistics and Probability</h3>
<p><strong>Python software implementations</strong>
List of packages and/or codes and/or frameworks and/or links:</p>
<ul>
<li>distfit: probability density function fitting and hypothesis testing</li>
<li>empiricaldist: empirical distribution functions</li>
<li>momentum: Running mean, variance, skew, and kurtosis</li>
<li>pingouin: Statistical package in Python based on Pandas</li>
<li>
<p>probs: Probability library</p>
</li>
<li>
<p>PyProbables: Probabilistic data structures in python</p>
</li>
<li>PyStats: statistical analysis and distributions</li>
<li>RunStats: Computing Statistics and Regression in One Pass</li>
<li>statsmodels: statistical modeling and econometrics</li>
<li>tensorflow-probability: Probabilistic reasoning and statistical analysis in TensorFlow</li>
<li>wquantiles: Weighted quantiles</li>
</ul>
<p><strong>R software implementations</strong>
List of packages and/or codes and/or frameworks and/or links:</p>
<ul>
<li>arsenal: An Arsenal of ’R’ Functions for Large-Scale Statistical Summaries</li>
<li>ashr: Methods for Adaptive Shrinkage, using Empirical Bayes</li>
<li>confintr: Confidence Intervals</li>
<li>DEM: The Distributed EM Algorithms in Multivariate Gaussian Mixture Models</li>
<li>DescTools: Tools for Descriptive Statistics</li>
<li>distr6: The Complete R6 Probability Distributions Interface</li>
<li>distr: Object Oriented Implementation of Distributions</li>
<li>distrEx: Extensions of Package ’distr’</li>
<li>distributionsrd: Distribution Fitting and Evaluation</li>
<li>DPQ: Density, Probability, Quantile (’DPQ’) Computations</li>
<li>EasyDescribe: A Convenient Way of Descriptive Statistics</li>
<li>entropy: Estimation of Entropy, Mutual Information and Related Quantities</li>
<li>estimatr: Fast Estimators for Design-Based Inference</li>
<li>evd: Functions for Extreme Value Distributions</li>
<li>expectreg: Expectile and Quantile Regression</li>
<li>fitur: Fit Univariate Distributions</li>
<li>fromo: Fast Robust Moments</li>
<li>Gmedian: Geometric Median, k-Medians Clustering and Robust Median PCA</li>
<li>HSAUR3: A Handbook of Statistical Analyses Using R (3rd Edition)</li>
<li>lmom: L-Moments</li>
<li>lmomco: L-Moments, Censored L-Moments, Trimmed L-Moments, L-Comoments, and Many Distributions</li>
<li>matrixdist: Statistics for Matrix Distributions</li>
<li>MatrixModels: Modelling with Sparse and Dense Matrices</li>
<li>matrixStats: Functions that Apply to Rows and Columns of Matrices (and to Vectors)</li>
<li>
<p>minsample2: The Minimum Sample Size</p>
</li>
<li>
<p>mlquantify: Algorithms for Class Distribution Estimation</p>
</li>
<li>mvtnorm: Multivariate Normal and t Distributions</li>
<li>NNS: Nonlinear nonparametric statistics using partial moments</li>
<li>overlapping: Estimation of Overlapping in Empirical Distributions</li>
<li>PCDimension: Finding the Number of Significant Principal Components</li>
<li>philentropy: Similarity and Distance Quantification Between Probability Functions</li>
<li>pls: Partial Least Squares and Principal Component Regression</li>
<li>psre: Presenting Statistical Results Effectively</li>
<li>Qest: Quantile-Based Estimator</li>
<li>qp: Quantile parametrization for probability distribution functions</li>
<li>RcppRoll: Efficient Rolling / Windowed Operations</li>
<li>revss: Robust Estimation in Very Small Samples</li>
<li>RobStatTM: Robust Statistics: Theory and Methods</li>
<li>robustbase: Basic Robust Statistics</li>
<li>roll: Rolling and Expanding Statistics</li>
<li>statsExpressions: Tidy Dataframes and Expressions with Statistical Details</li>
<li>walrus: Robust Statistical Methods</li>
<li>weights: Weighting and Weighted Statistics</li>
</ul>
<h3>7.38 Stress testing, rare events, extreme values and scenarios, survival analysis</h3>
<p><strong>Python software implementations</strong>
List of packages and/or codes and/or frameworks and/or links:</p>
<ul>
<li>pyextremes: Extreme Value Analysis</li>
<li>pycox is a python package for survival analysis and time-to-event prediction with PyTorch</li>
<li>scikit-extremes: univariate extreme value calculations</li>
</ul>
<p><strong>R software implementations</strong>
List of packages and/or codes and/or frameworks and/or links:</p>
<ul>
<li>BMAmevt: Multivariate Extremes: Bayesian Estimation of the Spectral Measure</li>
<li>climextRemes: Tools for Analyzing Climate Extremes</li>
<li>extRemes: Extreme Value Analysis</li>
<li>extremeStat: Extreme Value Statistics and Quantile Estimation</li>
<li>evd: Functions for Extreme Value Distributions</li>
<li>
<p>evmix: Extreme Value Mixture Modelling, Threshold Estimation and Boundary Corrected Kernel Density
    Estimation</p>
</li>
<li>
<p>ExtremalDep: Extremal Dependence Models</p>
</li>
<li>ExtremeRisks: Extreme Risk Measures</li>
<li>lax: Loglikelihood Adjustment for Extreme Value Models</li>
<li>lite: Likelihood-Based Inference for Time Series Extremes</li>
<li>mev: Modelling of Extreme Values</li>
<li>survivalmodels: Models for Survival Analysis</li>
</ul>
<h3>7.39 Symbolic regression &amp; data-driven model discovery and machine learning</h3>
<p><strong>Python software implementations</strong>
List of packages and/or codes and/or frameworks and/or links:</p>
<ul>
<li>2SEGP: Simple Simultaneous Ensemble Learning in Genetic Programming</li>
<li>AIFeynman: Physics-Inspired Method for Symbolic Regression</li>
<li>BindingGP: Symbolic Regression with Dimension Calculation</li>
<li>Data Driven Symbolic Regression</li>
<li>DEAP: Distributed Evolutionary Algorithms</li>
<li>DeepSymReg: Neural Network-Based Symbolic Regression in Deep Learning for Scientific Discovery</li>
<li>DeepSymRegTorch: PyTorch implementation of the EQL network, a neural network for symbolic regression</li>
<li>Deep symbolic optimization</li>
<li>diffeqpy: Solving differential equations in Python using DifferentialEquations.jl and the SciML Scientific
    Machine Learning organization</li>
<li>ellyn: python-wrapped version of ellen, a linear genetic programming system for symbolic regression and
    classification</li>
<li>EQLearner: A Seq2Seq approach to Symbolic Regression</li>
<li>ffx: Fast Function Extraction for symbolic regressio</li>
<li>geppy: framework for gene expression programming</li>
<li>gplearn: Genetic Programming in Python, with a scikit-learn inspired API</li>
<li>hal-cgp: Cartesian genetic programming</li>
<li>Neural Symbolic Regression That Scales</li>
<li>pyglyph: library based on deap providing abstraction layers for symbolic regression problems</li>
<li>pymbolic: Easy Expression Trees and Term Rewriting</li>
<li>PySR: High-Performance Symbolic Regression in Python</li>
<li>PySINDy: sparse identification of nonlinear dynamical systems from data</li>
<li>pySRURGS: Symbolic regression by uniform random global search</li>
<li>salmon-lm: symbolic algebra of linear regression and modeling</li>
<li>
<p>slearn: package linking symbolic representation with scikit-learn machine learning</p>
</li>
<li>
<p>SR Bench: benchmark framework for symbolic regression</p>
</li>
<li>SymEngine is a fast symbolic manipulation library</li>
<li>symfit: Symbolic Fitting; fitting as it should be.</li>
<li>symbolic experiments: Repository for symbolic regression/classification experiments</li>
<li>Symbolic Regression Boosting</li>
<li>Simpy: symbolic mathematics</li>
<li>symreg: A Symbolic Regression engine</li>
</ul>
<p><strong>R software implementations</strong>
List of packages and/or codes and/or frameworks and/or links:</p>
<ul>
<li>DiffEqR: Solving differential equations in R using DifferentialEquations.jl and the SciML Scientific Machine
    Learning ecosystem</li>
<li>gramEvol: Grammatical Evolution for R</li>
<li>symbolicDA: Analysis of Symbolic Data</li>
<li>symengine: Interface to the ’SymEngine’ Library</li>
</ul>
<h3>7.40 Testing (numerical, statistical, etc.), comparison and ranking</h3>
<p><strong>Python software implementations</strong>
List of packages and/or codes and/or frameworks and/or links:</p>
<ul>
<li>AutoTS: Automated Time Series Forecasting</li>
<li>darts: toolkit by Unit8 for easy manipulation and forecasting of time series</li>
<li>goftests: Generic goodness of fit tests for random plain old data</li>
<li>hypothesize: hypothesis testing using robust statistics</li>
<li>hypothetical: Hypothesis and statistical testing</li>
<li>hyppo: multivariate hypothesis testing</li>
<li>InvarianceUnitTests: Linear unit-tests for invariance discovery</li>
<li>MAPIE: scikit-learn-compatible module for estimating prediction intervals.</li>
<li>Merlion: A Machine Learning Framework for Time Series Intelligence by SalesForce</li>
<li>permute: permutation tests and confidence sets</li>
<li>PhiK: practical correlation constant that works consistently between categorical, ordinal and interval variables</li>
<li>pingouin: Statistical package in Python based on Pandas</li>
<li>responsible-ai-toolbox: Error Analysis dashboard, for identifying model errors and discovering cohorts of data
    for which the model underperforms.</li>
<li>RunStats: Computing Statistics and Regression in One Pass</li>
<li>scikit-learn: machine learning in Python</li>
<li>statsmodels: statistical modeling and econometrics</li>
<li>UltraNest: Fit and compare complex models reliably and rapidly. Advanced nested sampling.</li>
<li>xskillscore: Metrics for verifying forecasts</li>
</ul>
<p><strong>R software implementations</strong>
List of packages and/or codes and/or frameworks and/or links:</p>
<ul>
<li>ACV: Optimal Out-of-Sample Forecast Evaluation and Testing under Stationarity</li>
<li>amp: Statistical Test for the Multivariate Point Null Hypotheses</li>
<li>ashr: Methods for Adaptive Shrinkage, using Empirical Bayes</li>
<li>bayefdr: Bayesian Estimation and Optimisation of Expected False Discovery Rate</li>
<li>BEST: Bayesian Estimation Supersedes the t-Test</li>
<li>BFpack: Flexible Bayes Factor Testing of Scientific Expectations</li>
<li>blocklength: Select an Optimal Block-Length to Bootstrap Dependent Data (Block Bootstrap)</li>
<li>boot: Bootstrap Functions</li>
<li>boot.pval: Bootstrap p-Values</li>
<li>bootUR: Bootstrap Unit Root Tests</li>
<li>CADFtest: A Package to Perform Covariate Augmented Dickey-Fuller Unit Root Tests</li>
<li>ChangepointTesting: Change Point Estimation for Clustered Signals</li>
<li>clusrank: Wilcoxon Rank Tests for Clustered Data</li>
<li>cocor: Comparing Correlations</li>
<li>corTESTsrd: Significance Testing of Rank Cross-Correlations under SRD</li>
<li>CovTools: Statistical Tools for Covariance Analysis</li>
<li>crossvalidationCP: Cross-Validation for Change-Point Regression</li>
<li>crseEventStudy: A Robust and Powerful Test of Abnormal Stock Returns in Long-Horizon Event Studies</li>
<li>cvCovEst: Cross-Validated Covariance Matrix Estimation</li>
<li>cvms: Cross-Validation for Model Selection</li>
<li>CVST: Fast Cross-Validation via Sequential Testing</li>
<li>dgof: Discrete Goodness-of-Fit Tests</li>
<li>digitTests: Tests for Detecting Irregular Digit Patterns</li>
<li>DiscreteFDR: Multiple Testing Procedures with Adaptation for Discrete Tests</li>
<li>dsos: Dataset Shift with Outlier Scores</li>
<li>elo: Ranking Teams by Elo Rating and Comparable Methods</li>
<li>energy: E-Statistics: Multivariate Inference via the Energy of Data</li>
<li>exactRankTests: Exact Distributions for Rank and Permutation Tests</li>
<li>FactorAssumptions: Set of Assumptions for Factor and Principal Component Analysis</li>
<li>FAMT: Factor Analysis for Multiple Testing (FAMT) : Simultaneous Tests under Dependence in High-
    Dimensional Data</li>
<li>
<p>fbst: The Full Bayesian Evidence Test, Full Bayesian Significance Test and the e-Value</p>
</li>
<li>
<p>fdrci: Permutation-Based FDR Point and Confidence Interval Estimation</p>
</li>
<li>FDRestimation: Estimate, Plot, and Summarize False Discovery Rates</li>
<li>funtimes: Nonparametric estimators and tests for time series analysis</li>
<li>fwb: Fractional Weighted Bootstrap</li>
<li>fwildclusterboot: Fast Wild Cluster Bootstrap Inference for Linear Models</li>
<li>gvlma: Global Validation of Linear Models Assumptions</li>
<li>gt: Easily Create Presentation-Ready Display Tables</li>
<li>gtExtras: Extending ’gt’ for Beautiful HTML Tables</li>
<li>heplots: Visualizing Hypothesis Tests in Multivariate Linear Models</li>
<li>HSAUR3: A Handbook of Statistical Analyses Using R (3rd Edition)</li>
<li>htestClust: Reweighted Marginal Hypothesis Tests for Clustered Data</li>
<li>ICtest: Estimating and Testing the Number of Interesting Components in Linear Dimension Reduction</li>
<li>inferr: Inferential Statistics (parametric and non-parametric statistical tests)</li>
<li>L2DensityGoFtest: Density Goodness-of-Fit Test</li>
<li>locits: Test of Stationarity and Localized Autocovariance</li>
<li>mashr: Multivariate Adaptive Shrinkage</li>
<li>mcStats: Visualize Results of Statistical Hypothesis Tests</li>
<li>melt: Multiple Empirical Likelihood Tests</li>
<li>metrica: evaluate prediction performance of point-forecast models</li>
<li>MixedIndTests: Tests of Randomness and Tests of Independence</li>
<li>modeltime.resample: Resampling Tools for Time Series Forecasting</li>
<li>MSTest: Hypothesis Testing for Markov Switching Models</li>
<li>multDM: Multivariate Version of the Diebold-Mariano Test</li>
<li>MultiFit: Multiscale Fisher’s Independence Test for Multivariate Dependence</li>
<li>MultiHorizonSPA: Multi Horizon Superior Predictive Ability</li>
<li>multiverse: ’Explorable Multiverse’ Data Analysis and Reports to show the robustness of statistical inference</li>
<li>MVTests: Multivariate Hypothesis Tests and the confidence intervals</li>
<li>nestedcv: Nested Cross-Validation with ’glmnet’ and ’caret’</li>
<li>NonParRolCor: a Non-Parametric Statistical Significance Test for Rolling Window Correlation</li>
<li>OOS: Out-of-Sample Time Series Forecasting</li>
<li>origami: Generalized Framework for Cross-Validation</li>
<li>OptSig: Optimal Level of Significance for Regression and Other Statistical Tests</li>
<li>
<p>OPTtesting: Optimal Testing</p>
</li>
<li>
<p>OutliersO3: Draws Overview of Outliers (O3) Plots</p>
</li>
<li>pbo: Probability of Backtest Overfitting</li>
<li>performance: Assessment of Regression Models Performance</li>
<li>permutes: Permutation Tests for Time Series Data</li>
<li>poolr: Methods for Pooling P-Values from (Dependent) Tests</li>
<li>portes: Portmanteau Tests for Univariate and Multivariate Time Series Models</li>
<li>randtoolbox: Toolbox for Pseudo and Quasi Random Number Generation and Random Generator Tests</li>
<li>RDieHarder: R Interface to the ’DieHarder’ RNG Test Suite</li>
<li>RDnp: Robust Test for Complete Independence in High-Dimensions</li>
<li>rigr: Regression, Inference, and General Data Analysis Tools in R</li>
<li>Rita: Automated Transformations, Normality Testing, and Reporting</li>
<li>rmcorr: Repeated Measures Correlation</li>
<li>RobustANOVA: Robust One-Way ANOVA Tests under Heteroscedasticity and Nonnormality</li>
<li>robusTest: Calibrated Correlation, Two-Sample Tests</li>
<li>rsample: General Resampling Infrastructure</li>
<li>rstatix: Pipe-Friendly Framework for Basic Statistical Tests</li>
<li>s2dverification: Set of Common Tools for Forecast Verification</li>
<li>scoringfunctions: A Collection of Scoring Functions for Assessing Point Forecasts</li>
<li>scoringRules: Scoring Rules for Parametric and Simulated Distribution Forecasts</li>
<li>scoringutils: Utilities for Scoring and Assessing Predictions</li>
<li>sdafilter: distribution free multiple testing rules for false discovery rate (FDR) control under general depen-
    dence</li>
<li>sgof: Multiple Hypothesis Testing</li>
<li>SHT: Statistical Hypothesis Testing Toolbox</li>
<li>slider: Sliding Window Functions</li>
<li>SlidingWindows: Methods for Time Series Analysis</li>
<li>SPlit: Split a Dataset for Training and Testing</li>
<li>splitTools: Tools for Data Splitting</li>
<li>statsExpressions: Tidy Dataframes and tests (parametric, nonparametric, robust, etc)</li>
<li>tidyposterior: Bayesian Analysis to Compare Models using Resampling Statistics</li>
<li>tidystats: Save Output of Statistical Tests</li>
<li>UnitStat: Performs Unit Root Test Statistics</li>
<li>urca: Unit Root and Cointegration Tests for Time Series Data</li>
<li>USP: U-Statistic Permutation Tests of Independence for all Data Types</li>
<li>walrus: Robust Statistical Methods</li>
<li>yardstick: Tidy Characterizations of Model Performance</li>
</ul>
<h3>7.41 Testing software codes</h3>
<p><strong>Python software implementations</strong>
List of packages and/or codes and/or frameworks and/or links:</p>
<ul>
<li>benchmark: microbenchmark support library</li>
<li>bugsnag error monitoring and error reporting</li>
<li>case: Python unittest Utilities</li>
<li>cxxtest: CxxTest Unit Testing Framework</li>
<li>dirty-equals: make python code (generally unit tests) more declarative and therefore easier to read and write.</li>
<li>expectest: implements expect tests (also known as ”golden” tests)</li>
<li>formencode: validation and form generation</li>
<li>freezegun: allows your Python tests to travel through time by mocking the datetime module</li>
<li>green: clean, colorful, fast python test runner</li>
<li>Hypothesis: family of testing libraries which let you write tests parametrized by a source of examples</li>
<li>Mamba Test Runner: definitive testing tool for Python</li>
<li>mutattest: Safely run mutation trials without source code modifications and see what will get past your test
    suite.</li>
<li>nose2: unittest with plugins.</li>
<li>nox: Flexible test automation for Python</li>
<li>partialtesting: toolkit by Man Group to run only the tests relevant for code changes</li>
<li>playwright-python: Python version of the Playwright testing and automation library</li>
<li>Pynguin: PYthoN General UnIt Test geNerator</li>
<li>pyperformance: intended to be an authoritative source of benchmarks for all Python implementations</li>
<li>pytest: easy to write small tests, yet scales to support complex functional testing</li>
<li>pytest-benchmark: py.test fixture for benchmarking code</li>
<li>pytest-check: pytest plugin that allows multiple failures per test.</li>
<li>pytest-html: Plugin for generating HTML reports for pytest results</li>
<li>pytest-parallel: pytest plugin for parallel and concurrent testing</li>
<li>pytest-regressions: Pytest plugin for regression testing</li>
<li>stestr: parallel Python test runner built around subunit</li>
<li>TestSlide: test framework by Facebook</li>
<li>testtools: extensions to the Python standard library’s unit testing framework.</li>
<li>tox: Command line driven CI frontend and development task automation tool</li>
<li>ward: modern test framework for Python with a focus on productivity and readability.</li>
</ul>
<p><strong>R software implementations</strong>
List of packages and/or codes and/or frameworks and/or links:</p>
<ul>
<li>exampletestr: Help for Writing Unit Tests Based on Function Examples</li>
<li>melt: Multiple Empirical Likelihood Tests</li>
<li>mockthat: Function Mocking for Unit Testing</li>
<li>patrick: Parameterized Unit Testing by Google</li>
<li>realtest: When Expectations Meet Reality: Realistic Unit Testing</li>
<li>shinytest2: Testing for Shiny Applications</li>
<li>testdat: Data Unit Testing for R</li>
<li>testthat: Unit Testing for R</li>
<li>testthis: Utils and ’RStudio’ Addins to Make Testing Even More Fun</li>
<li>ttdo: Extend ’tinytest’ with ’diffobj’</li>
<li>unitizer: Interactive R Unit Tests</li>
<li>unittest: TAP-Compliant Unit Testing</li>
<li>xpectr: Generates Expectations for ’testthat’ Unit Testing</li>
</ul>
<h3>7.42 Time series analysis and modeling</h3>
<p><strong>Collections of resources</strong>
List of links:</p>
<ul>
<li>Curated list with python packages for time series analysis</li>
<li>Popular Python Time Series Packages</li>
<li>Resources for working with time series and sequence data</li>
</ul>
<p><strong>Python software implementations</strong>
List of packages and/or codes and/or frameworks and/or links:</p>
<ul>
<li>Clairvoyance: Unified, End-to-End AutoML Pipeline for Medical Time Series</li>
<li>darts: toolkit by Unit8 for easy manipulation and forecasting of time series</li>
<li>DataGene: Identify How Similar TS Datasets Are to One Another</li>
<li>deeptime: analysis of time series data including dimensionality reduction, clustering, and Markov model
    estimation</li>
<li>EntropyHub: open-source toolkit for entropic time-series analysis.</li>
<li>ETNA Time Series Library by Tinkoff AI</li>
<li>fastreg: Fast sparse regressions with advanced formula syntax. OLS, GLM, Poisson, Maxlike, and more.
    High-dimensional fixed effects</li>
<li>Featuretools: automated feature engineering</li>
<li>
<p>glum: Generalized linear models</p>
</li>
<li>
<p>hcrystalball: unifies the API for most commonly used libraries and modeling techniques for time-series fore-
    casting in the Python ecosystem</p>
</li>
<li>HyperTools: toolbox for gaining geometric insights into high-dimensional data</li>
<li>HyperTS: Full-Pipeline Automated Time Series (AutoTS) Analysis Toolkit</li>
<li>kats: tookit by Facebook for time series analysis and forecasting</li>
<li>KFAS: Kalman Filter and Smoother for Exponential Family State Space Models</li>
<li>khiva-python: Python binding for Khiva library for time series analytics</li>
<li>Loud ML: inference engine for metrics and events</li>
<li>luminaire: ML driven solutions for monitoring time series data</li>
<li>matrixprofile-ts: detect patterns and anomalies in massive datasets using Matrix Profile</li>
<li>MatrixStats: Methods that Apply to Rows and Columns of Matrices (and to Vectors)</li>
<li>mkl_fft: NumPy-based Python interface to Intel (R) MKL FFT functionality</li>
<li>nixtla: Automated time series processing and forecasting</li>
<li>pandas: data structures for data analysis, time series, and statistics</li>
<li>pyFFTW is a pythonic wrapper around FFTW 3, the speedy FFT library</li>
<li>pyFIt-SNE: FFT-accelerated Interpolation-based t-SNE (FIt-SNE)</li>
<li>pyts: time series classification</li>
<li>pytsal: Time Series analysis, visualization, forecasting along with AutoTS</li>
<li>seglearn: machine learning for time series</li>
<li>sktime: unified framework for machine learning with time series by UK national institute for data science and
    artificial intelligence</li>
<li>slearn: package linking symbolic representation with scikit-learn machine learning</li>
<li>statsmodels: statistical modeling and econometrics</li>
<li>stumpy: variety of time series data mining tasks</li>
<li>theft: Tools for Handling Extraction of Features from Time Series</li>
<li>timemachines: Evaluation and standardization of popular time series packages</li>
<li>timetk: A Tool Kit for Working with Time Series in R</li>
<li>Traces: library for unevenly-spaced time series analysis</li>
<li>tsai: time series tasks like classification, regression, forecasting, imputation</li>
<li>tsam: time series aggregation module (tsam)</li>
<li>ts-eval: Time Series analysis and evaluation tools</li>
<li>tsfresh: extracts relevant characteristics from time series</li>
<li>tslearn: machine learning toolkit dedicated to time-series data</li>
<li>tspreprocess: package to preprocess time series</li>
<li>tsmoothie: time-series smoothing and outlier detection in a vectorized way</li>
<li>vectorbt: library for backtesting and analyzing trading strategies at scale</li>
</ul>
<p><strong>R software implementations</strong>
List of packages and/or codes and/or frameworks and/or links:</p>
<ul>
<li>ASSA: Applied Singular Spectrum Analysis</li>
<li>astsa: Applied Statistical Time Series Analysis</li>
<li>autostsm: Automatic Structural Time Series Models</li>
<li>bdots: Bootstrapped Differences of Time Series</li>
<li>bfast: Breaks for Additive Season and Trend</li>
<li>bimets: Time Series and Econometric Modeling</li>
<li>bootUR: Bootstrap Unit Root Tests</li>
<li>ctbi: A Procedure to Clean, Decompose and Aggregate Timeseries</li>
<li>energy: E-Statistics: Multivariate Inference via the Energy of Data</li>
<li>entropy: Estimation of Entropy, Mutual Information and Related Quantities</li>
<li>freqdom: Frequency Domain Based Analysis: Dynamic PCA</li>
<li>funtimes: Functions for Time Series Analysis</li>
<li>garchx: Flexible and Robust GARCH-X Modelling</li>
<li>LMD: A Self-Adaptive Approach for Demodulating Multi-Component Signal</li>
<li>LSTS: Locally Stationary Time Series</li>
<li>lubridate: Make Dealing with Dates a Little Easier</li>
<li>mcvis: Multi-Collinearity Visualization</li>
<li>MixedIndTests: Tests of Randomness and Tests of Independence</li>
<li>MTS: All-Purpose Toolkit for Analyzing Multivariate Time Series (MTS) and Estimating Multivariate Volatil-
    ity Models</li>
<li>NonlinearTSA: Nonlinear Time Series Analysis</li>
<li>nonlinearTseries: Nonlinear Time Series Analysis</li>
<li>nortsTest: Assessing Normality of Stationary Process</li>
<li>NTS: Nonlinear Time Series Analysis</li>
<li>Rfssa: Functional Singular Spectrum Analysis</li>
<li>rhosa: Higher-Order Spectral Analysis</li>
<li>rrcov: Scalable Robust Estimators with High Breakdown Point</li>
<li>rrMixture: Reduced-Rank Mixture Models</li>
<li>Rssa: A Collection of Methods for Singular Spectrum Analysis</li>
<li>rtrend: Trend Estimating Tools</li>
<li>Rwave: Time-Frequency Analysis of 1-D Signals</li>
<li>
<p>seastests: Seasonality Tests</p>
</li>
<li>
<p>shrink: Global, Parameterwise and Joint Shrinkage Factor Estimation</p>
</li>
<li>simts: Time Series Analysis Tools</li>
<li>SLBDD: Statistical Learning for Big Dependent Data</li>
<li>svars: Data-Driven Identification of SVAR Models</li>
<li>tempdisagg: Temporal Disaggregation and Interpolation of Time Series</li>
<li>theft: Tools for Handling Extraction of Features from Time Series</li>
<li>TidyDensity: Functions for Tidy Analysis and Generation of Random Data</li>
<li>timetk: A Tool Kit for Working with Time Series in R</li>
<li>TSA: Time Series Analysis</li>
<li>tsbox: Class-Agnostic Time Series</li>
<li>tscopula: Time Series Copula Models</li>
<li>tseries: Time Series Analysis and Computational Finance</li>
<li>TSrepr: Time Series Representations</li>
<li>tsrobprep: Robust Preprocessing of Time Series Data</li>
<li>TSstudio: Functions for Time Series Analysis and Forecasting</li>
<li>tsutils: Time Series Exploration, Modelling and Forecasting</li>
<li>tsviz: Easy and Interactive Time Series Visualization</li>
<li>vars: VAR Modelling</li>
<li>xts: eXtensible Time Series</li>
</ul>
<h3>7.43 Text, sentiment and topic analytics (including NLP)</h3>
<p><strong>Python software implementations</strong></p>
<ul>
<li>AllenNLP: toolkit by Allen Institute of Articial Intelligence for NLP research</li>
<li>EmTract: Extracting Emotions from Social Media Text Tailored for Financial Contexts</li>
<li>EvoMSA: Sentiment Analysis System based on B4MSA and EvoDAG</li>
<li>fairseq: Facebook AI Research Sequence-to-Sequence Toolkit</li>
<li>FastFormers: toolkit by Microsoft to achieve inference of Transformer models for Natural Language Under-
    standing</li>
<li>gensim: topic modelling, document indexing and similarity retrieval with large corpora</li>
<li>GPT-3: Language Models are Few-Shot Learners</li>
<li>LIT: Language Interpretability Tool: Interactively analyze NLP models for model understanding</li>
<li>LangTech Text Library (LTTL) is an open-source python package for text processing and analysis.</li>
<li>Natural Language Processing Best Practices and Examples by Microsoft</li>
<li>
<p>netts: toolkit by UK national institute for data science and artificial intelligence for creating networks cap-
    turing semantic content of speech transcripts</p>
</li>
<li>
<p>nlpaug: Data augmentation for NLP</p>
</li>
<li>nltk: Natural Language Toolkit</li>
<li>pytext: A natural language modeling framework based on PyTorch</li>
<li>PyTorch-NLP: Basic Utilities for PyTorch Natural Language Processing (NLP)</li>
<li>Senta: Baidu’s open-source Sentiment Analysis System.</li>
<li>spaCy: Industrial-strength Natural Language Processing (NLP) in Python</li>
<li>stocksight: Stock market analyzer and predictor using Elasticsearch, Twitter, News headlines, NLP and
    sentiment analysis</li>
<li>sumy: automatic summarization of text documents and HTML pages</li>
<li>textacy: NLP, before and after spaCy</li>
<li>vaderSentiment: VADER (Valence Aware Dictionary and sEntiment Reasoner) is a lexicon and rule-based
    sentiment analysis tool</li>
<li>wordfreq: Access a database of word frequencies, in various natural languages.</li>
</ul>
<p><strong>R software implementations</strong></p>
<ul>
<li>cleanNLP: Tidy Data Model for Natural Language Processing</li>
<li>doc2concrete: Measuring Concreteness in Natural Language</li>
<li>fastTextR: An Interface to the ’fastText’ Library</li>
<li>globaltrends: Google Trends portal.</li>
<li>lsa: Latent Semantic Analysis</li>
<li>LSX: Model for Semisupervised Text Analysis Based on Word Embeddings</li>
<li>meanr: Sentiment Analysis Scorer</li>
<li>NLP: Natural Language Processing Infrastructure</li>
<li>opitools: Analyzing the Opinions in a Big Text Document</li>
<li>quanteda: Quantitative Analysis of Textual Data</li>
<li>saotd: Sentiment Analysis of Twitter Data</li>
<li>sentiment.ai: Simple Sentiment Analysis Using Deep Learning</li>
<li>SentimentAnalysis: Dictionary-Based Sentiment Analysis</li>
<li>sentimentr: Calculate Text Polarity Sentiment</li>
<li>sentometrics: Integrated Framework for Textual Sentiment Time Series Aggregation and Prediction</li>
<li>spacyr: Wrapper to the ’spaCy’ ’NLP’ Library</li>
<li>sweater: Speedy Word Embedding Association Test and Extras Using R</li>
<li>syuzhet: Extracts Sentiment and Sentiment-Derived Plot Arcs from Text</li>
<li>tau: Text Analysis Utilities</li>
<li>
<p>text2map: R Tools for Text Matrices, Embeddings, and Networks</p>
</li>
<li>
<p>text2sdg: Detecting UN Sustainable Development Goals in Text</p>
</li>
<li>text2vec: Modern Text Mining Framework for R</li>
<li>texter: An Easy Text and Sentiment Analysis Library</li>
<li>TextForecast: Regression Analysis and Forecasting Using Textual Data from a Time-Varying Dictionary</li>
<li>textTinyR: Text Processing for Small or Big Data Files</li>
<li>tidytext: Text Mining using ’dplyr’, ’ggplot2’, and Other Tidy Tools</li>
<li>transforEmotion: Sentiment Analysis for Text and Qualitative Data</li>
<li>tsentiment: Fetching Tweet Data for Sentiment Analysis</li>
<li>Xplortext: Statistical Analysis of Textual Data</li>
</ul>
<h3>7.44 Uncertainty: analysis and modeling.</h3>
<p>Links to resources</p>
<ul>
<li>Professionally curated list of awesome Conformal Prediction videos, tutorials, books, papers, PhD and MSc
    theses, articles and open-source libraries</li>
</ul>
<p><strong>Python software implementations</strong>
List of packages and/or codes and/or frameworks and/or links:</p>
<ul>
<li>Bumps: data fitting and uncertainty estimation</li>
<li>conformal-rnn: code for ”Conformal time-series forecasting”, NeurIPS 2021</li>
<li>crepes: Conformal Regressors and Conformal Predictive Systems</li>
<li>EasyVVUQ: verification, validation and uncertainty quantification in high performance computing</li>
<li>EnbPI: Ensemble batch prediction intervals</li>
<li>EnCQR: ensemble conformalized quantile regression (EnCQR)</li>
<li>MAPIE: scikit-learn-compatible module for estimating prediction intervals</li>
<li>mystic: highly-constrained non-convex optimization and uncertainty quantification</li>
<li>OpenTURNS (Open source initiative to Treat Uncertainties, Risks’N Statistics)</li>
<li>PySloth: Probabilistic Prediction</li>
<li>UncertaintyToolbox: predictive uncertainty quantification, calibration, metrics, and visualization</li>
<li>UQpy: UQpy (Uncertainty Quantification with python) is a general purpose Python toolbox for modeling
    uncertainty in physical and mathematical systems</li>
</ul>
<p><strong>R software implementations</strong>
List of packages and/or codes and/or frameworks and/or links:</p>
<ul>
<li>bootComb: Combine Parameter Estimates via Parametric Bootstrap</li>
</ul>
<h3>7.45 Visualization and reporting</h3>
<p><strong>Python software implementations</strong>
List of packages and/or codes and/or frameworks and/or links:</p>
<ul>
<li>Algviz is an algorithm visualization tool for your Python code</li>
<li>appmode: Jupyter extension that turns notebooks into web applications</li>
<li>Best of Streamlit</li>
<li>clustergram: Visualization and diagnostics for cluster analysis in Python</li>
<li>dash: framework for building ML and data science web apps</li>
<li>dash-extensions:extensions to the Plotly Dash framework</li>
<li>D-tale:Visualizer by Man Group for pandas data structures</li>
<li>FlameScope: visualization ny Netflix for exploring different time ranges as Flame Graphs.</li>
<li>HyperTools: toolbox for gaining geometric insights into high-dimensional data</li>
<li>ipyslides: Create Interactive Slides in Jupyter Notebook with all kind of rich content</li>
<li>itables: Pandas DataFrames as Interactive DataTables</li>
<li>Lux: automate the visualization and data analysis process</li>
<li>Markdown: Python implementation of markdown</li>
<li>matplotlib: omprehensive library for creating static, animated, and interactive visualizations</li>
<li>mpl-animators: interative animation framework for matplotlib</li>
<li>Orange: Interactive data analysis</li>
<li>plotly: graphing library makes interactive, publication-quality graphs</li>
<li>Plotly Resampler: Visualize large time-series data in plotly</li>
<li>plotnine: A grammar of graphics for Python</li>
<li>plottable: Beautifully customized tables with matplotlib</li>
<li>psyplot: interactive data visualization</li>
<li>PyGraphistry: quickly load, shape, embed, and explore big graphs with the GPU-accelerated Graphistry
    visual graph analyzer</li>
<li>PyMetis: Python wrapper around Metis, a graph partitioning package</li>
<li>PyShiny: Shiny for Python</li>
<li>pyvis: visualizing interactive network graphs</li>
<li>seaborn: statistical data visualization</li>
<li>seaborn analyzer: data analysis and visualization tool using Seaborn library</li>
<li>streamlit: fastest way to build and share data apps</li>
<li>tensorboard: TensorFlow’s Visualization Toolkit</li>
<li>
<p>torchsde: Differentiable SDE solvers with GPU support and efficient sensitivity analysis</p>
</li>
<li>
<p>tourr: Tour Methods for Multivariate Data Visualisation</p>
</li>
<li>Vega-Altair is a declarative statistical visualization library for Pytho</li>
<li>VisPy: interactive scientific visualization in Python</li>
<li>visdom: lexible tool for creating, organizing, and sharing visualizations of live, rich data</li>
</ul>
<p><strong>R software implementations</strong>
List of packages and/or codes and/or frameworks and/or links:</p>
<ul>
<li>apexcharter: Create Interactive Chart with the JavaScript ’ApexCharts’ Library</li>
<li>autoplotly: Automatic Generation of Interactive Visualizations for Statistical Results</li>
<li>classmap: Visualizing Classification Results</li>
<li>cleanrmd: Clean Class-Less ’R Markdown’ HTML Documents</li>
<li>clustree: Visualise Clusterings at Different Resolutions</li>
<li>ComplexUpset: Create Complex UpSet Plots Using ’ggplot2’ Components</li>
<li>condformat: Conditional Formatting in Data Frames</li>
<li>conductor: Create Tours in ’Shiny’ Apps Using ’Shepherd.js’</li>
<li>d3po: Fast and Beautiful Interactive Visualization for ’Markdown’ and ’Shiny’</li>
<li>DataVisualizations: Visualizations of High-Dimensional Data</li>
<li>descriptr: Generate Descriptive Statistics</li>
<li>DT: A Wrapper of the JavaScript Library ’DataTables’</li>
<li>echarty: Minimal R/Shiny Interface to JavaScript Library ’ECharts’</li>
<li>esquisse: Explore and Visualize Your Data Interactively</li>
<li>fmtr: Easily Apply Formats to Data</li>
<li>ggalluvial: Alluvial Plots in ’ggplot2’</li>
<li>GGally: Extension to ’ggplot2’</li>
<li>gganimate: A Grammar of Animated Graphics</li>
<li>ggbreak: Set Axis Break for ’ggplot2’</li>
<li>ggcharts: Shorten the Distance from Data Visualization Idea to Actual Plot</li>
<li>ggcorrplot: Visualization of a Correlation Matrix using ’ggplot2’</li>
<li>ggcorset: The Corset Plot</li>
<li>ggdag: Analyze and Create Elegant Directed Acyclic Graphs</li>
<li>ggdist: Visualizations of Distributions and Uncertainty</li>
<li>ggDoubleHeat: A Heatmap-Like Visualization Tool</li>
<li>ggeffects: Create Tidy Data Frames of Marginal Effects for ’ggplot’ from Model Outputs</li>
<li>
<p>ggESDA: Exploratory Symbolic Data Analysis with ’ggplot2’</p>
</li>
<li>
<p>ggfocus: Scales that Focus Specific Levels in your ggplot</p>
</li>
<li>ggforce: Accelerating ’ggplot2’</li>
<li>ggformula: Formula Interface to the Grammar of Graphics</li>
<li>ggfortify: Data Visualization Tools for Statistical Analysis Results</li>
<li>gghdr: Visualisation of Highest Density Regions in ’ggplot2’</li>
<li>ggheatmap: Plot Heatmap</li>
<li>gghighlight: Highlight Lines and Points in ’ggplot2’</li>
<li>ggh4x: Hacks for ’ggplot2’</li>
<li>ggiraph: Make ’ggplot2’ Graphics Interactive</li>
<li>ggmatplot: Plot Columns of Two Matrices Against Each Other Using ’ggplot2’</li>
<li>ggmice: Visualizations for ’mice’ with ’ggplot2’</li>
<li>ggmosaic: Mosaic Plots in the ’ggplot2’ Framework</li>
<li>ggmulti: High Dimensional Data Visualization</li>
<li>ggnetwork: Geometries to Plot Networks with ’ggplot2’</li>
<li>ggpattern: ’ggplot2’ Pattern Geoms</li>
<li>ggpie: pie, donut and rose pie plots with ggplot2</li>
<li>ggplot2: Create Elegant Data Visualisations Using the Grammar of Graphics</li>
<li>ggplotify: Convert Plot to ’grob’ or ’ggplot’ Object</li>
<li>ggpmisc: Miscellaneous Extensions to ’ggplot2’</li>
<li>ggpubr: ’ggplot2’ Based Publication Ready Plots</li>
<li>ggpval: Annotate Statistical Tests for ’ggplot2’</li>
<li>ggquickeda: Quickly Explore Your Data Using ’ggplot2’ and ’table1’ Summary Tables</li>
<li>ggside extends ’ggplot2’ by allowing users to add graphical information about one of the main panel’s axis
    using a familiar ’ggplot2’ style API with tidy data</li>
<li>ggsignif: Significance Brackets for ’ggplot2’</li>
<li>ggstance: Horizontal ’ggplot2’ Components</li>
<li>ggstar: Multiple Geometric Shape Point Layer for ’ggplot2’</li>
<li>ggstatsplot: ’ggplot2’ Based Plots with Statistical Details</li>
<li>ggthemes: Extra Themes, Scales and Geoms for ’ggplot2’</li>
<li>ggtrace: Provides ggplot2 geoms that allow groups of data points to be outlined or highlighted for emphasis</li>
<li>gluedown: Wrap Vectors in Markdown Formatting</li>
<li>gridstackeR: easy way to create responsive layouts with just a few lines of code using gridstack.js</li>
<li>gt: Easily Create Presentation-Ready Display Tables</li>
<li>
<p>gtExtras: additional functions for creating tables with gt</p>
</li>
<li>
<p>gtsummary: Presentation-Ready Data Summary and Analytic Result Tables</p>
</li>
<li>heatmaply: Interactive Cluster Heat Maps Using ’plotly’ and ’ggplot2’</li>
<li>heplots: Visualizing Hypothesis Tests in Multivariate Linear Models</li>
<li>htmlTable: Advanced Tables for Markdown/HTML</li>
<li>huxtable: Easily Create and Style Tables for LaTeX, HTML and Other Formats</li>
<li>jjAnno: An Annotation Package for ’ggplot2’ Output</li>
<li>kableExtra: Construct Complex Table with ’kable’ and Pipe Syntax</li>
<li>listdown: Create R Markdown from Lists</li>
<li>loon: Interactive Statistical Data Visualization</li>
<li>loon.ggplot: A Grammar of Interactive Graphics</li>
<li>magick: Advanced Graphics and Image-Processing in R</li>
<li>memoiR: R Markdown and Bookdown Templates to Publish Documents</li>
<li>ndtv: Network Dynamic Temporal Visualizations</li>
<li>numform: Tools to Format Numbers for Publication</li>
<li>performance: Assessment of Regression Models Performance</li>
<li>plot.matrix: Visualizes a Matrix as Heatmap</li>
<li>presenter: Present Data with Style</li>
<li>prompter: Add Tooltips in ’Shiny’ Apps with ’Hint.css’</li>
<li>psre: Presenting Statistical Results Effectively</li>
<li>quarto: R Interface to ’Quarto’ Markdown Publishing System</li>
<li>r2resize: In-Text Resizing for Containers, Images and Data Tables in ’Shiny’, ’Markdown’ and ’Quarto’
    Documents</li>
<li>r3js: allow WebGL-based 3D plotting using the three.js library</li>
<li>reactR: Make it easy to use ’React’ in R with ’htmlwidget’ scaffolds</li>
<li>reporter: Creates Statistical Reports</li>
<li>rheroicons: A Zero Dependency ’SVG’ Icon Library for ’Shiny’</li>
<li>rhino: A Framework for Enterprise Shiny Applications</li>
<li>rintrojs: Wrapper for the ’Intro.js’ Library</li>
<li>rmarkdown: Dynamic Documents for R</li>
<li>rsvg: Render SVG Images into PDF, PNG, (Encapsulated) PostScript, or Bitmap Arrays</li>
<li>semantic.dashboard: Dashboard with Fomantic UI Support for Shiny</li>
<li>shapviz: visualize SHapley Additive exPlanations (SHAP) - waterfall, force, importance, dependence plots</li>
<li>shiny: Web Application Framework for R</li>
<li>
<p>shinyChakraUI: A Wrapper of the ’React’ Library ’Chakra UI’ for ’Shiny’</p>
</li>
<li>
<p>shinydlplot: Add a Download Button to a ’shiny’ Plot or ’plotly’</p>
</li>
<li>shinyHugePlot: Efficient Plotting of Large-Sized Data</li>
<li>shinyMobile: Mobile Ready ’shiny’ Apps with Standalone Capabilities</li>
<li>shinySelect: A Wrapper of the ’react-select’ Library</li>
<li>shiny.semantic: Semantic UI Support for Shiny</li>
<li>shinytest: Test Shiny Apps</li>
<li>shinyWidgets: Custom Inputs Widgets for Shiny</li>
<li>starry: Explore Data with Plots and Tables</li>
<li>statsExpressions: Tidy Dataframes and Expressions with Statistical Details</li>
<li>sugrrants: Supporting Graphs for Analysing Time Series</li>
<li>tidybayes: Tidy Data and ’Geoms’ for Bayesian Models</li>
<li>tidycharts: Generate Tidy Charts Inspired by ’IBCS’</li>
<li>tidyHeatmap: A Tidy Implementation of Heatmap</li>
<li>tourr: Tour Methods for Multivariate Data Visualisation</li>
<li>tornado: Plots for Model Sensitivity and Variable Importance</li>
<li>trelliscopejs: Create Interactive Trelliscope Displays</li>
<li>tsviz: Easy and Interactive Time Series Visualization</li>
<li>UpSetR: A More Scalable Alternative to Venn and Euler Diagrams for Visualizing Intersecting Sets</li>
<li>visNetwork: Network Visualization using ’vis.js’ Library</li>
<li>visStatistics: Automated Visualization of Statistical Tests</li>
<li>vtable: Variable Table for Variable Documentation</li>
<li>xaringan: Presentation Ninja</li>
<li>yardstick: Tidy Characterizations of Model Performance</li>
</ul>
<h2>8 Codes for QWIM (Quantitative Wealth and Investment Management)</h2>
<h2>ment)</h2>
<h3>8.1 Collections of resources</h3>
<p>List of links:</p>
<ul>
<li>Curated list of practical financial machine learning tools and applications</li>
<li>EliteQuant: online resources for quantitative modeling, trading, portfolio management</li>
</ul>
<h3>8.2 Research studies with code</h3>
<p>Ardia et al. (“RiskPortfolios: Computation of Risk-Based Portfolios in R,” 2017)
Boileau et al. (“cvCovEst: Cross-validated covariance matrix estimator selection and evaluation in R,” 2021)
Brugiere ( <em>Quantitative Portfolio Management with Applications in Python</em> , 2020)
Bryzgalova et al. (“Forest Through the Trees: Building Cross-Sections of Stock Returns,” 2021)
Cajas (“Entropic Portfolio Optimization: a Disciplined Convex Programming Framework,” 2021)
Cajas (“OWA Portfolio Optimization: a Disciplined Convex Programming Framework,” 2021)
Chen and Zimmermann (“Open Source Cross-Sectional Asset Pricing,” 2022)
Chib ( <em>R package czfactor</em> , 2020)
Chib and Zhao ( <em>R package czzg</em> , 2020)
Coqueret and Guida ( <em>Machine Learning for Factor Investing: R Version</em> , 2020)
Coqueret ( <em>Perspectives in sustainable equity investing (website version)</em> , 2022)
de Carvalho and Rua (“Real-time nowcasting the US output gap: Singular spectrum analysis at work,” 2017)
Ding et al. (“A Python package for multi-stage stochastic programming,” 2020)
Dixon et al. ( <em>Machine Learning in Finance: from theory to practice</em> , 2020)
Dixon and Polson (“Deep Fundamental Factor Models,” 2020)
Dong et al. (“Anomalies and the expected market return,” 2022)
Guijarro-Ordonez et al. (“Deep Learning Statistical Arbitrage,” 2021)
Gurdogan and Kercheval (“Multi Anchor Point Shrinkage for the Sample Covariance Matrix (Extended Ver-
sion),” 2021)
Ho et al. (“Moving beyond P values: data analysis with estimation graphics,” 2019)
Irlam (“Multi Scenario Financial Planning via Deep Reinforcement Learning AI,” 2020)
Irlam ( <em>AI Planner</em> , 2020)
Irlam (“Machine learning for retirement planning,” 2020)
Jansen ( <em>Machine Learning for Algorithmic Trading (Second Edition)</em> , 2020)
Kakushadze and Yu (“Statistical Risk Models,” 2016)
Kakushadze and Yu (“Open Source Fundamental Industry Classification,” 2017)
Kakushadze and Yu (“Betas, Benchmarks, and Beating the Market,” 2018)
Kakushadze and Yu (“Decoding stock market with quant alphas,” 2018)
Kakushadze and Yu (“Machine learning risk models,” 2019)
Kakushadze and Yu (“Machine learning treasury yields,” 2020)
Lai et al. (“TODS: An Automated Time Series Outlier Detection System,” 2021)
Lettau and Pelger (“Factors That Fit the Time Series and Cross-Section of Stock Returns,” 2020)
Li et al. (“FinRL-Podracer: High Performance and Scalable Deep Reinforcement Learning for Quantitative
Finance,” 2021)
Liu et al. (“FinRL: Deep Reinforcement Learning Framework to Automate Trading in Quantitative Finance,”
2021)
Liu et al. (“FinRL-Meta: A Universe of Near-Real Market Environments for Data-Driven Deep Reinforcement
Learning in Quantitative Finance,” 2022)
Marinescu (“Risk-Based Optimal Portfolio Strategies: A Compendium,” 2022)
Martin (“PyPortfolioOpt: portfolio optimization in Python,” 2021)
Marwood and Minnen (“Safely Boosting Retirement Income by Harmonizing Drawdown Paths,” 2020)
McIndoe (“A Data Driven Approach to Market Regime Classification,” 2020)
Micheli and Neuman (“Evidence of Crowding on Russell 3000 Reconstitution Events,” 2022)
Milevsky ( <em>Retirement Income Recipes in R: From Ruin Probabilities to Intelligent Drawdowns</em> , 2020)
Qian et al. (“Combining forecasts for universally optimal performance,” 2022)
Rao and Jelvis ( <em>Foundations of Reinforcement Learning with Applications in Finance</em> , 2022)
Sarmas et al. ( <em>Multicriteria Portfolio Construction with Python</em> , 2020)
Sharma et al. (“DoWhy: Addressing Challenges in Expressing and Validating Causal Assumptions,” 2021)
Shi et al. (“Deep Learning Algorithms for Hedging with Frictions,” 2022)
Siebert et al. (“A systematic review of Python packages for time series analysis,” 2021)
Simos et al. (“Time-varying Black–Litterman portfolio optimization using a bio-inspired approach and neu-
ronets,” 2021)
Snow (“Machine learning in asset management,” 2019)</p>
<p>Snow (“Machine Learning in Asset Management Part 1: Portfolio Construction Trading Strategies,” 2020)
Snow (“Machine Learning in Asset Management - Part 2: Portfolio Construction - Weight Optimization,” 2020)
Tatsat et al. ( <em>Machine Learning and Data Science Blueprints for Finance: From Building Trading Strategies to
Robo-Advisors Using Python</em> , 2020)
Tuck et al. (“Portfolio Construction Using Stratified Models,” 2022)
Ungolo et al. (“affine_mortality: A Github repository for estimation, analysis, and projection of affine mortality
models,” 2021)
Vamossy and Skog (“EmTract: Investor Emotions and Market Behavior,” 2021)
Vinod (“R Package GeneralCorr Functions for Portfolio Choice,” 2021)
Yang et al. (“FinBERT: A Pretrained Language Model for Financial Communications,” 2020)
Yu et al. (“An AI approach to measuring financial risk,” 2020)</p>
<h3>8.3 Python software implementations.</h3>
<p>List of packages and/or codes and/or frameworks and/or links:</p>
<ul>
<li>alive-progress: new kind of Progress Bar, with real-time throughput, ETA, and very cool animations</li>
<li>alphalens: Performance analysis of predictive (alpha) stock factors</li>
<li>AlphaPy: Automated Machine Learning [AutoML] with Python, scikit-learn, Keras, XGBoost, LightGBM,
    and CatBoost</li>
<li>auquantoolbox: Backtesting toolbox for trading strategies</li>
<li>azapy: Financial Portfolio Optimization Algorithms</li>
<li>bt: flexible backtesting framework</li>
<li>btgym: Scalable, event-driven, deep-learning-friendly backtesting library</li>
<li>Clairvoyant: identify and monitor social/historical cues for short term stock movement</li>
<li>CVXPortfolio: Portfolio optimization and simulation</li>
<li>cyanure: Toolbox for Empirical Risk Minimization</li>
<li>Elegant-FinRL: algorithmic strategies using Reinforcement Learning</li>
<li>Empyrial: AI and data-driven quantitative portfolio management for risk and performance analytics</li>
<li>empyrical: Common financial risk and performance metrics</li>
<li>EmTract: Extracting Emotions from Social Media Text Tailored for Financial Contexts</li>
<li>ffn: Financial functions for Python</li>
<li>FinDataPy: download market data via Bloomberg, Eikon, Quandl, Yahoo etc.</li>
<li>FinMarketPy: backtesting trading strategies and analyzing financial markets</li>
<li>finnhub-python: Finnhub Python API Client to provide financial data(real-time stock price, global funda-
    mentals, global ETFs holdings and alternative data)</li>
<li>FinRL: Deep Reinforcement Learning for Quantitative Finance</li>
<li>FinRL-Meta: Universe of Near-Real Market Environments for Data-Driven Financial Reinforcement Learning</li>
<li>fredapi is a Python interface to the Federal Reserve Economic Data (FRED) and ALFRED databases</li>
<li>lifelib: Actuarial models in Python</li>
<li>
<p>lifelines: Survival analysis in Python, including Kaplan Meier, Nelson Aalen and regression</p>
</li>
<li>
<p>lrsm_portfolio: Portfolio Construction using Stratified Models</p>
</li>
<li>Machine Learning and Data Science Blueprints for Finance (codes for the book)</li>
<li>Machine Learning fior asset management</li>
<li>Machine Learning for Algorithmic Trading (codes for the book)</li>
<li>MLFinLab: Machine Learning Financial Laboratory</li>
<li>momentum: Running mean, variance, skew, and kurtosis</li>
<li>Multicriteria Portfolio Construction with Python</li>
<li>okama: investment portfolio analyzing and optimization tools</li>
<li>OpenBBTerminal: modern Python-based integrated environment for investment research</li>
<li>OptimalPortfolio: portfolio optimization</li>
<li>QuantAxis: Quantitative Financial FrameWork</li>
<li>QuantEcon: quantitative economics</li>
<li>Pandas TA: Technical Analysis Indicators</li>
<li>portfolio-backtest: backtest portfolio asset allocation</li>
<li>precise: online covariance and precision forecasting, portfolios, and model ensembles</li>
<li>predictionrevisited: implements the core statistical concepts from the book ”Prediction Revisited: The Im-
    portance of Observation”</li>
<li>pyfinance: general financial and security returns analysis</li>
<li>pyfolio: Portfolio and risk analytics in Python</li>
<li>pyhrp: hierarchical risk parity algorithms</li>
<li>PyPortfolioOpt: Financial portfolio optimisation</li>
<li>Qlib: Microsoft AI-oriented quantitative investment platform</li>
<li>QuantEcon.py: quantitative economics</li>
<li>QuantLib: Python bindings for the QuantLib library</li>
<li>QuantResearch: Quantitative analysis, strategies and backtests</li>
<li>Quantropy: Financial pipeline for the data-driven investor to research, develop and deploy robust strategie</li>
<li>QuantStats: Portfolio analytics for quants</li>
<li>Riskfolio-Lib: Portfolio Optimization and Quantitative Strategic Asset Allocation</li>
<li>Robust Risk-aware reinforcement learning</li>
<li>stocksight: Stock market analyzer and predictor using Elasticsearch, Twitter, News headlines, NLP and
    sentiment analysis</li>
<li>ta: Technical Analysis Library using Pandas and Numpy</li>
<li>TA-lib: Python wrapper for TA-Lib Technical Analysis Library</li>
<li>Tax-Calculator: USA Federal Individual Income and Payroll Tax Microsimulation Model</li>
<li>tf-quant-finance: High-performance TensorFlow library by Google for quantitative finance.</li>
<li>vectorbt: Supercharged backtesting and technical analysis for quants</li>
<li>zipline: Algorithmic Trading Library</li>
</ul>
<h3>8.4 R software implementations</h3>
<p>List of packages and/or codes and/or frameworks and/or links:</p>
<ul>
<li>ASSA: Applied Singular Spectrum Analysis</li>
<li>AssetAllocation: Backtesting Simple Asset Allocation Strategies</li>
<li>BEKKs: Multivariate Conditional Volatility Modelling and Forecasting</li>
<li>crseEventStudy: A Robust and Powerful Test of Abnormal Stock Returns in Long-Horizon Event Studies</li>
<li>DOSPortfolio: Dynamic Optimal Shrinkage Portfolio</li>
<li>ExtremeRisks: Extreme Risk Measures</li>
<li>FFdownload: Download Data from Kenneth French’s Website</li>
<li>FinnTS: Microsoft Finance Time Series Forecasting Framework</li>
<li>finreportr: Financial Data from U.S. Securities and Exchange Commission</li>
<li>fHMM: Fitting Hidden Markov Models to Financial Data</li>
<li>FinnTS: Microsoft Finance Time Series Forecasting Framework</li>
<li>fitHeavyTail: Mean and Covariance Matrix Estimation under Heavy Tails</li>
<li>fixedincome: Fixed Income Models, Calculations, Data Structures and Instruments</li>
<li>generalCorr: Generalized Correlations, Causal Paths and Portfolio Selection</li>
<li>greeks: Sensitivities of Prices of Financial Options</li>
<li>HDShOP: High-Dimensional Shrinkage Optimal Portfolios</li>
<li>HierPortfolios: Hierarchical Clustering-Based Portfolio Allocation Strategies</li>
<li>highOrderPortfolios: Design of High-Order Portfolios via Mean, Variance, Skewness, and Kurtosis</li>
<li>imputeFin: Imputation of Financial Time Series with Missing Values and/or Outliers</li>
<li>MarkowitzR: Statistical Significance of the Markowitz Portfolio</li>
<li>MortCast: Estimation and Projection of Age-Specific Mortality Rates</li>
<li>parma: Portfolio Allocation and Risk Management Applications</li>
<li>pbo: Probability of Backtest Overfitting</li>
<li>pec: Prediction Error Curves for Risk Prediction Models in Survival Analysis</li>
<li>pedquant: Public Economic Data and Quantitative Analysis</li>
<li>PerformanceAnalytics: Econometric Tools for Performance and Risk Analysis</li>
<li>PortfolioAnalytics: Portfolio Analysis, Including Numerical Methods for Optimization of Portfolios</li>
<li>portfolioBacktest: Automated Backtesting of Portfolios over Multiple Datasets</li>
<li>portvine: portfolio level risk estimates using ARMA-GARCH and vine copulas</li>
<li>priceR: Economics and Pricing Tools</li>
<li>
<p>qlcal: R Bindings to the Calendaring Functionality of ’QuantLib’</p>
</li>
<li>
<p>qrmtools: Tools for Quantitative Risk Management</p>
</li>
<li>quantmod: Quantitative Financial Modelling Framework</li>
<li>RcppQuantuccia: R Bindings to the Calendaring Functionality of ’QuantLib’</li>
<li>riskParityPortfolio: Design of Risk Parity Portfolios</li>
<li>RiskPortfolios: Computation of Risk-Based Portfolios</li>
<li>riskRegression: Risk Regression Models and Prediction Scores for Survival Analysis with Competing Risks</li>
<li>RPESE: Estimates of Standard Errors for Risk and Performance Measures</li>
<li>RQuantLib: R Interface to the ’QuantLib’ Library</li>
<li>SharpeR: Statistical Significance of the Sharpe Ratio</li>
<li>sharpeRratio: Moment-Free Estimation of Sharpe Ratios</li>
<li>sparseIndexTracking: Design of Portfolio of Stocks to Track an Index</li>
<li>SWIM: Scenario Weights for Importance Measurement</li>
<li>TextForecast: Regression Analysis and Forecasting Using Textual Data from a Time-Varying Dictionary</li>
<li>tidyquant: Tidy Quantitative Financial Analysis</li>
<li>Trading: CCR, Advanced Correlation &amp; Beta Estimates, Betting Strategies</li>
<li>tseries: Time Series Analysis and Computational Finance</li>
<li>ufRisk: Risk Measure Calculation in Financial TS</li>
<li>usincometaxes: wrapper to the NBER’s TAXSIM 35 tax simulator for federal and state income taxes</li>
<li>ycevo: Nonparametric Estimation of the Yield Curve Evolution</li>
<li>yfR: Downloads and Organizes Financial Data from Yahoo Finance</li>
</ul>
<h2>References</h2>
<p>Al Janabi, M. A. M., Arreola Hernandez, J., Berger, T., and Nguyen, D. K. (2017).“Multivariate dependence and
portfolio optimization algorithms under illiquid market scenarios.” In: <em>European Journal of Operational Research</em>
259(3), pp. 1121–1131.
Alaa, A., Van Breugel, B., Saveliev, E. S., and van der Schaar, M. (2022).“How Faithful is your Synthetic Data?
Sample-level Metrics for Evaluating and Auditing Generative Models.” In: <em>Proceedings of the 39th International
Conference on Machine Learning</em>. Ed. by K. Chaudhuri, S. Jegelka, L. Song, C. Szepesvari, G. Niu, and S.
Sabato. Vol. 162. Proceedings of Machine Learning Research. PMLR, pp. 290–306.
Albanese, C., Crepey, S., and Iabichino, S. (2020).“Reverse Stress Testing.” In: <em>SSRN e-Print</em>.
Alexander, C. and Ledermann, D. (2012).“ROM Simulation: Applications to Stress Testing and VaR.” In: <em>SSRN
e-Print</em>.
Alokley, S. A. and Albarrak, M. S. (2020).“Clustering of Extremes in Financial Returns: A Study of Developed
and Emerging Markets.” In: <em>Journal of Risk and Financial Management</em> 13(7), p. 141.
Amengual, D. and Sentana, E. (2020).“Is a Normal Copula the Right Copula?” In: <em>Journal of Business &amp; Economic
Statistics</em> 38(2), pp. 350–366.
Ardia, D. and Bluteau, K. (2017).“Stress-Testing With Parametric Models and Fully Flexible Probabilities.” In:
<em>Wilmott</em> 2017(87), pp. 52–55.
Ardia, D., Boudt, K., and Gagnon-Fleury, J.-P. (2017).“RiskPortfolios: Computation of Risk-Based Portfolios in
R.” In: <em>The Journal of Open Source Software</em> 2(10), pp. 171+.
Ardia, D. and Meucci, A. (2015).“Stress testing in non-normal markets via entropy pooling.” In: <em>Risk</em>.
Arora, R., Gao, R., and Tompaidis, S. (2021).“Extreme Yet Plausible: Choosing Scenarios to Stress Test Financial
Institutions.” In: <em>SSRN e-Print</em>.
Asch, A., Brady, E., Gallardo, H., Hood, J., Chu, B., and Farazmand, M. (2022). “Model-assisted deep learning of
rare extreme events from partial observations.” In: <em>arXiv e-Print</em>.
Assefa, S., Dervovic, D., Mahfouz, M., Balch, T., Reddy, P., and Veloso, M. (2019).“Generating Synthetic Data in
Finance: Opportunities, Challenges and Pitfalls.” In: <em>NeurIPS’19 Workshop on Robust AI in Financial Services</em>.
Aste, T. (2021).“Stress testing and systemic risk measures using multivariate conditional probability.” In: <em>arXiv
e-Print</em>.
Bacon, C. R. (2019).“Performance Attribution: History and Progress.” In: <em>CFA Institute Research Foundation
Publications</em>.
Baes, M. and Schaanning, E. (2020).“Reverse Stress Testing: Scenario Design for Macroprudential Stress Tests.”
In: <em>SSRN e-Print</em>.
Bahrpeyma, F., Roantree, M., Cappellari, P., Scriney, M., and McCarren, A. (2021).“A Methodology for Validating
Diversity in Synthetic Time Series Generation.” In: <em>MethodsX</em> 8, p. 101459.
Bai, Y., Lam, H., Vyetrenko, S., and Balch, T. (2021). “Efficient Calibration of Multi-Agent Market Simulators
from Time Series with Bayesian Optimization.” In: <em>arXiv e-Print</em>.
Bandara, K., Hewamalage, H., Liu, Y.-H., Kang, Y., and Bergmeir, C. (2021).“Improving the accuracy of global
forecasting models using time series data augmentation.” In: <em>Pattern Recognition</em> 120, p. 108148.
Barra Montevechi, J. A., Silva Costa, R. F. da, Pinho, A. F. de, and Carvalho Miranda, R. de (2017).“A simulation-
based approach to perform economic evaluation scenarios.” In: <em>Journal of Simulation</em> 11(2), pp. 185–192.
Bass, R., Gallagher, K., Ratcliffe, R., and Shah, S. (2018).“Factor Performance Across Market-Driven Scenarios.”
In: <em>SSRN e-Print</em>.
Beikirch, M., Cramer, S., Frank, M., Otte, P., Pabich, E., and Trimborn, T. (2021).“Robust Mathematical For-
mulation and Probabilistic Description of Agent-Based Computational Economic Market Models.” In: <em>arXiv
e-Print</em>.
Benali, F., Bodenes, D., Labroche, N., and de Runz, C. (2021).“MTCopula: Synthetic Complex Data Generation
Using Copula.” In: <em>HAL Archives Ouvertes</em>.
Bertsimas, D. and Van Parys, B. (2017).“Bootstrap Robust Prescriptive Analytics.” In: <em>arXiv e-Print</em>.
Bhatia, S., Jain, A., and Hooi, B. (2021).“ExGAN: Adversarial Generation of Extreme Samples.” In: <em>arXiv e-Print</em>.
Bhattarai, B., Baek, S., Bodur, R., and Kim, T.-K. (2020).“Sampling Strategies for GAN Synthetic Data.” In:
<em>ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>.
Bianchi, M. L., Stoyanov, S. V., Tassinari, G. L., Fabozzi, F. J., and Focardi, S. M. (2019). <em>Handbook of Heavy-Tailed
Distributions in Asset Management and Risk Management</em>. World Scientific. 600 pp.</p>
<p>Bilgili, M. S., Ferconi, M., and Ulitsky, A. (2017).“Stress Hedging in Portfolio Construction.” In: <em>Risk</em>.
Boileau, P., Hejazi, N., Collica, B., Laan, M. van der, and Dudoit, S. (2021).“cvCovEst: Cross-validated covariance
matrix estimator selection and evaluation in R.” In: <em>Journal of Open Source Software</em> 6(63), p. 3273.
Bolger, F. and Wright, G. (2017).“Use of expert knowledge to anticipate the future: Issues, analysis and directions.”
In: <em>International Journal of Forecasting</em> 33(1), pp. 230–243.
Bond-Taylor, S., Leach, A., Long, Y., and Willcocks, C. G. (2022). “Deep Generative Modelling: A Comparative
Review of VAEs, GANs, Normalizing Flows, Energy-Based and Autoregressive Models.” In: <em>arXiv e-Print</em>.
Boubaker, S. and Nguyen, D. K. (2019). <em>Handbook of Global Financial Markets</em>. World Scientific. 828 pp.
Breuer, T. and Summer, M. (2020).“Systematic stress tests on public data.” In: <em>Journal of Banking &amp; Finance</em> 118,
pp. 105886+.
Brugiere, P. (2020). <em>Quantitative Portfolio Management with Applications in Python</em>. Springer International Pub-
lishing. 189 pp.
Bryzgalova, S., Pelger, M., and Zhu, J. (2021).“Forest Through the Trees: Building Cross-Sections of Stock Returns.”
In: <em>SSRN e-Print</em>.
Buczak, A. L., Baugher, B. D., Martin, C. S., Keiley-Listermann, M. W., Howard, J., Parrish, N. H., Stalick, A. Q.,
Berman, D. S., and Dredze, M. H. (2022).“Crystal Cube: Forecasting Disruptive Events.” In: <em>Applied Artificial
Intelligence</em> 36(1) (2001179), pp. 1–24.
Buehler, H., Gonon, L., Teichmann, J., and Wood, B. (2019).“Deep hedging.” In: <em>Quantitative Finance</em> 19 (8),
pp. 1271–1291.
Buehler, H., Horvath, B., Lyons, T., Arribas, I. P., and Wood, B. (2020).“A Data-driven Market Simulator for
Small Data Environments.” In: <em>arXiv e-Print</em>.
Buehler, H., Horvath, B., Lyons, T., Arribas, I. P., and Wood, B. (2021).“Generating financial markets with
signatures.” In: <em>Risk</em>.
Cai, M.-L., Chen, Z.-H., Li, S.-P., Xiong, X., Zhang, W., Yang, M.-Y., and Ren, F. (2022).“New volatility evolution
model after extreme events.” In: <em>arXiv e-Print</em>.
Cajas, D. (2021a).“Entropic Portfolio Optimization: a Disciplined Convex Programming Framework.” In: <em>SSRN
e-Print</em>.
Cajas, D. (2021b).“OWA Portfolio Optimization: a Disciplined Convex Programming Framework.” In: <em>SSRN e-
Print</em>.
Cao, H. and Guo, X. (2021).“Generative Adversarial Network: Some Analytical Perspectives.” In: <em>arXiv e-Print</em>.
Carrillo, J. A., Nieto, M., Velez, J. F., and Velez, D. (2021).“A New Machine Learning Forecasting Algorithm
Based on Bivariate Copula Functions.” In: <em>Forecasting</em> 3(2), pp. 355–376.
Cavaliere, G., Nielsen, H. B., and Rahbek, A. (2020).“An Introduction to Bootstrap Theory in Time Series Econo-
metrics.” In: <em>SSRN e-Print</em>.
Cerqueira, V., Torgo, L., and Mozetič, I. (2020).“Evaluating time series forecasting models: an empirical study on
performance estimation methods.” In: <em>Machine Learning</em> 109, pp. 1997–2028.
Chabi-Yo, F. and Loudis, J. (2021).“A Decomposition of Conditional Risk Premia and Implications for Represen-
tative Agent Models.” In: <em>SSRN e-Print</em>.
Chadebec, C. and Allassonniere, S. (2021). “Data Augmentation with Variational Autoencoders and Manifold
Sampling.” In: <em>arXiv e-Print</em>.
Chalkis, A., Christoforou, E., Dalamagkas, T., and Emiris, I. Z. (2021).“Modeling of crisis periods in stock markets.”
In: <em>arXiv e-Print</em>.
Chalongvorachai, T. and Woraratpanya, K. (2021).“A data generation framework for extremely rare case signals.”
In: <em>Helyon</em> 7(8), e07687.
Charte, D., Charte, F., Garcia, S., Jesus, M. J. del, and Herrera, F. (2018).“A practical tutorial on autoencoders
for nonlinear feature fusion: Taxonomy, models, software and guidelines.” In: <em>Information Fusion</em> 44, pp. 78–96.
Chen, A. Y. and Zimmermann, T. (2022).“Open Source Cross-Sectional Asset Pricing.” In: <em>American Finance
Association Annual Meeting</em>.
Chen, C. Y.-H. and Nasekin, S. (2020).“Quantifying systemic risk with factor copulas.” In: <em>The European Journal
of Finance</em> 26(18), pp. 1926–1947.
Chen, D.-G. and Chen, J. D. (2017). <em>Monte-Carlo Simulation-Based Statistical Modeling</em>. Ed. by D.-G. Chen and
J. D. Chen. ICSA book series in statistics. Singapore: Springer Singapore. 424 pp.
Chen, J., Tam, D., Raffel, C., Bansal, M., and Yang, D. (2021a).“An Empirical Survey of Data Augmentation for
Limited Data Learning in NLP.” In: <em>arXiv e-Print</em>.</p>
<p>Chen, W., Koo, B., Wang, Y., O’Hare, C., Langrené, N., Toscas, P., and Zhu, Z. (2021b).“Using a stochastic eco-
nomic scenario generator to analyse uncertain superannuation and retirement outcomes.” In: <em>Annals of Actuarial
Science</em>.
Chen, W., Minney, A., Toscas, P., Koo, B., Zhu, Z., and Pantelous, A. A. (2021c).“Personalised drawdown strategies
and partial annuitisation to mitigate longevity risk.” In: <em>Finance Research Letters</em> 39 (101644).
Cheng, P.-K. and Planchet, F. (2018).“Stochastic Deflator for an Economic Scenario Generator with Five Factors.”
In: <em>arXiv e-Print</em>.
Chevalier, C., Martius, O., and Ginsbourger, D. (2021).“Modeling Nonstationary Extreme Dependence With Sta-
tionary Max-Stable Processes and Multidimensional Scaling.” In: <em>Journal of Computational and Graphical Statis-
tics</em>.
Chib, S. (2020). <em>R package czfactor</em>. Tech. rep. Washington University.
Chib, S. and Zhao, L. (2020). <em>R package czzg</em>. Tech. rep. Washington University.
Chihara, L. M. and Hesterberg, T. C. (2018). <em>Mathematical Statistics with Resampling and R, 2nd Edition</em>. Wiley.
560 pp.
Clark, A. G., Walkinshaw, N., and Hierons, R. M. (2021).“Test case generation for agent-based models: A systematic
literature review.” In: <em>arXiv e-Print</em>.
Cogneau, P. and Zakamouline, V. (2013).“Block bootstrap methods and the choice of stocks for the long run.” In:
<em>Quantitative Finance</em> 13(9), pp. 1443–1457.
Cohort, P., Corbetta, J., and Laachir, I. (2020).“Analytical scores for stress scenarios.” In: <em>arXiv e-Print</em>.
Coletta, A., Prata, M., Conti, M., Mercanti, E., Bartolini, N., Moulin, A., Vyetrenko, S., and Balch, T. (2021).
“Towards Realistic Market Simulations: a Generative Adversarial Networks Approach.” In: <em>arXiv e-Print</em>.
Colson, A. R. and Cooke, R. M. (2017).“Cross validation for the classical model of structured expert judgment.”
In: <em>Reliability Engineering and System Safety</em> 163, pp. 109–120.
Coqueret, G. (2022). <em>Perspectives in sustainable equity investing (website version)</em>.
Coqueret, G. and Guida, T. (2020). <em>Machine Learning for Factor Investing: R Version</em>. Chapman and Hall/CRC.
341 pp.
Cramer, E., Gorjao, L. R., Mitsos, A., Schafer, B., Witthaut, D., and Dahmen, M. (2021). “Validation Methods for
Energy Time Series Scenarios from Deep Generative Models.” In: <em>arXiv e-Print</em>.
Cubuk, E. D., Zoph, B., Shlens, J., and Le, Q. V. (2019).“RandAugment: Practical data augmentation with no
separate search.” In: <em>arXiv e-Print</em>.
Czado, C. and Nagler, T. (2022).“Vine Copula Based Modeling.” In: <em>Annual Review of Statistics and Its Application</em>
9(1).
Czasonis, M., Kritzman, M., Pamir, B., and Turkington, D. (2020).“Enhanced Scenario Analysis.” In: <em>The Journal
of Portfolio Management</em> 46(4), pp. 69–79.
Czasonis, M., Kritzman, M., and Turkington, D. (2021).“Relevance.” In: <em>SSRN e-Print</em>.
Da Silva, B. and Shi, S. S. (2019).“Towards Improved Generalization in Financial Markets with Synthetic Data
Generation.” In: <em>arXiv e-Print</em>.
Dahl, C. M. and Sorensen, E. N. (2021).“Time Series (re)sampling using Generative Adversarial Networks.” In:
<em>arXiv e-Print</em>.
Davidson, R. (2017).“Diagnostics for the bootstrap and fast double bootstrap.” In: <em>Econometric Reviews</em> 36(6-9),
pp. 1021–1038.
Davis, M. and Lleo, S. (2015).“Behaviouralizing Black-Litterman: Expert Opinions and Behavioural Biases in a
Diffusion Setting.” In: <em>SSRN e-Print</em>.
Davis, M. H. A. and Lleo, S. (2016).“A Simple Procedure for Combining Expert Opinion with Statistical Estimates
to Achieve Superior Portfolio Performance.” In: <em>The Journal of Portfolio Management</em> 42(4), pp. 49–58.
de Carvalho, M. and Rua, A. (2017).“Real-time nowcasting the US output gap: Singular spectrum analysis at
work .” In: <em>International Journal of Forecasting</em> 33(1), pp. 185–198.
De Gennaro Aquino, L., Sornette, D., and Strub, M. S. (2021).“Portfolio Selection With Exploration of New
Investment Opportunities.” In: <em>SSRN e-Print</em>.
De Luca, G. and Zuccolotto, P. (2016).“A double clustering algorithm for financial time series based on extreme
events .” In: <em>Statistics and Risk Modeling</em> 0(0).
De Meer, F., Schwendner, P., and Wunsch, M. (2021).“Tackling the exponential scaling of signature-based GANs
for high-dimensional financial time series generation.” In: <em>SSRN e-Print</em>.</p>
<p>De Meer Pardo, F. (2019).“Enriching Financial Datasets with Generative Adversarial Networks.” MA thesis. Delft
University of Technology.
De Meer Pardo, F. and Lopez, R. C. (2020).“Mitigating Overfitting on Financial Datasets with Generative Adver-
sarial Networks.” In: <em>The Journal of Financial Data Science</em> 2 (1), pp. 76–85.
De Meo, E. (2019).“Scenario Design for Macro-Financial Stress Testing.” In: <em>SSRN e-Print</em>.
de Miranda Cardoso, J. V., Ying, J., and Palomar, D. P. (2020). “Algorithms for Learning Graphs in Financial
Markets.” In: <em>arXiv e-Print</em>.
Debnath, A., Waghmare, G., Wadhwa, H., Asthana, S., and Arora, A. (2021).“Exploring Generative Data Aug-
mentation in Multivariate Time Series Forecasting : Opportunities and Challenges.” In: <em>MiLeTS’21: 7th KDD
Workshop on Mining and Learning from Time Series</em>.
Denev, A. and Mutnikas, Y. (2016).“A Formalized, Integrated and Visual Approach to Stress Testing.” In: <em>SSRN
e-Print</em>.
Diffenbaugh, N. S. (2020).“Verification of extreme event attribution: Using out-of-sample observations to assess
changes in probabilities of unprecedented events.” In: <em>Science Advances</em> 6(12), eaay2368.
Ding, D., Zhang, M., Pan, X., Yang, M., and He, X. (2019).“Modeling Extreme Events in Time Series Prediction.”
In: <em>Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</em>.
ACM.
Ding, L., Ahmed, S., and Shapiro, A. (2020).“A Python package for multi-stage stochastic programming.” In:
<em>Optimization Online e-Print</em>.
Dixon, M. and Polson, N. (2020).“Deep Fundamental Factor Models.” In: <em>SIAM Journal on Financial Mathematics</em>
11(3), SC–26–SC–37.
Dixon, M. F., Halperin, I., and Bilokon, P. (2020). <em>Machine Learning in Finance: from theory to practice</em>. Springer
International Publishing. 548 pp.
Dogariu, M., Stefan, L.-D., Boteanu, B. A., Lamba, C., and Bogdan Ionescu, B. K. nd (2021a).“Generation of
Realistic Synthetic Financial Time-Series.” In: <em>ACM Trans. Multimedia Comput. Commun. Appl</em> 37(4) (111).
Dogariu, M., Stefan, L.-D., Boteanu, B. A., Lamba, C., and Ionescu, B. (2021b).“Towards Realistic Financial Time
Series Generation via Generative Adversarial Learning.” In: <em>European Signal Processing Conference - EUSIPCO</em>.
Dong, X., Li, Y., Rapach, D., and Zhou, G. (2022).“Anomalies and the expected market return.” In: <em>Journal of
Finance</em> 27(1), pp. 639–681.
Eckerli, F. (2021).“Generative Adversarial Networks in finance: an overview.” In: <em>SSRN e-Print</em>.
Eckerli, F. and Osterrieder, J. (2021).“Generative Adversarial Networks in finance: an overview.” In: <em>arXiv e-Print</em>.
El Karoui, N. and Purdom, E. (2018).“Can we trust the bootstrap in high-dimensions? the case of linear models.”
In: <em>The Journal of Machine Learning Research</em>.
Elkamhi, R. and Stefanova, D. (2015).“Dynamic Hedging and Extreme Asset Co-movements.” In: <em>The Review of
Financial Studies</em> 28(3), pp. 743–790.
Engelke, S. and Ivanovs, J. (2021).“Sparse Structures for Multivariate Extremes.” In: <em>Annual Review of Statistics
and Its Application</em> 8(1).
Engle, R. F. (2020).“Stress Testing with Market Data.” In: <em>SSRN e-Print</em>.
Esmaeili, A., Gallagher, J. C., Springer, J. A., and Matson, E. T. (2021).“HAMLET: A Hierarchical Agent-based
Machine Learning Platform.” In: <em>ACM Transactions on Autonomous and Adaptive Systems</em> 16(3-4), pp. 1–46.
Fabozzi, F. J., Fabozzi, F. A., Lopez de Prado, M., and Stoyanov, S. (2021). <em>Asset Management: Tools and Issues</em>.
World Scientific. 516 pp.
Facchinato, S. and Pola, G. (2014).“Managing uncertainty with diversification across macroeconomic scenarios
(DAMS): from asset segmentation to portfolio.” In: <em>SSRN e-Print</em>.
Faez, F., Ommi, Y., Baghshah, M. S., and Rabiee, H. R. (2020).“Deep Graph Generators: A Survey.” In: <em>arXiv
e-Print</em>.
Faggini, M., Bruno, B., and Parziale, A. (2019).“Crises in economic complex networks: Black Swans or Dragon
Kings?” In: <em>Economic Analysis and Policy</em> 62, pp. 105–115.
Fakoor, R., Mueller, J., Erickson, N., Chaudhari, P., and Smola, A. J. (2020).“Fast, Accurate, and Simple Models
for Tabular Data via Augmented Distillation.” In: <em>arXiv e-Print</em>.
Fang, J. and Lin, J. (2020).“Prior knowledge distillation based on financial time series.” In: <em>arXiv e-Print</em>.
Fawaz, H. I., Forestier, G., Weber, J., Idoumghar, L., and Muller, P.-A. (2018).“Data augmentation using synthetic
data for time series classification with deep residual networks.” In: <em>arXiv e-Print</em>.</p>
<p>Flaig, S. and Junike, G. (2022). “Scenario generation for market risk models using generative neural networks.” In:
<em>arXiv e-Print</em>.
Flood, M. D. and Korenko, G. G. (2015).“Systematic scenario selection: stress testing and the nature of uncertainty.”
In: <em>Quantitative Finance</em> 15(1), pp. 43–59.
Fons, E., Dawson, P., Zeng, X.-j., Keane, J., and Iosifidis, A. (2021a).“Adaptive Weighting Scheme for Automatic
Time-Series Data Augmentation.” In: <em>arXiv e-Print</em>.
Fons, E., Dawson, P., Zeng, X.-j., Keane, J., and Iosifidis, A. (2021b).“Augmenting Transferred Representations for
Stock Classification.” In: <em>ICASSP 2021 - 2021 IEEE International Conference on Acoustics, Speech and Signal
Processing (ICASSP)</em>. IEEE.
Foramitti, J. (2021).“AgentPy: A package for agent-based modeling in Python.” In: <em>Journal of Open Source Software</em>
6(62), p. 3065.
Frahm, G. (2015).“A theoretical foundation of portfolio resampling.” In: <em>Theory and Decision</em> 79(1), pp. 107–132.
Franco-Pedroso, J., Gonzalez-Rodriguez, J., Planas, M., Cubero, J., Cobo, R., and Pablos, F. (2019a).“Generating
Virtual Scenarios of Multivariate Financial Data for Quantitative Trading Applications.” In: <em>The Journal of
Financial Data Science</em> 1 (2), pp. 55–77.
Franco-Pedroso, J., Gonzalez-Rodriguez, J., Planas, M., Cubero, J., Cobo, R., and Pablos, F. (2019b).“The ETS
challenges: a machine learning approach to the evaluation of simulated financial time series for improving gen-
eration processes.” In: <em>The Journal of Financial Data Science</em> 1(3) (3), pp. 68–86.
Franses, P. H. and Bruijn, B. de (2017).“Benchmarking Judgmentally Adjusted Forecasts.” In: <em>International Journal
of Finance and Economics</em> 22(1), pp. 3–11.
Fritzsch, S., Timphus, M., and Weiss, G. N. F. (2021).“Marginals Versus Copulas: Which Account For More Model
Risk In Multivariate Risk Forecasting?” In: <em>SSRN e-Print</em>.
Fu, B., Kirchbuchner, F., and Kuijper, A. (2020).“Data augmentation for time series.” In: <em>Proceedings of the 13th
ACM International Conference on Pervasive Technologies Related to Assistive Environments</em>. ACM.
Fulle, M. J. and Herwartz, H. (2021).“A Multivariate Markov-Switching GARCH Model with Copula-Distributed
Innovations.” In: <em>SSRN e-Print</em>.
Galeeva, R., Hoogland, J., and Eydeland, A. (2012).“Measuring correlation risk for Energy Derivatives.” In: <em>Risk
Management in Commodity Markets: From Shipping to Agriculturals and Energy</em>.
Gao, G., Mishra, B., and Ramazzotti, D. (2017).“Efficient Simulation of Financial Stress Testing Scenarios with
Suppes-Bayes Causal Networks.” In: <em>arXiv e-Print</em>.
Gao, G., Mishra, B., and Ramazzotti, D. (2018).“Causal data science for financial stress testing.” In: <em>Journal of
Computational Science</em> 26, pp. 294–304.
Gharghabi, S., Imani, S., Bagnall, A., Darvishzadeh, A., and Keogh, E. (2018).“Matrix profile XII: mpdist: A
novel time series distance measure to allow data mining in more challenging scenarios.” In: <em>IEEE International
Conference on Data Mining (ICDM)</em>. IEEE, pp. 965–970.
Gilleland, E. (2020a).“Bootstrap Methods for Statistical Inference. Part I: Comparative Forecast Verification for
Continuous Variables.” In: <em>Journal of Atmospheric and Oceanic Technology</em> 37(11), pp. 2117–2134.
Gilleland, E. (2020b).“Bootstrap Methods for Statistical Inference. Part II: Extreme-Value Analysis.” In: <em>Journal
of Atmospheric and Oceanic Technology</em> 37(11), pp. 2135–2144.
Glasserman, P., Kang, C., and Kang, W. (2015).“Stress scenario selection by empirical likelihood.” In: <em>Quantitative
Finance</em> 15(1), pp. 25–41.
Goel, K., Gu, A., Li, Y., and Re, C. (2020).“Model Patching: Closing the Subgroup Performance Gap with Data
Augmentation.” In: <em>arXiv e-Print</em>.
Golub, B., Greenberg, D., and Ratcliffe, R. (2018).“Market-Driven Scenarios: An Approach for Plausible Scenario
Construction.” In: <em>The Journal of Portfolio Management</em> 44(5), pp. 6–20.
Goncalves, S. and Perron, B. (2020).“Bootstrapping factor models with cross sectional dependence.” In: <em>Journal of
Econometrics</em> 218(2), pp. 476–495.
Gonzalez, D. P., Rebollo, F. F., Polo, F. J. G., and Vyetrenko, S. (2021).“Similarity Metrics for Transfer Learning
in Financial Markets.” In: <em>ICAPS Workshop on Planning for Financial Services (FinPlan 2021)</em>.
Grealish, A. and Kolm, P. N. (2021).“Robo-Advisory: From Investing Principles and Algorithms to Future Devel-
opments.” In: <em>SSRN e-Print</em>.
Großer, J. and Okhrin, O. (2021).“Copulae: An overview and recent developments.” In: <em>WIREs Computational
Statistics</em>.</p>
<p>Grundke, P. (2012).“Further recipes for quantitative reverse stress testing.” In: <em>Journal of Risk Model Validation</em>
6(2).
Guijarro-Ordonez, J., Pelger, M., and Zanotti, G. (2021).“Deep Learning Statistical Arbitrage.” In: <em>SSRN e-Print</em>.
Gurdogan, H. and Kercheval, A. (2021). “Multi Anchor Point Shrinkage for the Sample Covariance Matrix (Extended
Version).” In: <em>arXiv e-Print</em>.
Gzyl, H., Horst, E. ter, and Molina, G. (2017).“Inferring probability densities from expert opinion.” In: <em>Applied
Mathematical Modelling</em> 43, pp. 306–320.
Haldane, A. G. and Turrell, A. E. (2018).“Drawing on different disciplines: macroeconomic agent-based models.”
In: <em>Journal of Evolutionary Economics</em> 29(1), pp. 1–28.
Hambuckers, J. and Heuchenne, C. (2016).“Estimating the Out-of-Sample Predictive Ability of Trading Rules: A
Robust Bootstrap Approach.” In: <em>Journal of Forecasting</em> 35(4), pp. 347–372.
Harutyunyan, H., Moyer, D., Khachatrian, H., Steeg, G. V., and Galstyan, A. (2021).“Efficient Covariance Esti-
mation from Temporal Data.” In: <em>arXiv e-Print</em>.
Harwick, C. (2021).“Helipad: A Framework for Agent-Based Modeling in Python.” In: <em>SSRN e-Print</em>.
He, Z., Xie, L., Chen, X., Zhang, Y., Wang, Y., and Tian, Q. (2019).“Data Augmentation Revisited: Rethinking
the Distribution Gap between Clean and Augmented Data.” In: <em>arXiv e-Print</em>.
Heaton, J. B. and Witte, J. (2021).“Synthetic Financial Data: An Application to Regulatory Compliance for
Broker-Dealers.” In: <em>SSRN e-Print</em>.
Henry-Labordere, P. (2019).“Generative models for financial data.” In: <em>SSRN e-Print</em>.
Ho, J., Tumkaya, T., Aryal, S., Choi, H., and Claridge-Chang, A. (2019).“Moving beyond P values: data analysis
with estimation graphics.” In: <em>Nature Methods</em> 16(7), pp. 565–566.
Hofert, M., Prasad, A., and Zhu, M. (2021).“Multivariate time-series modeling with generative neural networks.”
In: <em>arXiv e-Print</em>.
Hoffman, J. I. E. (2015).“Resampling Statistics.” In: <em>Biostatistics for Medical and Biomedical Practitioners</em>. Elsevier,
pp. 655–661.
Hoffmann, J., Bar-Sinai, Y., Lee, L., Andrejevic, J., Mishra, S., Rubinstein, S. M., and Rycroft, C. H. (2018).
“Machine Learning in a data-limited regime: Augmenting experiments with synthetic data uncovers order in
crumpled sheets.” In: <em>arXiv e-Print</em>.
Homescu, C. (2014).“Many risks, one (optimal) portfolio.” In: <em>SSRN e-Print</em>.
Homescu, C. (2015).“Better Investing Through Factors, Regimes and Sensitivity Analysis.” In: <em>SSRN e-Print</em>.
Honore, B. E. and Hu, L. (2017).“Poor (Wo)man’s Bootstrap.” In: <em>Econometrica</em> 85(4), pp. 1277–1301.
Horowitz, J. L. (2019).“Bootstrap methods in econometrics.” In: <em>Annual review of economics</em> 11(1), pp. 193–224.
Hsu, M.-W., Lessmann, S., Sung, M.-C., Ma, T., and Johnson, J. E. V. (2016).“Bridging the divide in financial
market forecasting: machine learners vs. financial economists.” In: <em>Expert Systems with Applications</em> 61, pp. 215–
234.
Hu, J., Akande, O., and Wang, Q. (2021). “Multiple Imputation and Synthetic Data Generation with the R package
NPBayesImputeCat.” In: <em>arXiv e-Print</em>.
Huang, M. and Yu, S. (2020).“A new procedure for resampled portfolio with shrinkaged covariance matrix.” In:
<em>Journal of Applied Statistics</em> 47(44), pp. 642–652.
Imbens, G. and Menzel, K. (2021).“A causal bootstrap.” In: <em>Annals of Statistics</em> 49(3).
Imokoyende, M. (2019).“Variational Autoencoder In Finance.” In: <em>Towards Data Science</em>.
Irlam, G. (2020a). <em>AI Planner</em> .url:https://www.aiplanner.com/.
Irlam, G. (2020b).“Machine learning for retirement planning.” In: <em>The Journal of Retirement</em> 8(1), pp. 32–29.
Irlam, G. (2020c).“Multi Scenario Financial Planning via Deep Reinforcement Learning AI.” In: <em>SSRN e-Print</em>.
Istrate, G. (2021).“Models we Can Trust: Toward a Systematic Discipline of (Agent-Based) Model Interpretation
and Validation.” In: <em>arXiv e-Print</em>.
Iwana, B. K. and Uchida, S. (2021).“An empirical survey of data augmentation for time series classification with
neural networks.” In: <em>PLOS One</em> 16(7). Ed. by F. Schwenker, e0254841.
Jabbar, A., Li, X., and Omar, B. (2020).“A Survey on Generative Adversarial Networks: Variants, Applications,
and Training.” In: <em>arXiv e-Print</em>.
Jaeger, M., Krugel, S., Marinelli, D., Papenbrock, J., and Schwendner, P. (2020).“Understanding machine learning
for diversified portfolio construction by explainable AI.” In: <em>SSRN e-Print</em>.
Janke, T., Ghanmi, M., and Steinke, F. (2021). “Implicit Generative Copulas.” In: <em>arXiv e-Print</em>.
Jansen, S. (2020). <em>Machine Learning for Algorithmic Trading (Second Edition)</em>. Packt Publishing. 820 pp.</p>
<p>Javeri, I. Y., Toutiaee, M., Arpinar, I. B., Miller, J. A., and Miller, T. W. (2021).“Improving Neural Networks for
Time-Series Forecasting using Data Augmentation and AutoML.” In: <em>IEEE Seventh International Conference
on Big Data Computing Service and Applications (BigDataService)</em>. IEEE.
Jericevich, I., McKechnie, M., and Gebbie, T. (2021).“Calibrating an adaptive Farmer-Joshi agent-based model for
financial markets.” In: <em>arXiv e-Print</em>.
Jiang, L., Dai, B., Wu, W., and Loy, C. C. (2021a). “Deceive D: Adaptive Pseudo Augmentation for GAN Training
with Limited Data.” In: <em>arXiv e-Print</em>.
Jiang, W., Song, S., Hou, L., and Zhao, H. (2021b).“A set of efficient methods to generate high-dimensional binary
data with specified correlation structures.” In: <em>The American Statistician</em> 75(3), pp. 310-3221–37.
Jin, C. and Rinard, M. (2021). “Towards Context-Agnostic Learning Using Synthetic Data.” In: <em>arXiv e-Print</em>.
Johnson, M. C. and West, M. (2018).“Bayesian Predictive Synthesis: Forecast Calibration and Combination.” In:
<em>arXiv e-Print</em>.
Juan, A. A., Keenan, P., Martı́, R., McGarraghy, S., Panadero, J., Carroll, P., and Oliva, D. (2022).“A review of
the role of heuristics in stochastic optimisation: from metaheuristics to learnheuristics.” In: <em>Annals of Operations
Research</em>.
Jurczenko et al. (2020). <em>Machine Learning for Asset Management</em>. Ed. by E. Jurczenko. Wiley. 445 pp.
Kakushadze, Z. and Yu, W. (2016).“Statistical Risk Models.” In: <em>SSRN e-Print</em>.
Kakushadze, Z. and Yu, W. (2017).“Open Source Fundamental Industry Classification.” In: <em>MDPI Data</em> 22 (2).
Kakushadze, Z. and Yu, W. (2018a).“Betas, Benchmarks, and Beating the Market.” In: <em>The Journal of Trading</em>.
Kakushadze, Z. and Yu, W. (2018b).“Decoding stock market with quant alphas.” In: <em>Journal of Asset Management</em> ,
pp. 1–11.
Kakushadze, Z. and Yu, W. (2019).“Machine learning risk models.” In: <em>SSRN e-Print</em>.
Kakushadze, Z. and Yu, W. (2020).“Machine learning treasury yields.” In: <em>SSRN e-Print</em>.
Kang, Y., Hyndman, R. J., and Li, F. (2020).“GRATIS: GeneRAting TIme Series with diverse and controllable
characteristics.” In: <em>Statistical Analysis and Data Mining: The ASA Data Science Journal</em> 13(4), pp. 354–376.
Kang, Y., Spiliotis, E., Petropoulos, F., Athiniotis, N., Li, F., and Assimakopoulos, V. (2021).“Déjà vu: A data-
centric forecasting approach through time series cross-similarity.” In: <em>Journal of Business Research</em>.
Kantos, C. and diBartolomeo, D. (2020).“How the pandemic taught us to turn smart beta into real alpha.” In:
<em>Journal of Asset Management</em> 21(7), pp. 581–590.
Kapoor, A. and Shrivastava, U. (2014).“Extreme Values Theory and Return Level Analysis for Catastrophe Pre-
diction.” In: <em>The Journal of Investing</em> 23(2), pp. 124–135.
Karaś, M. and Serwatka, A. (2021).“Strong-hand conjecture: agent-based numerical simulation.” In: <em>The Journal
of Investment Strategies</em>.
Kegel, L., Hahmann, M., and Lehner, W. (2017).“Generating What-If Scenarios for Time Series Data.” In: <em>Proceed-
ings of the 29th International Conference on Scientific and Statistical Database Management - ’17</em>. New York,
New York, USA: ACM Press, pp. 1–12.
Kegel, L., Hahmann, M., and Lehner, W. (2018).“Feature-based comparison and generation of time series.” In:
<em>Proceedings of the 30th International Conference on Scientific and Statistical Database Management - ’18</em>. New
York, New York, USA: ACM Press, pp. 1–12.
Kemp, M. (2014). <em>Extreme Events: Robust Portfolio Construction in the Presence of Fat Tails</em>. Wiley. 334 pp.
Kingma, D. P. and Welling, M. (2019).“An introduction to variational autoencoders.” In: <em>Foundations and Trends
in Machine Learning</em> 12(4), pp. 307–392.
Koesdwiady, A., Khatib, A. E., and Karray, F. (2018).“Methods to Improve Multi-Step Time Series Prediction.”
In: <em>International Joint Conference on Neural Networks (IJCNN)</em>. IEEE, pp. 1–8.
Kondratyev, A. and Schwarz, C. (2020).“The Market Generator.” In: <em>Risk</em>.
Kong, K., Li, G., Ding, M., Wu, Z., Zhu, C., Ghanem, B., Taylor, G., and Goldstein, T. (2022). “Robust Optimization
as Data Augmentation for Large-scale Graphs.” In: <em>arXiv e-Print</em>.
Koochali, A., Dengel, A., and Ahmed, S. (2020).“If You Like It, GAN It. Probabilistic Multivariate Times Series
Forecast With GAN.” In: <em>arXiv e-Print</em>.
Kopeliovich, Y., Novosyolov, A., Satchkov, D., and Schachter, B. (2015).“Robust Risk Estimation and Hedging: A
Reverse Stress Testing Approach.” In: <em>The Journal of Derivatives</em> 22(4), pp. 10–25.
Koshiyama, A., Firoozye, N., and Treleaven, P. (2021).“Generative Adversarial Networks for Financial Trading
Strategies Fine-Tuning and Combination.” In: <em>Quantitative Finance</em> 21(5), pp. 797–813.</p>
<p>Kreiss, J.-P. and Paparoditis, E. (2011).“Bootstrap methods for dependent data: A review.” In: <em>Journal of the
Korean Statistical Society</em> 40(4), pp. 357–378.
Kritzman, M., Kinlaw, W., and Turkington, D. (2017). <em>A Practitioner’s Guide to Asset Allocation</em>. Wiley. 256 pp.
Kritzman, M., Li, D., Qiu, G. (, and Turkington, D. (2021).“Portfolio Choice with Path-Dependent Scenarios.” In:
<em>Financial Analysts Journal</em> 77(1), pp. 90–100.
Kritzman, M. and Turkington, D. (2021).“History, Shocks and Drifts: A New Approach to Portfolio Formation.”
In: <em>SSRN e-Print</em>.
Kritzman, M. and Turkington, D. (2022).“History, Shocks, and Drifts: A New Approach to Portfolio Formation.”
In: <em>The Journal of Portfolio Management</em> 48(2).
Kuchnik, M. and Smith, V. (2018).“Efficient Augmentation via Data Subsampling.” In: <em>arXiv e-Print</em>.
Lai, K.-H., Zha, D., Wang, G., Xu, J., Zhao, Y., Kumar, D., Chen, Y., Zumkhawaka, P., Wan, M., Martinez, D.,
and Hu, X. (2021). “TODS: An Automated Time Series Outlier Detection System.” In: <em>arXiv e-Print</em>.
Lam, H. and Li, F. (2020).“Parametric Scenario Optimization under Limited Data: A Distributionally Robust
Optimization View.” In: <em>arXiv e-Print</em>.
Laskin, M., Lee, K., Stooke, A., Pinto, L., Abbeel, P., and Srinivas, A. (2020). “Reinforcement Learning with
Augmented Data.” In: <em>arXiv e-Print</em>.
Lawrence, A. R., Kaiser, M., Sampaio, R., and Sipos, M. (2021).“Data Generating Process to Evaluate Causal
Discovery Techniques for Time Series Data.” In: <em>arXiv e-Print</em>.
Ledermann, D. and Alexander, C. (2012). “Further properties of random orthogonal matrix simulation.” In: <em>Math-
ematics and Computers in Simulation</em> 83, pp. 56–79.
Ledermann, W., Alexander, C., and Ledermann, D. (2011). “Random orthogonal matrix simulation.” In: <em>Linear
Algebra and its Applications</em> 434, pp. 1444–1467.
Ledoit, O. and Wolf, M. (2021).“Shrinkage estimation of large covariance matrices: Keep it simple, statistician?”
In: <em>Journal of Multivariate Analysis</em> 186, p. 104796.
Lee, Y.-H., Hsieh, M.-H., Kuo, W., and Tsai, C. J. (2021).“How can an economic scenario generation model cope
with abrupt changes in financial markets?” In: <em>China Finance Review International</em> 11(3), pp. 372–405.
Lee, M. I. (2013).“Stress testing Monte Carlo assumptions.” In: <em>SSRN e-Print</em>.
Leon, C. and Reveiz, A. (2012).“Monte Carlo Simulation of Long-Term Dependent Processes: A Primer.” In:
<em>Wilmott</em> 2012(60), pp. 48–57.
Lerch, S., Thorarinsdottir, T. L., Ravazzolo, F., and Gneiting, T. (2017).“Forecaster’s Dilemma: Extreme Events
and Forecast Evaluation.” In: <em>Statistical Science</em> 32(1), pp. 106–127.
Lettau, M. and Pelger, M. (2020).“Factors That Fit the Time Series and Cross-Section of Stock Returns.” In: <em>The
Review of Financial Studies</em> 33(5), pp. 2274–2325.
Lezmi, E., Malongo, H., Roncalli, T., and Sobotka, R. (2019).“Portfolio Allocation with Skewness Risk: A Practical
Guide.” In: <em>SSRN e-Print</em>.
Lezmi, E., Roche, J., Roncalli, T., and Xu, J. (2020).“Improving the Robustness of Trading Strategy Backtesting
with Boltzmann Machines and Generative Adversarial Networks.” In: <em>SSRN e-Print</em>.
Leznik, M., Michalsky, P., Willis, P., Schanzel, B., Ostberg, P.-O., and Domaschka, J. (2021).“Multivariate Time
Series Synthesis Using Generative Adversarial Networks.” In: <em>Proceedings of the ACM/SPEC International Con-
ference on Performance Engineering</em>. ACM.
Li, B., Luo, S., Qin, X., and Pan, L. (2021a).“Improving GAN with inverse cumulative distribution function for
tabular data synthesis.” In: <em>Neurocomputing</em> 456, pp. 373–383.
Li, G., Huang, L., Yang, J., and Zhang, W. (2022).“A Synthetic Regression Model for Large Portfolio Allocation.”
In: <em>Journal of Business &amp; Economic Statistics</em> , pp. 1–13.
Li, Z., Liu, X.-Y., Zheng, J., Wang, Z., Walid, A., and Guo, J. (2021b).“FinRL-Podracer: High Performance and
Scalable Deep Reinforcement Learning for Quantitative Finance.” In: <em>ACM International Conference on AI in
Finance</em>.
Li, Z., Zhao, Y., and Fu, J. (2020).“SynC: A Copula based Framework for Generating Synthetic Data from
Aggregated Sources.” In: <em>International Conference on Data Mining Workshops (ICDMW)</em>. IEEE.
Lim, S. H., Erichson, N. B., Utrera, F., Xu, W., and Mahoney, M. W. (2021). “Noisy Feature Mixup.” In: <em>arXiv
e-Print</em>.
Lin, Z., Jain, A., Wang, C., Fanti, G., and Sekar, V. (2019).“Generating High-fidelity, Synthetic Time Series
Datasets with DoppelGANger.” In: <em>arXiv e-Print</em>.</p>
<p>Linardi, M., Zhu, Y., Palpanas, T., and Keogh, E. (2018).“VALMOD: A suite for easy and exact detection of
variable length motifs in data series.” In: <em>Proceedings of the 2018 International Conference on Management of
Data - SIGMOD ’18</em>. New York, New York, USA: ACM Press, pp. 1757–1760.
Lindner, D., Shah, R., Abbeel, P., and Dragan, A. (2021). “Learning What To Do by Simulating the Past.” In:
<em>arXiv e-Print</em>.
Little, M. A. and Badawy, R. (2020). “Causal bootstrapping.” In: <em>arXiv e-Print</em>.
Liu, B., Zhang, Z., and Cui, R. (2020).“Efficient Time Series Augmentation Methods.” In: <em>13th International
Congress on Image and Signal Processing, BioMedical Engineering and Informatics (CISP-BMEI)</em>. IEEE.
Liu, X.-Y., Rui, J., Gao, J., Yang, L., Yang, H., Wang, Z., Wang, C. D., and Guo, J. (2022). “FinRL-Meta: A
Universe of Near-Real Market Environments for Data-Driven Deep Reinforcement Learning in Quantitative
Finance.” In: <em>arXiv e-Print</em>.
Liu, X.-Y., Yang, H., Gao, J., and Wang, C. (2021).“FinRL: Deep Reinforcement Learning Framework to Automate
Trading in Quantitative Finance.” In: <em>SSRN e-Print</em>.
Lopez de Prado, M. (2020). <em>Machine learning for asset managers</em>. Cambridge University Press. 190 pp.
Lu, L. and Ghosh, S. (2021). “Nonparametric estimation of multivariate copula using empirical bayes method.” In:
<em>arXiv e-Print</em>.
Lux, T. (2021).“Can heterogeneous agent models explain the alleged mispricing of the S&amp;P 500?” In: <em>Quantitative
Finance</em> 21(9), pp. 1413–1433.
Ma, J. (2021). “copent: Estimating Copula Entropy and Transfer Entropy in R.” In: <em>arXiv e-Print</em>.
Mammen, E. and Nandi, S. (2012).“Bootstrap and Resampling.” In: <em>Handbook of Computational Statistics</em>. Ed. by
J. E. Gentle, W. K. Hardle, and Y. Mori. Springer Handbooks of Computational Statistics. Springer Berlin
Heidelberg, pp. 499–527.
Mannix, R. and Cesa, M. (2021).“’Signatures’ promise quants a tool for all jobs.” In: <em>Risk (Quant Investing)</em>.
Mariani, G., Zhu, Y., Li, J., Scheidegger, F., Istrate, R., Bekas, C., and Malossi, A. C. I. (2019).“PAGAN: Portfolio
Analysis with Generative Adversarial Networks.” In: <em>arXiv e-Print</em>.
Marinescu, M. (2022).“Risk-Based Optimal Portfolio Strategies: A Compendium.” In: <em>SSRN e-Print</em>.
Marti, G. (2020a).“CORRGAN: sampling realistic financial correlation matrices using generative adversarial net-
works .” In: <em>ICASSP - IEEE nternational Conference on Acoustics, Speech and Signal Processing</em>. IEEE, pp. 8459–
8463.
Marti, G. (2020b).“Generating Realistic Synthetic Data in Finance: Applications of GANs.” In: <em>IHS Markit Webinar</em>.
Marti, G., Andler, S., Nielsen, F., and Donnat, P. (2017). “Exploring and measuring non-linear correlations: Copulas,
Lightspeed Transportation and Clustering.” In: <em>Proceedings of Machine Learning Research</em> 55, pp. 59–69.
Marti, G., Goubet, V., and Nielsen, F. (2021a).“cCorrGAN: Conditional Correlation GAN for Learning Empirical
Conditional Distributions in the Elliptope.” In: <em>International Conference on Geometric Science of Information</em>.
Springer International Publishing, pp. 613–620.
Marti, G., Nielsen, F., Bihkowski, M., and Donnat, P. (2021b).“A review of two decades of correlations, hierarchies,
networks and clustering in financial markets.” In: <em>Progress in Information Geometry</em> , pp. 245–274.
Martin, R. (2021).“PyPortfolioOpt: portfolio optimization in Python.” In: <em>Journal of Open Source Software</em> 6(61),
p. 3066.
Marwood, D. and Minnen, D. (2020).“Safely Boosting Retirement Income by Harmonizing Drawdown Paths.” In:
<em>Journal of Financial Planning</em> 33(11), pp. 46–60.
Maschner, C., Moritz, B., and Schmitz, M. (2021).“Modern Asset Management.” In: <em>SSRN e-Print</em>.
McIndoe, C. (2020).“A Data Driven Approach to Market Regime Classification.” MA thesis. Imperial College.
Medina, M. A., Davis, R. A., and Samorodnitsky, G. (2021). “Spectral learning of multivariate extremes.” In: <em>arXiv
e-Print</em>.
Meucci, A. (2008). “Fully Flexible Views: Theory and Practice.” In: <em>Risk</em> 21(10), pp. 97–102.
Meucci, A. (2012). <em>A Fully Integrated Liquidity and Market Risk Model</em>. Tech. rep. EDHEC.
Meucci, A., Ardia, D., and Keel, S. (2012). “Fully Flexible Extreme Views.” In: <em>Risk</em> 14(2), pp. 39–49.
Meyer, D. and Nagler, T. (2021).“Synthia: multidimensional synthetic data generation in Python.” In: <em>Journal of
Open Source Software</em> 6(65), p. 2863.
Michaud, R. O. and Michaud, R. (2015).“Estimation Error and Portfolio Optimization: A Resampling Solution.”
In: <em>SSRN e-Print</em>.
Micheli, A. and Neuman, E. (2022). “Evidence of Crowding on Russell 3000 Reconstitution Events.” In: <em>arXiv
e-Print</em>.</p>
<p>Mikalsen, K. O., Bianchi, F. M., Soguero-Ruiz, C., and Jenssen, R. (2018).“Time Series Cluster Kernel for Learning
Similarities between Multivariate Time Series with Missing Data.” In: <em>Pattern Recognition</em> 76, pp. 569–581.
Milevsky, M. A. (2020). <em>Retirement Income Recipes in R: From Ruin Probabilities to Intelligent Drawdowns</em>. Springer
International Publishing. 302 pp.
Moudiki, T. and Planchet, F. (2016).“Economic Scenario Generators.” In: <em>Modelling in Life Insurance - A Man-
agement Perspective</em>. Ed. by J.-P. Laurent, R. Norberg, and F. Planchet. EAA Series. Springer International
Publishing, pp. 81–104.
Nasri, B. R. and Rémillard, B. N. (2019).“Copula-based dynamic models for multivariate time series.” In: <em>Journal
of Multivariate Analysis</em> 172, pp. 107–121.
Nasri, B. R., Rémillard, B. N., and Thioub, M. Y. (2020).“Goodness-of-fit for regime-switching copula models with
application to option pricing.” In: <em>Canadian Journal of Statistics</em> 48(1), pp. 79–96.
Naveau, P., Hannart, A., and Ribes, A. (2020).“Statistical methods for extreme event attribution in climate science.”
In: <em>Annual Review of Statistics and its Application</em> 7(1), pp. 89–110.
Nguyen, H. D. and Chamroukhi, F. (2018).“Practical and theoretical aspects of mixture-of-experts modeling: An
overview.” In: <em>WIREs Data Mining Knowl Discov</em> 8(4), e1246.
Ni, H., Szpruch, L., Wiese, M., Liao, S., and Xiao, B. (2020).“Conditional Sig-Wasserstein GANs for Time Series
Generation.” In: <em>arXiv e-Print</em>.
Niemann, J.-H., Klus, S., and Schutte, C. (2021).“Data-driven model reduction of agent-based systems using the
Koopman generator.” In: <em>arXiv e-Print</em>.
Oneto, L. (2019).“Resampling Methods.” In: <em>Model Selection and Error Estimation in a Nutshell</em>. Springer Inter-
national Publishing, pp. 25–31.
Opdyke, J. D. (2020).“Full Probabilistic Control for Direct and Robust, Generalized and Targeted Stressing of the
Correlation Matrix (Even When Eigenvalues are Empirically Challenging.” In: <em>QuantMinds/RiskMinds Confer-
ence</em>.
Ortec Finance (2014).“Ex ante risk management with scenarios.” In: <em>CFA Society Switzerland</em>.
Packham, N. and Woebbeking, F. (2021).“Correlation scenarios and correlation stress testing.” In: <em>SSRN e-Print</em>.
Padhi, I., Schiff, Y., Melnyk, I., Rigotti, M., Mroueh, Y., Dognin, P., Ross, J., Nair, R., and Altman, E. (2021).
“Tabular Transformers for Modeling Multivariate Time Series.” In: <em>arXiv e-Print</em>.
Page, S. (2013).“How to combine long and short return histories efficiently.” In: <em>Financial Analysts Journal</em> 69(1),
pp. 45–52.
Pan, I., Mason, L., and Matar, O. (2021). “Data-Centric Engineering: integrating simulation, machine learning and
statistics. Challenges and Opportunities.” In: <em>arXiv e-Print</em>.
Panchekha, A., Tull, R., and Bell, M. M. (2018).“Ensemble Active Management.” In: <em>SSRN e-Print</em>.
Papenbrock, J., Schwendner, P., Jaeger, M., and Krugel, S. (2021).“Matrix Evolutions: Synthetic Correlations and
Explainable Machine Learning for Constructing Robust Investment Portfolios.” In: <em>The Journal of Financial
Data Science</em> 3(2), pp. 51–69.
Papoudakis, G., Christianos, F., and Albrecht, S. V. (2021). “Agent Modelling under Partial Observability for Deep
Reinforcement Learning.” In: <em>arXiv e-Print</em>.
Pathak, P. K. and Rao, C. R. (2013).“The Sequential Bootstrap.” In: <em>Handbook of Statistics</em>. Vol. 31. Elsevier,
pp. 2–18.
Paul, J., Michael, B.-S., Pedro, M., Rajbir, S. N., Shubham, K., Valentin, F., Jan, G., and Tim, J. (2022). “PSA-
GAN: Progressive Self Attention GANs for Synthetic Time Series.” In: <em>arXiv e-Print</em>.
Pei, H., Ren, K., Yang, Y., Liu, C., Qin, T., and Li, D. (2021). “Towards Generating Real-World Time Series Data.”
In: <em>arXiv e-Print</em>.
Perez, J., Arroba, P., and Moya, J. M. (2022). “Data augmentation through multivariate scenario forecasting in
Data Centers using Generative Adversarial Networks.” In: <em>arXiv e-Print</em>.
Perrin, S. and Roncalli, T. (2020).“Machine Learning Optimization Algorithms &amp; Portfolio Allocation.” In: <em>Machine
Learning for Asset Management: New Developments and Financial Applications</em>. Ed. by E. Jurczenko. Wiley,
pp. 261–328.
Perumal, R. and van Zyl, T. L. (2020).“Surrogate Assisted Methods for the Parameterisation of Agent-Based
Models.” In: <em>arXiv e-Print</em>.
Pesenti, S. M., Bettini, A., Millossovich, P., and Tsanakas, A. (2020).“Scenario weights for importance measurement
(SWIM) - an R package for sensitivity analysis.” In: <em>SSRN e-Print</em>.</p>
<p>Pesenti, S. M., Millossovich, P., and Tsanakas, A. (2019).“Reverse sensitivity testing: What does it take to break
the model?” In: <em>European Journal of Operational Research</em> 274(2), pp. 654–670.
Qi, D. and Majda, A. J. (2019).“Using machine learning to predict extreme events in complex systems.” In:
<em>Proceedings of the National Academy of Sciences of the United States of America</em>.
Qian, W., Rolling, C. A., Cheng, G., and Yang, Y. (2022).“Combining forecasts for universally optimal perfor-
mance.” In: <em>International Journal of Forecasting</em>.
Raab, G. M., Nowok, B., and Dibben, C. (2021). “Assessing, visualizing and improving the utility of synthetic data.”
In: <em>arXiv e-Print</em>.
Racca, A. and Magri, L. (2022). “Statistical prediction of extreme events from small datasets.” In: <em>arXiv e-Print</em>.
Raghunathan, T. E. (2021).“Synthetic Data.” In: <em>Annual Review of Statistics and Its Application</em> 8(1), pp. 129–140.
Raileanu, R., Goldstein, M., Yarats, D., Kostrikov, I., and Fergus, R. (2021). “Automatic Data Augmentation for
Generalization in Deep Reinforcement Learning.” In: <em>arXiv e-Print</em>.
Rajabi, A. and Garibay, O. O. (2021). “TabFairGAN: Fair Tabular Data Generation with Generative Adversarial
Networks.” In: <em>arXiv e-Print</em>.
Rao, A. and Jelvis, T. (2022). <em>Foundations of Reinforcement Learning with Applications in Finance</em>.
Rebonato, R. (2018).“The quickest way to lose the money you cannot afford to lose: reverse stress testing with
maximum entropy.” In: <em>Journal of Risk</em> 20(3), pp. 83–93.
Rikli, S., Bigler, D. N., Pfenninger, M., and Osterrieder, J. (2021).“Wasserstein GAN: Deep Generation applied on
Bitcoins financial time series.” In: <em>arXiv e-Print</em>.
Rocca, J. and Rocca, B. (2019).“Intuitively Understanding Variational Autoencoders.” In: <em>Towards Data Science</em>.
Rojas, H. and Dias, D. (2021).“Stress testing network reconstruction via graphical causal model.” In: <em>Applied
Stochastic Models in Business and Industry</em>.
Romano, J. P. and Wolf, M. (2018).“Multiple Testing of One-Sided Hypotheses: Combining Bonferroni and the
Bootstrap.” In: <em>Predictive econometrics and big data</em>. Ed. by V. Kreinovich, S. Sriboonchitta, and N. Chakpitak.
Vol. 753. Springer International Publishing, pp. 78–94.
Roncalli, T. (2021).“Advanced Course in Asset Management.” In: <em>SSRN e-Print</em>.
Rosen, D. (2015a).“Integrating Economic Scenarios with Advanced Scenario Analytics to Manage Investment
Portfolios.” In: <em>SSRN e-Print</em>.
Rosen, D. (2015b).“Re-Thinking Scenarios: Stress Testing of Multi-Asset Portfolios by Integrating Economic Sce-
narios with Advanced Simulation Analytics.” In: <em>SSRN e-Print</em>.
Rosen, D. and Saunders, D. (2015).“Regress Under Stress: A Simple Least-Squares Method for Integrating Economic
Scenarios with Risk Simulations.” In: <em>SSRN e-Print</em>.
Rosen, D. and Saunders, D. (2016).“Regress under stress: A simple least-squares method for integrating economic
scenarios with risk simulations.” In: <em>Journal of Risk Management in Financial Institutions</em> 9(4), pp. 391–412.
Rosolia, A. and Osterrieder, J. (2021).“Analyzing Deep Generated Financial Time Series for Various Asset Classes.”
In: <em>SSRN e-Print</em>.
Ruenzi, S., Ungeheuer, M., and Weigert, F. (2020).“Joint Extreme events in equity returns and liquidity and their
cross-sectional pricing implications.” In: <em>Journal of Banking &amp; Finance</em> 115, p. 105809.
Sahamkhadam, M. and Stephan, A. (2021).“Portfolio Optimization Based on Forecasting Models Using Vine
Copulas: An Empirical Assessment for the Financial Crisis.” In: <em>SSRN e-Print</em>.
Salazar, A., Vergara, L., and Safont, G. (2021).“Generative Adversarial Networks and Markov Random Fields for
oversampling very small training sets.” In: <em>Expert Systems with Applications</em> 163, p. 113819.
Sani, A., Lazaric, A., and Ryabko, D. (2015).“The replacement bootstrap for dependent data.” In: <em>IEEE Interna-
tional Symposium on Information Theory (ISIT)</em>. IEEE, pp. 1194–1198.
Sapp, T. R. A. (2017).“Efficient Estimation of Distributional Tail Shape and the Extremal Index with Applications
to Risk Management.” In: <em>Journal of Mathematical Finance</em> 06(04), pp. 626–659.
Sarmas, E., Xidonas, P., and Doukas, H. (2020). <em>Multicriteria Portfolio Construction with Python</em>. Springer Inter-
national Publishing.
Sarris, D., Spiliotis, E., and Assimakopoulos, V. (2020).“Exploiting resampling techniques for model selection in
forecasting: an empirical evaluation using out-of-sample tests.” In: <em>Operational Research</em> 20(2), pp. 701–721.
Saxena, D. and Cao, J. (2020).“Generative Adversarial Networks (GANs): Challenges, Solutions, and Future
Directions.” In: <em>arXiv e-Print</em>.
Saxena, D. and Cao, J. (2022).“Generative Adversarial Networks (GANs).” In: <em>ACM Computing Surveys</em> 54(3),
pp. 1–42.</p>
<p>Schissler, A. G., Bedrick, E. J., Knudson, A. D., Kozubowski, T. J., Nguyen, T., Petereit, J., Piegorsch, W. W.,
and Tran, D. (2021). “Simulating High-Dimensional Multivariate Data using the bigsimr R Package.” In: <em>arXiv
e-Print</em>.
Schneider, P. G. (2020).“Sparse economic scenarios.” In: <em>SSRN e-Print</em>.
Schuderer, A., Bromuri, S., and Eekelen, M. van (2021).“Sim-Env: Decoupling OpenAI Gym Environments from
Simulation Models.” In: <em>arXiv e-Print</em>.
Schwaab, B., Zhang, X. (, and Lucas, A. (2021).“Modeling Extreme Events: Time-Varying Extreme Tail Shape.”
In: <em>SSRN e-Print</em>.
Seabrook, I., Caccioli, F., and Aste, T. (2021).“An Information Filtering approach to stress testing: an application
to FTSE markets.” In: <em>arXiv e-Print</em>.
Sebastian, A. and Gebbie, T. (2019).“Systematic Asset Allocation using Flexible Views for South African Markets.”
In: <em>arXiv e-Print</em>.
Shah, V. and Shroff, G. (2021). “Forecasting Market Prices using DL with Data Augmentation and Meta-learning:
ARIMA still wins!” In: <em>arXiv e-Print</em>.
Sharma, A., Syrgkanis, V., Zhang, C., and Kiciman, E. (2021a). “DoWhy: Addressing Challenges in Expressing and
Validating Causal Assumptions.” In: <em>arXiv e-Print</em>.
Sharma, D., Bouchaud, J.-P., Gualdi, S., Tarzia, M., and Zamponi, F. (2021b).“V- U-, L- or W- shaped economic
recovery after Covid-19: Insights from an Agent Based Model.” In: <em>PLOS ONE</em> 16(3). Ed. by S. C. Gherghina,
e0247823.
Sharma, D., Bouchaud, J.-P., Tarzia, M., and Zamponi, F. (2020).“A constraint-satisfaction agent-based model for
the macroeconomy.” In: <em>arXiv e-Print</em>.
Shen, Z., Liu, J., He, Y., Zhang, X., Xu, R., Yu, H., and Cui, P. (2021). “Towards Out-Of-Distribution Generaliza-
tion: A Survey.” In: <em>arXiv e-Print</em>.
Shi, X., Xu, D., and Zhang, Z. (2022). “Deep Learning Algorithms for Hedging with Frictions.” In: <em>arXiv e-Print</em>.
Shi, Y., Li, B., and Du, G. (2021).“Pyramid scheme in stock market: a kind of financial market simulation.” In:
<em>arXiv e-Print</em>.
Siddique, A., Hasan, I., and Lynch, D. (2019). <em>Stress Testing (Second Edition)</em>. Risk Books. 500 pp.
Siebert, J., Gross, J., and Schroth, C. (2021).“A systematic review of Python packages for time series analysis.”
In: <em>Engineering Proceedings</em> 5(1) (22).
Siew, L. W., Hj, and Ismail, H. B. (2015).“The Impact of Different Economic Scenarios Towards Portfolio Selection
in Enhanced Index Tracking Problem.” In: <em>Advanced Science Letters</em> , pp. 1285–1288.
Silva, A. C. and Ferreira, F. F. (2021).“Surrogate Monte Carlo.” In: <em>arXiv e-Print</em>.
Silva, T., Pinheiro, P. R., and Poggi, M. (2017).“A more human-like portfolio optimization approach.” In: <em>European
Journal of Operational Research</em> 256(1), pp. 252–260.
Simos, T. E., Mourtas, S. D., and Katsikis, V. N. (2021).“Time-varying Black–Litterman portfolio optimization
using a bio-inspired approach and neuronets.” In: <em>Applied Soft Computing</em> 112, p. 107767.
Skoglund, J. (2019).“Quantification of model risk in stress testing and scenario analysis.” In: <em>Journal of Risk Model
Validation</em> 13(1), pp. 1–23.
Smith, K. E. and Smith, A. O. (2020).“Conditional GAN for timeseries generation.” In: <em>arXiv e-Print</em>.
Snow, D. (2019).“Machine learning in asset management.” In: <em>SSRN e-Print</em>.
Snow, D. (2020a).“DataGene: A Framework for Dataset Similarity.” In: <em>SSRN e-Print</em>.
Snow, D. (2020b).“DeltaPy: A Framework for Tabular Data Augmentation in Python.” In: <em>SSRN e-Print</em>.
Snow, D. (2020c).“Machine Learning in Asset Management - Part 2: Portfolio Construction - Weight Optimization.”
In: <em>The Journal of Financial Data Science</em> 2 (2), pp. 17–24.
Snow, D. (2020d).“Machine Learning in Asset Management Part 1: Portfolio Construction Trading Strategies.” In:
<em>The Journal of Financial Data Science</em> 2(1) (1), pp. 10–23.
Staum, J. (2009).“Monte Carlo Computation in Finance.” In: <em>Monte Carlo and Quasi-Monte Carlo Methods 2008</em>.
Ed. by P. L’ Ecuyer and A. B. Owen. Springer Berlin Heidelberg, pp. 19–42.
Steehouwer, H. (2014).“Ex-ante risk management with scenarios.” In: <em>CFA Society Switzerland Series</em>.
Steehouwer, H. and Slater, A. (2010).“Macroeconomic Scenarios: A Frequency Domain Approach.” In: <em>SSRN e-
Print</em>.
Stephanovitch, A., Tanielian, U., Cadre, B., Klutchnikoff, N., and Biau, G. (2022). “Optimal 1-Wasserstein Distance
for WGANs.” In: <em>arXiv e-Print</em>.</p>
<p>Sun, H., Deng, Z., Chen, H., and Parkes, D. C. (2020).“Decision-Aware Conditional GANs for Time Series Data.”
In: <em>arXiv e-Print</em>.
Tadayon, M. and Pottie, G. (2020).“tsBNgen: A Python Library to Generate Time Series Data from an Arbitrary
Dynamic Bayesian Network Structure.” In: <em>arXiv e-Print</em>.
Takahashi, S., Chen, Y., and Tanaka-Ishii, K. (2019).“Modeling financial time-series with generative adversarial
networks.” In: <em>Physica A: Statistical Mechanics and its Applications</em> 527, p. 121261.
Tan, V. and Zohren, S. (2021).“Large Non-Stationary Noisy Covariance Matrices: A Cross-Validation Approach.”
In: <em>SSRN e-Print</em>.
Tanaka, K. (2017).“Forecasting scenarios from the perspective of a reverse stress test using second-order cone
programming.” In: <em>Journal of Risk Model Validation</em> 11(2), pp. 1–21.
Tatsat, H., Puri, S., and Lookabaugh, B. (2020). <em>Machine Learning and Data Science Blueprints for Finance: From
Building Trading Strategies to Robo-Advisors Using Python</em>. O’Reilly. 400 pp.
Taylor, L. and Nitschke, G. (2017).“Improving Deep Learning using Generic Data Augmentation.” In: <em>arXiv e-Print</em>.
ter Ellen, S., Hommes, C. H., and Zwinkels, R. C. J. (2021).“Comparing behavioural heterogeneity across asset
classes.” In: <em>Journal of Economic Behavior &amp; Organization</em>.
Thiem, T. N., Kemeth, F. P., Bertalan, T., Laing, C. R., and Kevrekidis, I. G. (2021).“Global and Local Reduced
Models for Interacting, Heterogeneous Agents.” In: <em>arXiv e-Print</em>.
Traccucci, P., Dumontier, L., Garchery, G., and Jacot, B. (2019).“A Triptych Approach for Reverse Stress Testing
of Complex Portfolios.” In: <em>Risk (Cutting Edge)</em>.
Tran, T., Pham, T., Carneiro, G., Palmer, L., and Reid, I. (2017).“A Bayesian Data Augmentation Approach for
Learning Deep Models.” In: <em>arXiv e-Print</em>.
Trimborn, T., Otte, P., Cramer, S., Beikirch, M., Pabich, E., and Frank, M. (2020).“SABCEMM: A Simulator for
Agent-Based Computational Economic Market Models.” In: <em>Computational Economics</em> 55(2), pp. 707–744.
Trucı́os, C., Mazzeu, J. H. G., Hallin, M., Hotta, L. K., Pereira, P. L. V., and Zevallos, M. (2021).“Forecasting
Conditional Covariance Matrices in High-Dimensional Time Series: a General Dynamic Factor Approach.” In:
<em>Journal of Business &amp; Economic Statistics</em> , pp. 1–35.
Tsamardinos, I., Greasidou, E., and Borboudakis, G. (2018).“Bootstrapping the out-of-sample predictions for
efficient and accurate cross-validation.” In: <em>Machine Learning</em> , pp. 1–28.
Tsanakas, A. and Zhu, R. (2021).“Copula model selection using image recognition.” In: <em>SSRN e-Print</em>.
Tuck, J., Barratt, S., and Boyd, S. (2022).“Portfolio Construction Using Stratified Models.” In: <em>Machine Learning
in Financial Markets: A guide to contemporary practices</em>. Ed. by A. Capponi and C.-A. Lehalle. Cambridge
University Press.
Ungolo, F., Sherris, M., and Zhou, Y. (2021).“affine_mortality: A Github repository for estimation, analysis, and
projection of affine mortality models.” In: <em>SSRN e-Print</em>.
Vamossy, D. and Skog, R. (2021). “EmTract: Investor Emotions and Market Behavior.” In: <em>arXiv e-Print</em>.
van Beek, M. (2020).“Consistent Calibration of Economic Scenario Generators: The Case for Conditional Simula-
tion.” In: <em>arXiv e-Print</em>.
Vandin, A., Giachini, D., Lamperti, F., and Chiaromonte, F. (2021).“Automated and Distributed Statistical Anal-
ysis of Economic Agent-Based Models.” In: <em>arXiv e-Print</em>.
Vanini, P. (2020).“Asset Management.” In: <em>SSRN e-Print</em>.
Vieira, A. (2020).“Generating Synthetic Sequential Data using GANs.” In: <em>Towards AI</em>.
Vinod, H. D. (2012).“Constructing Scenarios of Time Heterogeneous Series for Stress Testing.” In: <em>SSRN e-Print</em>.
Vinod, H. D. (2021).“R Package GeneralCorr Functions for Portfolio Choice.” In: <em>SSRN e-Print</em>.
Volpi, R., Namkoong, H., Sener, O., Duchi, J., Murino, V., and Savarese, S. (2018).“Generalizing to Unseen Domains
via Adversarial Data Augmentation.” In: <em>arXiv e-Print</em>.
Waller, N. G. (2020).“Generating Correlation Matrices With Specified Eigenvalues Using the Method of Alternating
Projections.” In: <em>The American Statistician</em> 74(1), pp. 21–28.
Wang, B., Xu, H., Zhang, J., Chen, C., Fang, X., Xu, Y., Kang, N., Hong, L., Jiang, C., Cai, X., Li, J., Zhou, F.,
Li, Y., Liu, Z., Chen, X., Han, K., Shu, H., Song, D., Wang, Y., Zhang, W., Xu, C., Li, Z., Liu, W., and Zhang,
T. (2020a).“VEGA: Towards an End-to-End Configurable AutoML Pipeline.” In: <em>arXiv e-Print</em>.
Wang, H. and Tu, W. (2014).“Bootstrap methods: the classical theory and recent development.” In: <em>Wiley statsref:
statistics reference online</em>. Ed. by N. Balakrishnan, T. Colton, B. Everitt, W. Piegorsch, F. Ruggeri, and J. L.
Teugels. Chichester, UK: John Wiley &amp; Sons, Ltd, pp. 1–12.</p>
<p>Wang, L., Ma, F., and Liu, G. (2020b).“Forecasting stock volatility in the presence of extreme shocks: Short-term
and long-term effects.” In: <em>Journal of Forecasting</em> 39(5), pp. 797–810.
Wang, R. (2021). “Discriminating modelling approaches for Point in Time Economic Scenario Generation.” In: <em>arXiv
e-Print</em>.
Wang, Y., Polson, N. G., and Sokolov, V. O. (2019).“Scalable Data Augmentation for Deep Learning.” In: <em>arXiv
e-Print</em>.
Wang, Y., Huang, G., Song, S., Pan, X., Xia, Y., and Wu, C. (2020c).“Regularizing Deep Networks with Semantic
Data Augmentation.” In: <em>arXiv e-Print</em>.
Wen, Q., Sun, L., Yang, F., Song, X., Gao, J., Wang, X., and Xu, H. (2021).“Time Series Data Augmentation for
Deep Learning: A Survey.” In: <em>Proceedings of the Thirtieth IJCAI Conference</em>.
Westphal, R. and Sornette, D. (2020).“How Market Intervention Can Prevent Bubbles and Crashes.” In: <em>SSRN
e-Print</em>.
Wiese, M., Knobloch, R., Korn, R., and Kretschmer, P. (2020).“Quant GANs: deep generation of financial time
series.” In: <em>Quantitative Finance</em> 20(9), pp. 1419–1440.
Wood, M. (2018).“How sure are we? Two approaches to statistical inference.” In: <em>arXiv e-Print</em>.
Xie, Q., Dai, Z., Hovy, E., Luong, M.-T., and Le, Q. V. (2019).“Unsupervised Data Augmentation.” In: <em>arXiv
e-Print</em>.
Xu, H., Wang, J., Li, H., Ouyang, D., and Shao, J. (2021).“Unsupervised meta-learning for few-shot learning.” In:
<em>Pattern Recognition</em> 116, p. 107951.
Xu, L., Gotwalt, C., Hong, Y., King, C. B., and Meeker, W. Q. (2020).“Applications of the Fractional-Random-
Weight Bootstrap.” In: <em>The American Statistician</em> , pp. 1–21.
Yacoby, Y., Pan, W., and Doshi-Velez, F. (2020).“Characterizing and Avoiding Problematic Global Optima of
Variational Autoencoders.” In: <em>Proceedings of Machine Learning Research</em> , pp. 1–17.
Yang, Y., UY, M. C. S., and Huang, A. (2020). “FinBERT: A Pretrained Language Model for Financial Commu-
nications.” In: <em>arXiv e-Print</em>.
Yao, H., Jia, X., Kumar, V., and Li, Z. (2020).“Learning with Small Data.” In: <em>Proceedings of the 26th ACM
SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</em>. ACM.
Ye, R. and Dai, Q. (2021).“Implementing transfer learning across different datasets for time series forecasting.” In:
<em>Pattern Recognition</em> 109, p. 107617.
Yeh, C.-C. M. (2020).“Towards a Near Universal Time Series Data Mining Tool: Introducing the Matrix Profile.”
In: <em>arXiv e-Print</em>.
Yeh, C.-C. M., Zhu, Y., Ulanova, L., Begum, N., Ding, Y., Dau, H. A., Zimmerman, Z., Silva, D. F., Mueen, A., and
Keogh, E. (2017).“Time series joins, motifs, discords and shapelets: a unifying view that exploits the matrix
profile.” In: <em>Data Mining and Knowledge Discovery</em> 32(1), pp. 1–41.
Yılmaz, A., Kara, M., and Ozdemir, O. (2021).“Comparison of different estimation methods for extreme value
distribution.” In: <em>Journal of Applied Statistics</em> 48(13-15), pp. 2259–2284.
Yoon, J., Jarrett, D., and van der Schaar, M. (2019).“Time-series Generative Adversarial Networks.” In: <em>NIPS</em>.
NIPS.
Yu, L., Hardle, W. K., Borke, L., and Benschop, T. (2020a).“An AI approach to measuring financial risk.” In:
<em>SSRN e-Print</em>.
Yu, P. L. H., Ng, F. C., and Ting, J. K. W. (2020b).“Adjusting covariance matrix for risk management.” In:
<em>Quantitative Finance</em> 20(10), pp. 1681–1699.
Yu, R. (2020).“A Tutorial on VAEs: From Bayes’ Rule to Lossless Compression.” In: <em>arXiv e-Print</em>.
Yuan, J. and Yuan, X. (2021).“A Monte Carlo synthetic sample based performance evaluation method for covariance
matrix estimators.” In: <em>Applied Economics Letters</em>.
Zhang, J. (2020).“Modern Monte Carlo methods for efficient uncertainty quantification and propagation: A survey.”
In: <em>WIREs Computational Statistics</em> 13(5).
Zhang, S. (2018).“Optimal Retirement Planning: Scenario Generation, Preferences, and Objectives.” PhD thesis.
University of Waterloo.
Zhang, X., Wang, Z., Liu, D., and Ling, Q. (2018). “DADA: Deep Adversarial Data Augmentation for Extremely
Low Data Regime Classification.” In: <em>arXiv e-Print</em>.
Zhao, L. (2022).“Event Prediction in the Big Data Era.” In: <em>ACM Computing Surveys</em> 54(5), pp. 1–37.
Zhu, Y., Mariani, G., and Li, J. (2021).“Pagan: Portfolio Analysis with Generative Adversarial Networks.” In:
<em>SSRN e-Print</em>.</p>
<p>Zhu, Y., Imamura, M., Nikovski, D., and Keogh, E. (2018).“Time series chains: A novel tool for time series data
mining.” In: <em>Proceedings of the Twenty-Seventh International Joint Conference on Artificial Intelligence</em>. Ed. by
J. Lang. California: International Joint Conferences on Artificial Intelligence Organization, pp. 5414–5418.
Zhu, Y., Imamura, M., Nikovski, D., and Keogh, E. (2019).“Introducing time series chains: a new primitive for
time series data mining.” In: <em>Knowledge and Information Systems</em> 60, pp. 1135–1161.
Ziyin, L., Minami, K., and Imajo, K. (2021).“What Data Augmentation Do We Need for Deep-Learning-Based
Finance?” In: <em>arXiv e-Print</em>.
Zorn, J. (2019).“Panic-aware portfolio optimization.” In: <em>Journal of Asset Management</em>.</p>
<h2>Appendix A: Overviews of investment processes and models in QWIM</h2>
<h3>References</h3>
<p>List of references:
Coqueret and Guida ( <em>Machine Learning for Factor Investing: R Version</em> , 2020)
Dixon et al. ( <em>Machine Learning in Finance: from theory to practice</em> , 2020)
Fabozzi et al. ( <em>Asset Management: Tools and Issues</em> , 2021)
Grealish and Kolm (“Robo-Advisory: From Investing Principles and Algorithms to Future Developments,” 2021)
Homescu (“Many risks, one (optimal) portfolio,” 2014)
Homescu (“Better Investing Through Factors, Regimes and Sensitivity Analysis,” 2015)
Jansen ( <em>Machine Learning for Algorithmic Trading (Second Edition)</em> , 2020)
Jurczenko et al. ( <em>Machine Learning for Asset Management</em> , 2020)
Kritzman et al. ( <em>A Practitioner’s Guide to Asset Allocation</em> , 2017)
Lopez de Prado ( <em>Machine learning for asset managers</em> , 2020)
Maschner et al. (“Modern Asset Management,” 2021)
Perrin and Roncalli (“Machine Learning Optimization Algorithms &amp; Portfolio Allocation,” 2020)
Roncalli (“Advanced Course in Asset Management,” 2021)
Vanini (“Asset Management,” 2020)</p>
<h3>Online courses</h3>
<p>List of online courses:</p>
<ul>
<li>Investment Management with Python and Machine Learning Specialization
    Introduction to Portfolio Construction and Analysis with Python
    Advanced Portfolio Construction and Analysis with Python
    Python and Machine Learning for Asset Management
    Python and Machine Learning for Asset Management with Alternative Data Sets</li>
<li>Machine Learning and Reinforcement Learning in Finance Specialization
    Guided Tour of Machine Learning in Finance
    Fundamentals of Machine Learning in Finance
    Reinforcement Learning in Finance
    Overview of Advanced Methods of Reinforcement Learning in Finance</li>
<li>Investment Management Specialization
    Understanding Financial Markets
    Meeting Investors’ Goals
    Portfolio and Risk Management
    Securing Investment Returns in the Long Run
    Planning your Client’s Wealth over a 5-year Horizon</li>
<li>Investment and Portfolio Management Specialization
    Global Financial Markets and Instruments
    Portfolio Selection and Risk Management
    Biases and Portfolio Selection
    Investment Strategies and Portfolio Analysis
    Build a Winning Investment Portfolio</li>
</ul>
<h2>Appendix C: Comparison of investment using portfolios metrics and benchmark portfolios</h2>
<h2>mark portfolios</h2>
<p>For your QWIM project it is likely that you would compare investment portfolios constructed using your method(s)
versus benchmark portfolios constructed using most common "optimal portfolio" types used in the industry and in
academia. See below for an example of how this can be done.</p>
<p><code>Figure 6: Example of portfolio optimization process</code>
Source:PyPortfolioOpt</p>
<h3>Portfolio optimization methods</h3>
<p>List of portfolio optimization methods may include (seeRoncalli (“Advanced Course in Asset Management,” 2021)
and Perrin and Roncalli (“Machine Learning Optimization Algorithms &amp; Portfolio Allocation,” 2020)for a com-
prehensive overview of such methods):</p>
<ul>
<li>equal weighting</li>
<li>mean variance optimization (Markowitz)</li>
<li>minimum variance optimization</li>
<li>maximum diversification</li>
<li>risk budgeting/risk parity</li>
<li>hierarchical risk parity</li>
<li>Black-Litterman</li>
<li>robust versions of some the above portfolio optimization methods
Some relevant links:</li>
<li>Portfolio Optimization: A General Framework for Portfolio Choice</li>
<li>Performance of risk-based asset allocation strategies</li>
<li>Revisiting the Portfolio Optimization Machine Portfolio</li>
<li>Construction Techniques Applied to Traditional Multi Asset Portfolios</li>
</ul>
<h3>Python and R packages/codes for portfolio optimization</h3>
<ul>
<li>Codes mentioned inSnow (“Machine Learning in Asset Management - Part 2: Portfolio Construction - Weight
    Optimization,” 2020)</li>
<li>Empyrial</li>
<li>MLFinLab</li>
<li>Optimal Portfolio</li>
<li>PortfolioAnalytics</li>
<li>PortfolioLab</li>
<li>PyPortfolioOpt</li>
<li>Quantropy</li>
<li>Riskfolio-Lib</li>
<li>RiskPortfolios</li>
<li>riskparityportfolio</li>
</ul>
<h3>Portfolio metrics</h3>
<p>List of portfolio metrics may include some of the following (seeBacon (“Performance Attribution: History and
Progress,” 2019)for a comprehensive list):</p>
<ul>
<li>Sharpe ratio</li>
<li>Sortino ratio</li>
<li>Information ratio</li>
<li>Maximum Drawdown</li>
<li>expected shortfall</li>
<li>maximum loss</li>
<li>and more.
Some relevant links:</li>
<li>Portfolio metrics</li>
<li>Picking the Right Risk-Adjusted Performance Metric</li>
<li>Risk-Adjusted Performance Measurement – State of the Art</li>
<li>An Investor’s Guide to the Risk Versus Return Conundrum</li>
<li>How sharp is the Sharpe ratio? Risk-adjusted Performance Measures</li>
</ul>
<h3>Python and R packages/codes for portfolio metrics and performance evaluation</h3>
<ul>
<li>bt</li>
<li>empyrical</li>
<li>ffn</li>
<li>JFE</li>
<li>MLFinLab</li>
<li>PerformanceAnalytics</li>
<li>portfolioBacktest</li>
<li>Portfolio Optimization and Performance Evaluation</li>
<li>Pyfolio</li>
<li>QuantStats</li>
<li>Riskfolio-Lib</li>
<li>tidyquant</li>
</ul>
<h3>How to compare investment portfolios</h3>
<p>Let us consider portfolio optimization methods (selected from the ones implemented in Python and/or R packages
mentioned above, such as PyPortfolioOpt) which rely on based on expected returns and expected covariance matrix.
One would construct two portfolios (let’s call them Traditional and Enhanced) using the same portfolio op-
timization method(s), where the only difference would be in terms of the inputs (expected returns and expected
covariance matrix) to the optimization method:
As of the date of portfolio construction, expected returns and expected covariance matrix can be either calculated
using only historical data or, respectively, output from your model. Then one would compare side-by-side various
portfolio metrics for these two portfolios. Comparison would be done across the entire Out-Of-Sample period, and
also across each market regine period.
NOTE: If you have N forecasting methods used in your coding framework, then for each optimizaton method
you would end up with (1+N) optimal portfolios
To exemplifty, let’s say that you want to construct portfolios at date of June 20, 2019, and you have data as
below</p>
<ul>
<li>Range of entire dataset: January 1st, 1990 - August 1, 2020</li>
<li>Range of Training dataset: January 1st, 1990- February 20, 2017</li>
<li>Range of Test dataset: February 20, 2017 - August 1, 2020
For Traditional portfolio:</li>
<li>vector of expected means is calculated based on historical data available at June 20, 2019 (namely from 1990
to June 19, 2019)</li>
<li>expected covariance matrix is calculated based on historical data available at June 20, 2019 (namely from
1990 to June 19, 2019)
For Enhanced portfolio:</li>
<li>
<p>vector of expected means is calculated based on forecasted values available at June 20, 2019 and obtained
using the forecasted model trained on given training dataset (which is from 1990 to 2017)</p>
</li>
<li>
<p>expected covariance matrix is calculated based on forecasted values available at June 20, 2019 and obtained
    using the forecasted model trained on given training dataset (which is from 1990 to 2017)
Then one would compare various portfolio metrics among the two portfolios. These metrics can be calculated on
following time periods:</p>
</li>
<li>from date of portfolio construction (June 20, 2019) to last date for which you have data (August 1, 2020)</li>
<li>from starting date of dataset (January 1st, 1990) to last date for which you have data (August 1, 2020)</li>
<li>from starting date of dataset (January 1st, 1990) to date of portfolio construction (June 20, 2019)
So you would have side-by-side comparisons of portfolio metrics for each of the above 3 time periods.
Portfolio metrics can be calculated using various Python and/or R packages mentioned above.</li>
</ul>